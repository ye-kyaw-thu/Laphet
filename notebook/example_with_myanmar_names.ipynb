{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a41a129b-1dcd-433b-830b-d1ce546f05e2",
   "metadata": {},
   "source": [
    "# Laphet with Myanmar Names Dataset\n",
    "\n",
    "ဒီ Jupyter notebook က Laphet LM Toolkit ကို သုံးပြီး MLP, Bi-LSTM, Transformer, BERT, GPT အခြေခံတဲ့ language model (LM) တွေကို ဆောက်ကြည့်တာ၊ ဆောက်ထားပြီးသား LM ကိုသုံးပြီး text generation စမ်းလုပ်ပြထားတာပါ။  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102f76d6-b828-4250-9234-00caf02d91d1",
   "metadata": {},
   "source": [
    "## Dataset Information\n",
    "\n",
    "Dataset link: [https://github.com/ye-kyaw-thu/myRoman](https://github.com/ye-kyaw-thu/myRoman)  \n",
    "\n",
    "myRoman ဒေတာ format က အောက်ပါအတိုင်း ရှိတာမို့  \n",
    "\n",
    "1\tကကြိုးကြာ\tက ကြိုး ကြာ\tka kyoe kyar  \n",
    "2\tကချောင်လွမ်းနန်း\tက ချောင် လွမ်း နန်း\tka chaung lwan nan  \n",
    "3\tကချောင်လွမ်းနန်း\tက ချောင် လွမ်း နန်း\tka chaung lwan nang  \n",
    "\n",
    "ဝဏ္ဏဖြတ်ထားတဲ့ (i.e. syllable) တတိယ ကော်လံကို ယူသုံးထားပါတယ်။  \n",
    "ပြီးတော့ ‌ZWNJ (U+200C) နဲ့ SHY (U+00AD) သင်္ကေတတွေကို clean လုပ်ပြီး သုံးခဲ့ပါတယ်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d6982d-00e8-4a4f-b809-13b139e91b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev_name.txt  start_names.txt  test_name.txt  train_name.txt\n"
     ]
    }
   ],
   "source": [
    "ls ./data/myRoman/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816fc343-d013-4a92-bf0d-a8f1b0152f54",
   "metadata": {},
   "source": [
    "train_name.txt ဖိုင်က training လုပ်တဲ့အခါမှာ သုံးဖို့အတွက် ပြင်ထားတာ။  \n",
    "dev_name.txt ဖိုင်က development သို့မဟုတ် validation အတွက် သုံးဖို့ ပြင်ထားတာ။  \n",
    "test_name.txt ဖိုင်က testing/evaluation လုပ်ဖို့အတွက် ပြင်ထားတာ။  \n",
    "start_names.txt ဖိုင်က ဆောက်ထားတဲ့ language model တွေနဲ့ မြန်မာနာမည်တွေကို generate လုပ်ခိုင်းတဲ့အခါမှာ ကိုယ်က စစေချင်တဲ့ ဝဏ္ဏ (i.e. syllable) စာလုံးတွေကို ပြင်ထားတဲ့ ဖိုင်ပါ။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "301671e0-feeb-4d40-9f52-e4e0be7d9afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1000    3193   37204 ./data/myRoman/dev_name.txt\n",
      "     15      18     205 ./data/myRoman/start_names.txt\n",
      "   1000    3246   37728 ./data/myRoman/test_name.txt\n",
      "  27246   88007 1028564 ./data/myRoman/train_name.txt\n",
      "  29261   94464 1103701 total\n"
     ]
    }
   ],
   "source": [
    "!wc ./data/myRoman/*.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbebf178-7430-43f6-9a99-4e733a2fd55e",
   "metadata": {},
   "source": [
    "အထက်မှာ မြင်ရတဲ့အတိုင်း training data က စာကြောင်းရေ နှစ်သောင်းခုနှစ်ထောင်ကျော်ရှိပါတယ်။  \n",
    "development နဲ့ test ဒေတာကိုတော့ စာကြောင်းရေ တစ်ထောင်စီ ထားထားပါတယ်။\n",
    "\n",
    "File format က sentence တစ်ကြောင်းကို နာမည်တစ်ခုမို့လို့ တနည်းအားဖြင့် training ဒေတာက မြန်မာစာနဲ့ ရိုက်ထားတဲ့ နာမည်ပေါင်း နှစ်သောင်းခုနှစ်ထောင်ကျော်ရှိပါတယ်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25faf117-c1fc-41df-a55f-1d79e9e9d0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "သူ ရ ဖြိုး မင်း\n",
      "ခန့် မင်း သူ\n",
      "ခိုင် ဇာ ဝင်း\n",
      "ကြည် အောင် မင်း\n",
      "အောင် ဇင် ခန့်\n",
      "ကျော် လင်း ဝေ\n",
      "ခတ္တာ ဇော်\n",
      "ကောင်း ခန့် လင်း\n",
      "အောင် ထူး\n",
      "အောင် သန်း ထွန်း\n"
     ]
    }
   ],
   "source": [
    "!head ./data/myRoman/train_name.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12cd7a84-0f27-409e-92b4-f14a6c664d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ကံ ကောင်း\n",
      "လဲ့ လဲ့\n",
      "ကျော် တိုး ဝေ\n",
      "သက် ဘုန်း နိုင်\n",
      "သိမ့် သူ သူ ကျော်\n",
      "သဲ အိန္ဒြေ အောင်\n",
      "ကျော် သန်း ထွန်း\n",
      "အိ မွန် သန့်\n",
      "အေး မြင့် မိုရ် ပိုင်\n",
      "အောင် ဖုန်း ပိုင်\n"
     ]
    }
   ],
   "source": [
    "!head ./data/myRoman/dev_name.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67277981-f61e-416e-9052-dcd8372c3be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "အေး သိင်္ဂီ\n",
      "သာ စော\n",
      "ကျော့ ယ မင်း သွယ်\n",
      "မိုး ဆု ပန်\n",
      "ခေါ် ထန့်\n",
      "ခိုင် ခိုင် ဖြိုး\n",
      "ကြယ် စင် မင်း ခန့်\n",
      "သေး မယ်\n",
      "သိဒ္ဓိ ဆန်း\n",
      "က လျာ သန်း\n"
     ]
    }
   ],
   "source": [
    "!head ./data/myRoman/test_name.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ef1659e-22fa-4ad5-9b32-eb4f959f98e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ကျော်\n",
      "မ မ\n",
      "အေး\n",
      "လှ လှ\n",
      "\n",
      "မြ အေး\n",
      "သ\n",
      "မောင်\n",
      "မြင့် မြင့်\n",
      "ရွှေ\n"
     ]
    }
   ],
   "source": [
    "!head ./data/myRoman/start_names.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0144bd9-5a43-4d71-88d7-0ffad475d7b2",
   "metadata": {},
   "source": [
    "start_names.txt ဖိုင်ထဲမှာ blank line ကိုလည်း တမင်တကာ ထားပြီး စမ်းထားတာပါ။ ကျပန်း အစစာလုံးနဲ့ ပရိုဂရမ်က name generate လုပ်ပေးသလား စမ်းချင်လို့ပါ။  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46704e53-c2c5-4694-a504-93b17f53c810",
   "metadata": {},
   "source": [
    "## --help of Laphet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12ad27a2-453e-4134-a137-a8fc0041c8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: laphet.py [-h] --model_type {mlp,bilstm,transformer,bert,gpt} [--train]\n",
      "                 [--generate] [--test] [--data DATA] [--model MODEL]\n",
      "                 [--vocab VOCAB] [--dev_file DEV_FILE] [--test_file TEST_FILE]\n",
      "                 [--prompt PROMPT] [--input INPUT] [--seq_len SEQ_LEN]\n",
      "                 [--output OUTPUT] [--no_of_generation NO_OF_GENERATION]\n",
      "                 [--epochs EPOCHS] [--batch_size BATCH_SIZE] [--lr LR]\n",
      "                 [--embed_dim EMBED_DIM] [--num_heads NUM_HEADS]\n",
      "                 [--num_layers NUM_LAYERS] [--hidden_dim HIDDEN_DIM]\n",
      "                 [--ff_dim FF_DIM] [--dropout DROPOUT]\n",
      "                 [--temperature TEMPERATURE] [--top_k TOP_K] [--top_p TOP_P]\n",
      "\n",
      "Laphet language model toolkit for Burmese.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --model_type {mlp,bilstm,transformer,bert,gpt}\n",
      "                        Type of model to use: mlp, bilstm, transformer, bert\n",
      "                        or gpt.\n",
      "  --train               Train the model.\n",
      "  --generate            Generate text using the trained model.\n",
      "  --test                Test the BERT model and evaluate perplexity.\n",
      "  --data DATA           Path to the dataset.\n",
      "  --model MODEL         Path to save/load the model.\n",
      "  --vocab VOCAB         Path to save/load the tokenizer vocabulary\n",
      "  --dev_file DEV_FILE   Path to the development or validation dataset.\n",
      "  --test_file TEST_FILE\n",
      "                        Path to the test dataset.\n",
      "  --prompt PROMPT       Prompt for text generation (default: None).\n",
      "  --input INPUT         File with starting words for line-by-line generation\n",
      "                        (default: None).\n",
      "  --seq_len SEQ_LEN     Sequence length (default: 30).\n",
      "  --output OUTPUT       File to save the generated text (default: None).\n",
      "  --no_of_generation NO_OF_GENERATION\n",
      "                        Number of sequences to generate (default: 1).\n",
      "  --epochs EPOCHS       Number of training epochs (default: 10).\n",
      "  --batch_size BATCH_SIZE\n",
      "                        Batch size (default: 32).\n",
      "  --lr LR               Learning rate (default: 0.0001).\n",
      "  --embed_dim EMBED_DIM\n",
      "                        Embedding dimension (default: 256).\n",
      "  --num_heads NUM_HEADS\n",
      "                        Number of attention heads (default: 4).\n",
      "  --num_layers NUM_LAYERS\n",
      "                        Number of layers (default: 4).\n",
      "  --hidden_dim HIDDEN_DIM\n",
      "                        Hidden dimension for LSTM (default: 512).\n",
      "  --ff_dim FF_DIM       Feedforward dimension for Transformer (default: 512).\n",
      "  --dropout DROPOUT     Dropout rate for LSTM (default: 0.5).\n",
      "  --temperature TEMPERATURE\n",
      "                        Sampling temperature (default: 1.0).\n",
      "  --top_k TOP_K         Top-k sampling (default: 10).\n",
      "  --top_p TOP_P         Top-p sampling (default: 0.9).\n"
     ]
    }
   ],
   "source": [
    "!python ./laphet.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238f50e4-3269-4067-938d-dbe6cbb468bb",
   "metadata": {},
   "source": [
    "ကိုယ်စက်ထဲမှာ pytorch အပါအဝင် လိုအပ်တဲ့ python library တွေကို မှန်မှန်ကန်ကန် install လုပ်ထားရင် အထက်ပါလိုမျိုး help screen ကို မြင်ရပါလိမ့်မယ်။   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03b68ee-7332-4094-9133-93d65b9cf11c",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP) based Language Modeling\n",
    "\n",
    "အရင်ဆုံး MLP-based LM ကို ဆောက်မယ်။ ပြီးရင် text generation လုပ်ကြည့်မယ်။ ပြီးရင် test data ကိုသုံးပြီး evaluation လုပ်ကြည့်မယ်။  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931ce127-8140-4785-b89c-fd921994538a",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbd20ea0-1070-4788-87de-354d146ef9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Training): 100%|█████████████████| 852/852 [00:06<00:00, 129.71it/s]\n",
      "Epoch 1, Training Loss: 1.2911\n",
      "Epoch 1/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 505.43it/s]\n",
      "Epoch 1, Validation Loss: 1.0546\n",
      "Best model saved at ./model/name/mlp.model with validation loss: 1.0546\n",
      "Epoch 2/10 (Training): 100%|█████████████████| 852/852 [00:06<00:00, 133.31it/s]\n",
      "Epoch 2, Training Loss: 1.0532\n",
      "Epoch 2/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 504.22it/s]\n",
      "Epoch 2, Validation Loss: 1.0525\n",
      "Best model saved at ./model/name/mlp.model with validation loss: 1.0525\n",
      "Epoch 3/10 (Training): 100%|█████████████████| 852/852 [00:06<00:00, 135.22it/s]\n",
      "Epoch 3, Training Loss: 1.0522\n",
      "Epoch 3/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 502.92it/s]\n",
      "Epoch 3, Validation Loss: 1.0521\n",
      "Best model saved at ./model/name/mlp.model with validation loss: 1.0521\n",
      "Epoch 4/10 (Training): 100%|█████████████████| 852/852 [00:06<00:00, 137.78it/s]\n",
      "Epoch 4, Training Loss: 1.0520\n",
      "Epoch 4/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 502.03it/s]\n",
      "Epoch 4, Validation Loss: 1.0520\n",
      "Best model saved at ./model/name/mlp.model with validation loss: 1.0520\n",
      "Epoch 5/10 (Training): 100%|█████████████████| 852/852 [00:06<00:00, 141.32it/s]\n",
      "Epoch 5, Training Loss: 1.0519\n",
      "Epoch 5/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 514.98it/s]\n",
      "Epoch 5, Validation Loss: 1.0519\n",
      "Best model saved at ./model/name/mlp.model with validation loss: 1.0519\n",
      "Epoch 6/10 (Training): 100%|█████████████████| 852/852 [00:06<00:00, 140.36it/s]\n",
      "Epoch 6, Training Loss: 1.0519\n",
      "Epoch 6/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 498.19it/s]\n",
      "Epoch 6, Validation Loss: 1.0519\n",
      "Best model saved at ./model/name/mlp.model with validation loss: 1.0519\n",
      "Epoch 7/10 (Training): 100%|█████████████████| 852/852 [00:06<00:00, 140.83it/s]\n",
      "Epoch 7, Training Loss: 1.0519\n",
      "Epoch 7/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 507.54it/s]\n",
      "Epoch 7, Validation Loss: 1.0519\n",
      "Best model saved at ./model/name/mlp.model with validation loss: 1.0519\n",
      "Epoch 8/10 (Training): 100%|█████████████████| 852/852 [00:06<00:00, 136.58it/s]\n",
      "Epoch 8, Training Loss: 1.0518\n",
      "Epoch 8/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 507.36it/s]\n",
      "Epoch 8, Validation Loss: 1.0518\n",
      "Best model saved at ./model/name/mlp.model with validation loss: 1.0518\n",
      "Epoch 9/10 (Training): 100%|█████████████████| 852/852 [00:06<00:00, 137.43it/s]\n",
      "Epoch 9, Training Loss: 1.0518\n",
      "Epoch 9/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 512.31it/s]\n",
      "Epoch 9, Validation Loss: 1.0518\n",
      "Best model saved at ./model/name/mlp.model with validation loss: 1.0518\n",
      "Epoch 10/10 (Training): 100%|████████████████| 852/852 [00:06<00:00, 137.85it/s]\n",
      "Epoch 10, Training Loss: 1.0518\n",
      "Epoch 10/10 (Validation): 100%|████████████████| 32/32 [00:00<00:00, 521.50it/s]\n",
      "Epoch 10, Validation Loss: 1.0518\n",
      "Best model saved at ./model/name/mlp.model with validation loss: 1.0518\n",
      "\n",
      "real\t1m4.453s\n",
      "user\t1m6.102s\n",
      "sys\t0m0.387s\n"
     ]
    }
   ],
   "source": [
    "!time python laphet.py --model_type mlp --train --data ./data/myRoman/train_name.txt \\\n",
    "--dev_file ./data/myRoman/dev_name.txt --model ./model/name/mlp.model --seq_len 50 --epochs 10 --batch_size 32 --lr 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a872326e-a819-45ac-b541-f70a7191f2a5",
   "metadata": {},
   "source": [
    "ထွက်လာတဲ့ vocab ဖိုင်နဲ့ model ဖိုင်ကို လေ့လာကြည့်ရအောင်..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f02cbd9-0d5d-428d-8a25-b6c7c4271d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ye ye 4.8M Jan 27 00:39 ./model/name/mlp.model\n",
      "-rw-rw-r-- 1 ye ye  24K Jan 27 00:38 ./model/name/mlp.model.vocab\n"
     ]
    }
   ],
   "source": [
    "ls -lh ./model/name/mlp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b65769a-bf29-4494-9ea6-ad9b7291cd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/name/mlp.model: Zip archive data, at least v0.0 to extract, compression method=store\n"
     ]
    }
   ],
   "source": [
    "!file ./model/name/mlp.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65692360-8fcf-4d04-93e3-ade2e2fbe5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ရု\t0\n",
      "တြီ\t1\n",
      "အဲ\t2\n",
      "မိန်\t3\n",
      "ဆုန်\t4\n",
      "တုံ\t5\n",
      "ကိုက်\t6\n",
      "စုက္က\t7\n",
      "ရှုံး\t8\n",
      "ကျော်\t9\n"
     ]
    }
   ],
   "source": [
    "!head ./model/name/mlp.model.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c972af4-6aae-4f43-8734-fbb191452c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ဝန်း\t1433\n",
      "ဘု\t1434\n",
      "အေ\t1435\n",
      "ကတ္တီ\t1436\n",
      "သိမ့်\t1437\n",
      "ဆံ\t1438\n",
      "မှိုင်\t1439\n",
      "အန်\t1440\n",
      "ရစ္စ\t1441\n",
      "ဇော\t1442\n"
     ]
    }
   ],
   "source": [
    "!tail ./model/name/mlp.model.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23190499-5d4d-4b91-9dd5-6870fd511793",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba855c51-44e9-461f-a119-b2af134b018e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ye/exp/name-lm/lib/laphet.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Generated Text 1: ရဲ သဉ္ဇာ ဘာ လှေ ဒွေး ချော ရို လျို လည်း အိဏ်း ကျွန် ဟက်ခ် သီ ရွှန်း ခြယ် အီ အစ္စ တင့် စီ ဂုန် ကေး လက်စ် စော ပြန်း ခွေ ဒင်း သော် ယတ် ဖောင်း စောမ် သိဉ္စည်း စမ်း ထဲမ်း အိန္ဓု မန် ပျံ့ ဿဏ် သင်္ချာ ကြည် ကြုံ ရှာ ပေါက် ကွ ရေ့ဒ်ဗ် ပြောင်း ကျီ ဇယ် ရုဏ် ရှိုး ပေါ် လာန်\n",
      "Generated Text 2: ရဲ လုတ် ဇာရ် ရော် လွင် နိုး ခွေ ဣန္ဒ ကွေး နွေ ထား ဇမ်း ဓု လိန်း တွန်း နွန်း ရှိမ်း ကြုံ ဏီ ချွန် ကျွန် ရစ္စ သင်္ချာ တီး ကြယ် ဒ ဒေါ မောက် ရှား ဿန်း အော် ဂျမ်း ပါး နဲမ်း န ရယ်လ် ချိုင်း ခမ်း ရွိုင် ဗစ် ဟီး ကျော် အန့် ဂူ သိမ့် ထိုင် မွေး ဂေး ဟွမ် ကောင် ကင်း\n",
      "Generated Text 3: ရဲ ကွ ဒေါင်း လုံး ဂျက်ခ် စည် နေး သတ် ကြည့် ဏိ လောင်ဝ် တည် ဂျယ် နု ကျွင်း ယော ဟွမ် သင်္ခ ဇမ္ဗူ ညိမ့် သိုက် သဉ္ဇာ ထွယ် ခွေ နာ့ ကွမ်း တု အိန္တာ တောက် ကျိမ် နဲ့ ဆွယ် ဟတ် ဘင်း ရုံ ဝယ် ဆောမ်း သင့် ကိန်း ညွန် သ ညိမ့် လမ့် ဖေါ ဒူ ပျံ့ စေး ညိမ်း ခွါလ် ဘွဲ စုက္က\n",
      "Generated Text 4: ရဲ ခတ် ပြိုင် လုံး မှုံ လမ့် ခံ့ ဝေ ခေါ်လ် ဘုဏ်း ပို ဂိမ်း ဝါး ချင် ပွင့် နယ် လာန်း ဂျူ ဂေ စင် ဟာ မြေး ချန်း ကွတ် မဉ္ဇူ ဇုံ ကျွန်း တံ ရမ်း ယော ရံ သတ္တိ ရှောင် မား ရှိ ဘ ကျုံ ခို ဘုံ အစ္စ ဂျိမ်းစ် ဆင့် လက်ျာ ကော ဝမ်း ယိုင် ဘာ ဗ ရှဲ သန် နှဲမ်း\n",
      "Generated Text 5: ရဲ ကျိုင်း ယု သို စန်း လမ် အိန္ဒြေ ကွန့် ကွီး ဂါး မီ ဇမ့် ဆွေ ဂျီး နမ် ဟံ ဆန့် ရိုး ဗန် အံ ပြာ အွန် ရု သီ ဣန္တာ ပေ ဟင်လ် ဖို့ ဟမ် သွဲ့ စန်း ဗေး ကောလ် မွှန်း လုတ် စွန် ကျဲရ် အဏ္ဏ ပေါ့ ကွာ ကွက် ဇာ ပို့ တို ဟွ မုံ နွမ် သေ့ ဖိ ဒေါင်း ရွှင်\n",
      "Generated Text 6: ရဲ ဆွိ သွင် ယူ အပ္ပ မံ ရှာမ် အိန္ဒု ထွဏ်း ရွမ်း ခမ့် နှော သိ တီးလ် ဂျိုး ကွတ် နတ် ကြ သျှန် ကြုတ် ခန်း ပျံ့ တံ့ ချုံး က မွမ်း ထိပ် ဆူး ကွက် ရင့် လု မံ တိမ်း လျန် အိန္နီ တွယ် ဒူ တွမ် ဆင် ကျော ထာသ် ကမ္မ ထော မြင် ဗ ဝိ ဖြိုး သော့ စံ ဘွမ် ကျိမ်\n",
      "Generated Text 7: ရဲ ဝံ မဲန်း ထိန် စိန် ချယ်လ် လျင် ကမ်း ဇို အွန် လျင့် ချယ်လ် ဒယ်လ် ထဲမ်း ဝင်း ဂ ဿဲ ဿ ရိန်း စို ကျား သျှမ်း မား သျှန်း လိန် ဥတ္တ တိမ်း ဧည့် ဂုံ ကြော့ ဒို ဟေ ဝိန် ပြည့် ဝန်း မူ စဉ့် ရမ် ကြည် ရို့စ် ဝတ် ဒန့် ချိုး အိဏ်း ခွမ် ပမ် ချို ခွမ်း သျှန္တီ ကေး ဝင့်\n",
      "Generated Text 8: ရဲ ထိုး ဗင် မာ့ ပြီး ကွန်း တ ကွ တီလ် ယူ သုံး ယိန်း စောမ် နွန်း ကင်း ချိန် နွမ် ရမ်း ရယ် စန်း အိန္မာ မြစ် မွေ နွယ် မန် နှာ လုံ စူး လမ် ကိမ်း ကို မုံ ဘူး ယျ သီ ဣန္ဒ အော် ဘူ ကမ္ဘာ ရှည် ရိန်း ဘက် ဝီ ဆယ် ပြိုင် လွမ် အမ် ပြည့် နူး စက္ကန့် ဘွဲ့\n",
      "Generated Text 9: ရဲ ချိန်း အဏ္ဏ လျံ ခွမ်း ဒန့် ကြည် ဓမ္မာ သိင်္ဂါ ရာ ဗွီ ကောလ် နေ တေ့ ဟိဏ်း သဉ္စာ ဟောက် တော စင်း မုခ် ဆူ နှင်မ် ကေး မို ပေါ် ချင် ယောင် မန် ဒွတ် ဗင် တုန် နှာ အိ ခ သင်္ကေ ဟွမ် ခွား သံ မှိုင်း ချိတ် သျှန်း မန် ခင် ကင် အိဏ်း ငဲ မား ပယ် နွန် ပါ့ ဇင်း\n",
      "Generated Text 10: ရဲ ရင်န် ကျုံ မူ ဂဲလ် ဘန်း ယန် အဲင်န် အိမ်း ဂိတ် ဘောက် ကွမ် ဝဏ် ဒင့် ကက် ရှင် နဲ သိုင်း တု တိုက် နှောင်း ဇွဲ စုက္က ကြိုင်း ဟုန် ကွက် ယ ဖု ကျီ ခေါ အား ဗြ လျင် မာ့ ဘု ဒင့် မေ ဇန္ဒား စဉ် င အက် ကမ်း ရွက် ရေ့စ် ဇုံ လည်း ဇူ မိုက် ဝါလ် ရပ် လဲမ့်\n",
      "\n",
      "real\t0m1.853s\n",
      "user\t0m4.111s\n",
      "sys\t0m0.251s\n"
     ]
    }
   ],
   "source": [
    "!time python -u laphet.py --model_type mlp --generate --model ./model/name/mlp.model \\\n",
    "--seq_len 50 --prompt \"ရဲ\" --no_of_generation 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4ecb66-0497-4cc5-a407-82ee6a828241",
   "metadata": {},
   "source": [
    "လူနာမည်ဆိုရင်တော့ ဝဏ္ဏအလုံး ၅၀ ဆိုတာက မဖြစ်နိုင်လို့ နှစ်လုံးလောက်ပဲ ထားပြီး text generate လုပ်ခိုင်းကြည့်ရအောင်။   \n",
    "sequence length ကို --seq_len 2 ဆိုတဲ့ setting နဲ့ run မယ်။ ရလဒ်က အောက်ပါအတိုင်းပါ။   \n",
    "တစ်ခုရှိတာက တစ်ခေါက် generate လုပ်ခိုင်းတိုင်း နာမည်အသစ်တွေကိုပဲ generate လုပ်မှာမို့ run တဲ့အခေါက်တိုင်းမှာ မတူတဲ့ syllable sequence တွေကိုပဲ ထုတ်ပေးပါလိမ့်မယ်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d28d0d81-ede6-4381-b7e3-8d6b5d549f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ye/exp/name-lm/lib/laphet.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Generated Text 1: ရဲ ဂျမ်း ရည်\n",
      "Generated Text 2: ရဲ တာ ရည်\n",
      "Generated Text 3: ရဲ ထု အုပ်\n",
      "Generated Text 4: ရဲ နေး ဟောမ်း\n",
      "Generated Text 5: ရဲ ဇမ် ချွန်\n",
      "Generated Text 6: ရဲ သ ရမ်\n",
      "Generated Text 7: ရဲ ညင် ဥက္ကာ\n",
      "Generated Text 8: ရဲ ချာ ဂေး\n",
      "Generated Text 9: ရဲ ထာသ် ဘုဏ်း\n",
      "Generated Text 10: ရဲ ညက် ပြိုင်\n",
      "\n",
      "real\t0m1.282s\n",
      "user\t0m3.539s\n",
      "sys\t0m0.249s\n"
     ]
    }
   ],
   "source": [
    "!time python -u laphet.py --model_type mlp --generate --model ./model/name/mlp.model \\\n",
    "--seq_len 2 --prompt \"ရဲ\" --no_of_generation 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5815325b-faca-42a7-8ca7-da7bc7672858",
   "metadata": {},
   "source": [
    "myRoman ရဲ့ ဒေတာမှာက တိုင်းရင်းသားနာမည်မျိုးစုံ ပါဝင်ပါတယ်။ အဲဒါကြောင့် ဗမာနာမည်အနေနဲ့ ကြည့်ရင် ထူးဆန်းတဲ့ နာမည်မျိုးတွေလည်း ထုတ်ပေးပါလိမ့်မယ်။ သေချာတာက MLP-based language model က အလုပ်လုပ်ပေးတာကိုတော့ တွေ့ရပါလိမ့်မယ်။  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea270d8-beb8-4d9f-aaa2-579502a606d1",
   "metadata": {},
   "source": [
    "## Text Generation with Start-Word Input File\n",
    "\n",
    "အင်္ဂလိပ်လိုခေါင်းစဉ်မှာက start word လို့ပေးထားပေမဲ့ ကျွန်တော်တို့ လက်ရှိ training လုပ်ထားတာက syllable သို့မဟုတ် ဝဏ္ဏဖြတ်ပြီး လုပ်ထားတာမို့လို့ start word သတ်မှတ်ပေးထားတဲ့ ဖိုင်မှာလည်း syllable unit ဖြတ်ပေးထားမှ အဆင်ပြေပါလိမ့်မယ်။ word ဖြတ်ပြီး training လုပ်ထားတဲ့ မော်ဒယ်အတွက်ဆိုရင်တော့ word unit နဲ့ သွားပါ။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12819b23-7bc8-4234-ad16-99a8e01b75c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ye/exp/name-lm/lib/laphet.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Random Prompt Generated: သင်း\n",
      "Generated texts saved to ./output/name/mlp_gen_texts.txt\n",
      "\n",
      "real\t0m1.341s\n",
      "user\t0m3.623s\n",
      "sys\t0m0.229s\n"
     ]
    }
   ],
   "source": [
    "!time python laphet.py --model_type mlp --generate --model ./model/name/mlp.model \\\n",
    "--seq_len 2 --input ./data/myRoman/start_names.txt --no_of_generation 5 --output ./output/name/mlp_gen_texts.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc2ee83-6c4b-4108-83fc-033153ccd57d",
   "metadata": {},
   "source": [
    "ထွက်လာတဲ့ output ဖိုင်ကို လေ့လာကြည့်ရအောင်။  \n",
    "--no_of_generation 5 ဆိုပြီး ထားခဲ့တာမို့လို့ input file ထဲက အစ စာလုံး တစ်ခုစီအတွက် ဥပမာ ငါးခုစီ generate လုပ်ပေးပါလိမ့်မယ်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8f2b328-5240-4703-86b9-2061771435fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ကျော် သျှန္တီ နွမ်း\n",
      "ကျော် ကာ ရို\n",
      "ကျော် ဆပ် အေ\n",
      "ကျော် ရုံး မြဉ္ဇူ\n",
      "ကျော် ချိ လတ်\n",
      "မ မ နု ထင်\n",
      "မ မ ဖွာ ပျို\n",
      "မ မ ဆူ အော\n",
      "မ မ ဇို ဏာ\n",
      "မ မ ခြူ ကြိုင်း\n",
      "အေး ခံ့ အေး\n",
      "အေး လိမ်း ရှိုင်းန်း\n",
      "အေး ငိုင် လှီး\n",
      "အေး စို ရေး\n",
      "အေး အမ်း ဗန်\n",
      "လှ လှ ဂျယ်လ် ကူ\n",
      "လှ လှ ကွဲ ချိုင်း\n",
      "လှ လှ ကြား စက္ကန့်\n",
      "လှ လှ တီးလ် ဆွမ်း\n",
      "လှ လှ ဇမ် ကူ\n",
      "သင်း ကော စင်\n",
      "သင်း ပေး အိပ်\n",
      "သင်း ဇောင်း မုခ်\n",
      "သင်း အက် ယံ\n",
      "သင်း ကမ္မ လန်\n",
      "မြ အေး တန့် ဒမ်း\n",
      "မြ အေး လင် တေး\n",
      "မြ အေး သက် ဒို့ဗ်\n",
      "မြ အေး ဆယ် လှန်\n",
      "မြ အေး လိုင် စိုက်\n",
      "သ မိုက် ညွှန်း\n",
      "သ ခဲ ဣန္ဒာ\n",
      "သ မက် ခြယ်\n",
      "သ က ပေါက်\n",
      "သ တင်း သုဒ္ဓေါ\n",
      "မောင် ချွတ် နွေး\n",
      "မောင် တည် ရိုင်းန်\n",
      "မောင် ပွန်း ဝူ\n",
      "မောင် တွာ ထန်း\n",
      "မောင် ပီး အောန်\n",
      "မြင့် မြင့် ဆွင် တုတ်\n",
      "မြင့် မြင့် ချင် သို့\n",
      "မြင့် မြင့် စမ်း နား\n",
      "မြင့် မြင့် တုတ် နွယ်\n",
      "မြင့် မြင့် အက် [PAD]\n",
      "ရွှေ တု ဂျမ်\n",
      "ရွှေ ခံ့ ဟိန်း\n",
      "ရွှေ မိန် ကွန့်\n",
      "ရွှေ ကြယ် လွှမ်း\n",
      "ရွှေ ဆည်း ခြာ\n",
      "အဂ္ဂ တွေး ဣန္ဒ\n",
      "အဂ္ဂ ရှဲမ်း ဇီ\n",
      "အဂ္ဂ လျှား မွန်း\n",
      "အဂ္ဂ တူး ဟေး\n",
      "အဂ္ဂ ရွတ် အုတ်\n",
      "ဥက္ကာ ရတ် မြင်\n",
      "ဥက္ကာ သို ဖူ\n",
      "ဥက္ကာ တောက် ဣန္တာ\n",
      "ဥက္ကာ ကု ဘောမ်\n",
      "ဥက္ကာ ခေါင်း လီ\n",
      "သိင်္ဂီ ယ ဘင်\n",
      "သိင်္ဂီ ရှိန် ရိုင်\n",
      "သိင်္ဂီ ကပ် ဇန္ဒား\n",
      "သိင်္ဂီ ပါ ကြွေ\n",
      "သိင်္ဂီ နိုင်း ဗျက်\n",
      "မေ နံ့ ချုံး\n",
      "မေ ဿာ သန်း\n",
      "မေ ဟိန်း ကျွဲ\n",
      "မေ အန် ပါ\n",
      "မေ ယု သိဉ္စည်း\n",
      "ခိုင် မိုက် ဟင်\n",
      "ခိုင် ဖီ တောင်\n",
      "ခိုင် ဆာ သုံး\n",
      "ခိုင် ချက်စ် မောက်\n",
      "ခိုင် မင် ကျွံ\n"
     ]
    }
   ],
   "source": [
    "!cat ./output/name/mlp_gen_texts.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a074a9-41bf-4ee0-9606-214dc33f1698",
   "metadata": {},
   "source": [
    "input ဖိုင်က မေ့နေနိုင်တာမို့ ပြန်ရိုက်ပြရရင် အောက်ပါအတိုင်းပါ။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8bb29c94-becf-4dfc-bb81-c9facfbf28a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ကျော်\n",
      "မ မ\n",
      "အေး\n",
      "လှ လှ\n",
      "\n",
      "မြ အေး\n",
      "သ\n",
      "မောင်\n",
      "မြင့် မြင့်\n",
      "ရွှေ\n",
      "အဂ္ဂ\n",
      "ဥက္ကာ\n",
      "သိင်္ဂီ\n",
      "မေ\n",
      "ခိုင်\n"
     ]
    }
   ],
   "source": [
    "!cat ./data/myRoman/start_names.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4a9f71-b1e0-4a20-8462-ee604886f5d4",
   "metadata": {},
   "source": [
    "## Testing and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824a502a-f4e8-41bd-baf0-1f3553cb6cbd",
   "metadata": {},
   "source": [
    "Testing လုပ်ချင်တာမို့လို့ --test ဆိုတဲ့ command option နဲ့ run ရပါလိမ့်မယ်။  \n",
    "test ဖိုင်ရှိတဲ့ path ကို ညွှန်းပေးရပါလိမ့်မယ်။  \n",
    "--test_file ./data/myRoman/test_name.txt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "921982f5-3cb7-46c9-91cd-66d80b9e42d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ye/exp/name-lm/lib/laphet.py:216: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Testing: 100%|██████████████████████████████████| 16/16 [00:00<00:00, 52.34it/s]\n",
      "Average Perplexity on Test Data: 1.1114\n",
      "Average Cross-Entropy on Test Data: 0.1056\n",
      "\n",
      "real\t0m1.229s\n",
      "user\t0m3.579s\n",
      "sys\t0m0.188s\n"
     ]
    }
   ],
   "source": [
    "!time python laphet.py --model_type mlp --test --model ./model/name/mlp.model \\\n",
    "--test_file ./data/myRoman/test_name.txt --seq_len 50 --batch_size 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311f4aaa-0865-4359-8093-80f5107109c1",
   "metadata": {},
   "source": [
    "Laphet LM Toolkit မှာ Perplexity ရော၊ Cross-Entropy နဲ့ရော evaluation လုပ်ကြည့်ထားပါတယ်။  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919ef3f8-0277-491a-9fc9-e1bf3a84f375",
   "metadata": {},
   "source": [
    "## Bi-LSTM based Language Modeling\n",
    "\n",
    "ဒီတစ်ခါတော့ command တစ်ခုစီကို အသေးစိတ်မရှင်းတော့ဘူး။  \n",
    "--model_type ဆိုတဲ့ နေရာမှာ bilstm ကို setup လုပ်ရင်ရပါပြီ။  \n",
    "ထွက်လာမယ့် model ဖိုင်နာမည်ကိုတော့ မတူအောင်ပေးသင့်တာပေါ့။  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9a1136-af83-4ee3-8dad-90a9a19e7a05",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0148bf38-188b-4d12-93b1-ee46a53aed98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Training): 100%|██████████████████| 852/852 [00:15<00:00, 55.18it/s]\n",
      "Epoch 1, Training Loss: 0.4833\n",
      "Epoch 1/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 164.94it/s]\n",
      "Epoch 1, Validation Loss: 0.3169\n",
      "Best model saved at ./model/name/bilstm.model with validation loss: 0.3169\n",
      "Epoch 2/10 (Training): 100%|██████████████████| 852/852 [00:15<00:00, 56.16it/s]\n",
      "Epoch 2, Training Loss: 0.3127\n",
      "Epoch 2/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 164.77it/s]\n",
      "Epoch 2, Validation Loss: 0.3085\n",
      "Best model saved at ./model/name/bilstm.model with validation loss: 0.3085\n",
      "Epoch 3/10 (Training): 100%|██████████████████| 852/852 [00:15<00:00, 56.40it/s]\n",
      "Epoch 3, Training Loss: 0.3053\n",
      "Epoch 3/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 164.33it/s]\n",
      "Epoch 3, Validation Loss: 0.3010\n",
      "Best model saved at ./model/name/bilstm.model with validation loss: 0.3010\n",
      "Epoch 4/10 (Training): 100%|██████████████████| 852/852 [00:15<00:00, 56.37it/s]\n",
      "Epoch 4, Training Loss: 0.2878\n",
      "Epoch 4/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 162.82it/s]\n",
      "Epoch 4, Validation Loss: 0.2705\n",
      "Best model saved at ./model/name/bilstm.model with validation loss: 0.2705\n",
      "Epoch 5/10 (Training): 100%|██████████████████| 852/852 [00:15<00:00, 56.12it/s]\n",
      "Epoch 5, Training Loss: 0.2335\n",
      "Epoch 5/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 166.35it/s]\n",
      "Epoch 5, Validation Loss: 0.1878\n",
      "Best model saved at ./model/name/bilstm.model with validation loss: 0.1878\n",
      "Epoch 6/10 (Training): 100%|██████████████████| 852/852 [00:15<00:00, 56.12it/s]\n",
      "Epoch 6, Training Loss: 0.1653\n",
      "Epoch 6/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 163.92it/s]\n",
      "Epoch 6, Validation Loss: 0.1368\n",
      "Best model saved at ./model/name/bilstm.model with validation loss: 0.1368\n",
      "Epoch 7/10 (Training): 100%|██████████████████| 852/852 [00:15<00:00, 56.05it/s]\n",
      "Epoch 7, Training Loss: 0.1148\n",
      "Epoch 7/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 161.98it/s]\n",
      "Epoch 7, Validation Loss: 0.0891\n",
      "Best model saved at ./model/name/bilstm.model with validation loss: 0.0891\n",
      "Epoch 8/10 (Training): 100%|██████████████████| 852/852 [00:15<00:00, 56.36it/s]\n",
      "Epoch 8, Training Loss: 0.0726\n",
      "Epoch 8/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 164.31it/s]\n",
      "Epoch 8, Validation Loss: 0.0579\n",
      "Best model saved at ./model/name/bilstm.model with validation loss: 0.0579\n",
      "Epoch 9/10 (Training): 100%|██████████████████| 852/852 [00:15<00:00, 56.38it/s]\n",
      "Epoch 9, Training Loss: 0.0479\n",
      "Epoch 9/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 160.82it/s]\n",
      "Epoch 9, Validation Loss: 0.0434\n",
      "Best model saved at ./model/name/bilstm.model with validation loss: 0.0434\n",
      "Epoch 10/10 (Training): 100%|█████████████████| 852/852 [00:15<00:00, 56.32it/s]\n",
      "Epoch 10, Training Loss: 0.0353\n",
      "Epoch 10/10 (Validation): 100%|████████████████| 32/32 [00:00<00:00, 161.87it/s]\n",
      "Epoch 10, Validation Loss: 0.0360\n",
      "Best model saved at ./model/name/bilstm.model with validation loss: 0.0360\n",
      "\n",
      "real\t2m36.390s\n",
      "user\t2m37.484s\n",
      "sys\t0m0.915s\n"
     ]
    }
   ],
   "source": [
    "!time python laphet.py --model_type bilstm --train --data ./data/myRoman/train_name.txt \\\n",
    "--dev_file ./data/myRoman/dev_name.txt --model ./model/name/bilstm.model --seq_len 50 --epochs 10 --batch_size 32 --lr 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f01d158-df75-4f62-9968-f0fed3b648a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ye ye 92M Jan 27 01:11 ./model/name/bilstm.model\n",
      "-rw-rw-r-- 1 ye ye 24K Jan 27 01:08 ./model/name/bilstm.model.vocab\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ./model/name/bilstm.model*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef9a353-0b32-418d-b787-0f600f61227d",
   "metadata": {},
   "source": [
    "## Text Generation\n",
    "\n",
    "--prompt \"ရဲ\" ဆိုတဲ့ setting နဲ့ run မှာမို့လို့ \"ရဲ\" နဲ့ စတဲ့ နာမည်တွေကို generate လုပ်ပေးသွားပါလိမ့်မယ်။  \n",
    "sequence length က ၅၀ ထားထားတာမို့လို့ နာမည်အရှည်ကြီးတွေ ရိုက်ထုတ်ပေးပါလိမ့်မယ်။  \n",
    "ပြီးတော့ --no_of_generation ကို ၁၀ ထားထားတာမို့လို့ စုစုပေါင်း စာကြောင်း ၁၀ကြောင်းအနေနဲ့ generate လုပ်ပေးသွားပါလိမ့်မယ်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a181e5c-7b17-4f6f-b6ee-ec71c4cf229a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ye/exp/name-lm/lib/laphet.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Generated Text 1: ရဲ ကွမ်း ကိန်း မြန် မြန် ထား ထား ဇ မြန် မြန် ချက်စ် မြန် ထား ကွမ်း ကိန်း ချက်စ် ထား မြန် မြန် မြန် မြန် သဉ္ဇ ကိန်း ဆိုက် ထား ကွမ်း ချက်စ် ချက်စ် သဉ္ဇ ကိန်း မြန် ထား မြန် မြန် ထား ချက်စ် ထား မြန် မြန် ဇ ထား ထား မြန် ချက်စ် ကိန်း ထား ကိန်း ကွမ်း မြန် ကိန်း ဇ\n",
      "Generated Text 2: ရဲ မြန် ကွမ်း ကိန်း မြန် မြန် မြန် မြန် သဉ္ဇ ထား မြန် ကိန်း ကွမ်း ကွမ်း မြန် မြန် ဇ ကိန်း ဆိုက် ကိန်း ဇ မြန် မြန် ကွမ်း မြန် ကိန်း ဇ မြန် မြန် မြန် ချက်စ် ကွမ်း ကိန်း ဆိုက် ချက်စ် ကိန်း ကိန်း မြန် ကိန်း မြန် ကိန်း မြန် ချက်စ် ချက်စ် မြန် ဇ ဇ ထား ချက်စ် မြန် မြန်\n",
      "Generated Text 3: ရဲ မြန် ကွမ်း သဉ္ဇ မြန် ကွမ်း ကွမ်း ချက်စ် ကိန်း ဇ ကိန်း မြန် မြန် ဇ မြန် မြန် သဉ္ဇ ဇ သဉ္ဇ မြန် ထား ကိန်း ဆိုက် ချက်စ် မြန် မြန် ဇ ကိန်း ကိန်း ကိန်း ချက်စ် ချက်စ် ထား ကိန်း ချက်စ် သဉ္ဇ ဇ မြန် မြန် ထား သဉ္ဇ မြန် မြန် ကိန်း ကိန်း ကိန်း ကိန်း ကိန်း ကိန်း မြန် ကိန်း\n",
      "Generated Text 4: ရဲ ကွမ်း ထား မြန် ကိန်း မြန် မြန် ဇ ထား မြန် ကွမ်း ကိန်း ကိန်း ကိန်း ကိန်း မြန် ချက်စ် ကိန်း ထား မြန် ကိန်း မြန် ကိန်း ကိန်း ဇ ကိန်း မြန် ကိန်း ကိန်း မြန် မြန် ထား ထား ကိန်း ကိန်း ဇ မြန် ကိန်း ထား ထား မြန် ထား မြန် ကိန်း ထား မြန် ကိန်း ဇ မြန် မြန် သဉ္ဇ\n",
      "Generated Text 5: ရဲ သဉ္ဇ ထား မြန် ကိန်း ထား မြန် ထား ကိန်း သဉ္ဇ မြန် သဉ္ဇ သဉ္ဇ ကိန်း ကိန်း ချက်စ် ချက်စ် မြန် မြန် ထား မြန် ကိန်း ဇ မြန် မြန် ဇ ဇ သဉ္ဇ မြန် မြန် မြန် ဇ ကိန်း သဉ္ဇ ကိန်း ထား ကိန်း မြန် မြန် ထား မြန် ထား မြန် ကွမ်း မြန် ထား ဆိုက် ထား မြန် ချက်စ် ကိန်း\n",
      "Generated Text 6: ရဲ ကွမ်း ကိန်း မြန် ကိန်း ထား မြန် မြန် မြန် မြန် ကိန်း မြန် မြန် ဇ ကွမ်း ထား ဇ ကိန်း မြန် ကွမ်း မြန် ဇ ဇ သဉ္ဇ ကွမ်း ကွမ်း ဇ ကိန်း ကိန်း ကိန်း ကိန်း မြန် မြန် ကိန်း မြန် မြန် သဉ္ဇ ကိန်း ကိန်း မြန် မြန် မြန် ထား ချက်စ် ထား ကိန်း ဇ ထား ဇ မြန် ကိန်း\n",
      "Generated Text 7: ရဲ မြန် ဆိုက် မြန် ဇ ဇ မြန် သဉ္ဇ ထား ဇ ချက်စ် သဉ္ဇ ဇ မြန် ဇ ချက်စ် ကိန်း ကွမ်း ထား မြန် မြန် မြန် ကိန်း မြန် ထား မြန် မြန် ကွမ်း သဉ္ဇ သဉ္ဇ မြန် ဆိုက် ဇ ကွမ်း သဉ္ဇ ကိန်း ဆိုက် မြန် ဇ မြန် ထား ကွမ်း သဉ္ဇ မြန် မြန် ကွမ်း ဇ ထား ဇ သဉ္ဇ ကွမ်း\n",
      "Generated Text 8: ရဲ ထား ကိန်း မြန် ဇ ကိန်း ဇ မြန် ကိန်း ထား သဉ္ဇ ဆိုက် ထား မြန် ကိန်း မြန် ဇ ထား ကွမ်း ဇ ကိန်း ချက်စ် ကိန်း ထား မြန် သဉ္ဇ ကိန်း ထား မြန် ထား ကွမ်း မြန် ချက်စ် သဉ္ဇ ကိန်း မြန် ကွမ်း ထား သဉ္ဇ သဉ္ဇ သဉ္ဇ မြန် မြန် ထား ကိန်း ဆိုက် ကွမ်း မြန် ကိန်း ကိန်း ထား\n",
      "Generated Text 9: ရဲ ချက်စ် ဇ ကိန်း မြန် မြန် ကိန်း ကိန်း ထား ကိန်း ကိန်း မြန် မြန် ဇ ကိန်း ကိန်း မြန် မြန် မြန် ဇ မြန် ဇ မြန် ထား သဉ္ဇ ကွမ်း ချက်စ် သဉ္ဇ ကွမ်း ကိန်း ထား ထား ထား ဇ ဇ ချက်စ် ထား ချက်စ် မြန် မြန် ကိန်း ဇ ဇ ထား ဇ ထား မြန် ကွမ်း ကိန်း ချက်စ် ထား\n",
      "Generated Text 10: ရဲ ချက်စ် မြန် မြန် ထား ကိန်း ထား ကိန်း ကိန်း မြန် မြန် မြန် ထား မြန် ကွမ်း ကိန်း ဇ ထား ကိန်း ကိန်း ကိန်း မြန် မြန် သဉ္ဇ ကွမ်း ထား မြန် ကိန်း ထား ကိန်း ထား ကိန်း မြန် မြန် မြန် ကိန်း ကိန်း မြန် ကိန်း မြန် မြန် ကိန်း မြန် ချက်စ် ဆိုက် ကိန်း ကွမ်း ထား ချက်စ် ဇ မြန်\n",
      "\n",
      "real\t0m1.649s\n",
      "user\t0m3.912s\n",
      "sys\t0m0.249s\n"
     ]
    }
   ],
   "source": [
    "!time python laphet.py --model_type bilstm --generate --model ./model/name/bilstm.model \\\n",
    "--seq_len 50 --prompt \"ရဲ\" --no_of_generation 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02be845-1f91-46ab-a24b-278db20882ef",
   "metadata": {},
   "source": [
    "## Text Generation with Start-Word Input File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ff4474a-16cc-4954-8291-403e94c206fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ye/exp/name-lm/lib/laphet.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Random Prompt Generated: ကြား\n",
      "Generated texts saved to ./output/name/bilstm_gen_texts.txt\n",
      "\n",
      "real\t0m1.503s\n",
      "user\t0m3.726s\n",
      "sys\t0m0.280s\n"
     ]
    }
   ],
   "source": [
    "!time python laphet.py --model_type bilstm --generate --model ./model/name/bilstm.model \\\n",
    "--seq_len 2 --input ./data/myRoman/start_names.txt --no_of_generation 5 --output ./output/name/bilstm_gen_texts.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df0e072f-e626-4b36-8e0e-786a59e33891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ကျော် ကိန်း မြန်\n",
      "ကျော် မြန် မြန်\n",
      "ကျော် ထား မြန်\n",
      "ကျော် ကိန်း ထား\n",
      "ကျော် မြန် မြန်\n",
      "မ မ ချက်စ် ထား\n",
      "မ မ မြန် ထား\n",
      "မ မ သဉ္ဇ ချက်စ်\n",
      "မ မ ချက်စ် ထား\n",
      "မ မ ကိန်း ကိန်း\n",
      "အေး မြန် ကိန်း\n",
      "အေး မြန် မြန်\n",
      "အေး မြန် မြန်\n",
      "အေး ကိန်း မြန်\n",
      "အေး မြန် ကိန်း\n",
      "လှ လှ ဇ မြန်\n",
      "လှ လှ ဇ မြန်\n",
      "လှ လှ ချက်စ် ကွမ်း\n",
      "လှ လှ ကိန်း သဉ္ဇ\n",
      "လှ လှ ဆိုက် ချက်စ်\n",
      "ကြား ဆိုက် မြန်\n",
      "ကြား ထား ဇ\n",
      "ကြား ဆိုက် သဉ္ဇ\n",
      "ကြား ဇ ထား\n",
      "ကြား ချက်စ် ချက်စ်\n",
      "မြ အေး မြန် မြန်\n",
      "မြ အေး မြန် ထား\n",
      "မြ အေး မြန် မြန်\n",
      "မြ အေး မြန် မြန်\n",
      "မြ အေး မြန် ဇ\n",
      "သ မြန် ချက်စ်\n",
      "သ ဇ မြန်\n",
      "သ သဉ္ဇ ထား\n",
      "သ မြန် ချက်စ်\n",
      "သ ချက်စ် ဇ\n",
      "မောင် ချက်စ် ဇ\n",
      "မောင် ကွမ်း ကွမ်း\n",
      "မောင် ကိန်း မြန်\n",
      "မောင် ချက်စ် သဉ္ဇ\n",
      "မောင် ကိန်း ဇ\n",
      "မြင့် မြင့် ဆိုက် သဉ္ဇ\n",
      "မြင့် မြင့် ထား ကွမ်း\n",
      "မြင့် မြင့် ဇ ဇ\n",
      "မြင့် မြင့် ထား ကိန်း\n",
      "မြင့် မြင့် ကွမ်း ကိန်း\n",
      "ရွှေ မြန် မြန်\n",
      "ရွှေ သဉ္ဇ ထား\n",
      "ရွှေ သဉ္ဇ ဇ\n",
      "ရွှေ ထား ဆိုက်\n",
      "ရွှေ ဆိုက် ဇ\n",
      "အဂ္ဂ ကိန်း ကွမ်း\n",
      "အဂ္ဂ သဉ္ဇ ချက်စ်\n",
      "အဂ္ဂ ကိန်း ချက်စ်\n",
      "အဂ္ဂ ဇ ဇ\n",
      "အဂ္ဂ ထား မြန်\n",
      "ဥက္ကာ မြန် ကိန်း\n",
      "ဥက္ကာ ကိန်း ဇ\n",
      "ဥက္ကာ ဆိုက် ထား\n",
      "ဥက္ကာ ဇ ကိန်း\n",
      "ဥက္ကာ ကွမ်း ဆိုက်\n",
      "သိင်္ဂီ ဇ ကိန်း\n",
      "သိင်္ဂီ ချက်စ် မြန်\n",
      "သိင်္ဂီ သဉ္ဇ မြန်\n",
      "သိင်္ဂီ ဆိုက် ဇ\n",
      "သိင်္ဂီ ချက်စ် ဇ\n",
      "မေ ဆိုက် ဆိုက်\n",
      "မေ သဉ္ဇ ကိန်း\n",
      "မေ ဆိုက် ဇ\n",
      "မေ ဇ ကိန်း\n",
      "မေ မြန် မြန်\n",
      "ခိုင် ကွမ်း ကိန်း\n",
      "ခိုင် မြန် ချက်စ်\n",
      "ခိုင် ကိန်း ကွမ်း\n",
      "ခိုင် မြန် မြန်\n",
      "ခိုင် ကိန်း မြန်\n"
     ]
    }
   ],
   "source": [
    "!cat ./output/name/bilstm_gen_texts.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90b3e5fc-9af0-472a-b06f-219ea883e434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  75  245 3026 ./output/name/bilstm_gen_texts.txt\n"
     ]
    }
   ],
   "source": [
    "!wc ./output/name/bilstm_gen_texts.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43f9cf7-f17f-479c-bf3a-6f3dc341cba1",
   "metadata": {},
   "source": [
    "## Testing/Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf7084e2-528b-4b7d-9a22-befe1a5a8b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ye/exp/name-lm/lib/laphet.py:216: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Testing: 100%|██████████████████████████████████| 16/16 [00:00<00:00, 40.66it/s]\n",
      "Average Perplexity on Test Data: 1.0314\n",
      "Average Cross-Entropy on Test Data: 0.0309\n",
      "\n",
      "real\t0m1.534s\n",
      "user\t0m3.799s\n",
      "sys\t0m0.253s\n"
     ]
    }
   ],
   "source": [
    "!time python laphet.py --model_type bilstm --test --model ./model/name/bilstm.model \\\n",
    "--test_file ./data/myRoman/test_name.txt --seq_len 50 --batch_size 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded6a616-596c-4ae1-8a88-65681aa81eb8",
   "metadata": {},
   "source": [
    "# Transformer based Language Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dd9ff4-f462-4049-9dc2-e703cf046731",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8756e6df-f9c9-418d-95e8-ff55b66239a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 194.39it/s]\n",
      "Epoch 1, Training Loss: 0.2378\n",
      "Epoch 1/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 589.61it/s]\n",
      "Epoch 1, Validation Loss: 0.0437\n",
      "Best model saved at ./model/name/transformer.model with validation loss: 0.0437\n",
      "Epoch 2/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 208.26it/s]\n",
      "Epoch 2, Training Loss: 0.0290\n",
      "Epoch 2/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 592.74it/s]\n",
      "Epoch 2, Validation Loss: 0.0211\n",
      "Best model saved at ./model/name/transformer.model with validation loss: 0.0211\n",
      "Epoch 3/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 209.82it/s]\n",
      "Epoch 3, Training Loss: 0.0151\n",
      "Epoch 3/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 589.92it/s]\n",
      "Epoch 3, Validation Loss: 0.0135\n",
      "Best model saved at ./model/name/transformer.model with validation loss: 0.0135\n",
      "Epoch 4/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 204.99it/s]\n",
      "Epoch 4, Training Loss: 0.0096\n",
      "Epoch 4/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 592.68it/s]\n",
      "Epoch 4, Validation Loss: 0.0096\n",
      "Best model saved at ./model/name/transformer.model with validation loss: 0.0096\n",
      "Epoch 5/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 206.21it/s]\n",
      "Epoch 5, Training Loss: 0.0066\n",
      "Epoch 5/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 594.08it/s]\n",
      "Epoch 5, Validation Loss: 0.0073\n",
      "Best model saved at ./model/name/transformer.model with validation loss: 0.0073\n",
      "Epoch 6/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 208.00it/s]\n",
      "Epoch 6, Training Loss: 0.0046\n",
      "Epoch 6/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 599.08it/s]\n",
      "Epoch 6, Validation Loss: 0.0057\n",
      "Best model saved at ./model/name/transformer.model with validation loss: 0.0057\n",
      "Epoch 7/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 205.97it/s]\n",
      "Epoch 7, Training Loss: 0.0033\n",
      "Epoch 7/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 585.32it/s]\n",
      "Epoch 7, Validation Loss: 0.0048\n",
      "Best model saved at ./model/name/transformer.model with validation loss: 0.0048\n",
      "Epoch 8/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 208.66it/s]\n",
      "Epoch 8, Training Loss: 0.0024\n",
      "Epoch 8/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 586.48it/s]\n",
      "Epoch 8, Validation Loss: 0.0042\n",
      "Best model saved at ./model/name/transformer.model with validation loss: 0.0042\n",
      "Epoch 9/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 208.47it/s]\n",
      "Epoch 9, Training Loss: 0.0017\n",
      "Epoch 9/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 558.75it/s]\n",
      "Epoch 9, Validation Loss: 0.0039\n",
      "Best model saved at ./model/name/transformer.model with validation loss: 0.0039\n",
      "Epoch 10/10 (Training): 100%|████████████████| 852/852 [00:04<00:00, 206.31it/s]\n",
      "Epoch 10, Training Loss: 0.0012\n",
      "Epoch 10/10 (Validation): 100%|████████████████| 32/32 [00:00<00:00, 592.65it/s]\n",
      "Epoch 10, Validation Loss: 0.0037\n",
      "Best model saved at ./model/name/transformer.model with validation loss: 0.0037\n",
      "\n",
      "real\t0m43.555s\n",
      "user\t0m45.178s\n",
      "sys\t0m0.360s\n"
     ]
    }
   ],
   "source": [
    "!time python laphet.py --model_type transformer --train --data ./data/myRoman/train_name.txt \\\n",
    "--dev_file ./data/myRoman/dev_name.txt --model ./model/name/transformer.model --seq_len 50 --epochs 10 --batch_size 32 --lr 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245709b3-4251-44bd-b3bb-2d47739e1c8d",
   "metadata": {},
   "source": [
    "မော်ဒယ် အမျိုးအစားပေါ်ကို မူတည်ပြီးတော့ training လုပ်တဲ့အခါမှာ ကြာချိန်က တူမှာ မဟုတ်ပါဘူး။ လက်ရှိမှာ နာမည်ဒေတာမို့လို့ တကယ်က စာကြောင်းအနေနဲ့ တိုပါတယ်။ ပြီးတော့ သုံးထားတဲ့ GPU အမျိုးအစားနဲ့ memory အပေါ်မှာလည်း မူတည်ပါလိမ့်မယ်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd74aa78-2b25-4d65-9781-78492f29f02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ye ye 11M Jan 27 01:26 ./model/name/transformer.model\n",
      "-rw-rw-r-- 1 ye ye 24K Jan 27 01:25 ./model/name/transformer.model.vocab\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ./model/name/transformer.model*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083cc0e7-cb02-4f27-aa0c-0d855dec84bf",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f61592e4-2e4e-41a7-a448-8de88d8263a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ye/exp/name-lm/lib/laphet.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Generated Text 1: ရဲ ဋာ သိင်္ဂီ စေး ငိုက် ညို ခဲ ဖေ ဆောင် ဖေ ရှာ ကွန်း မြက် နက် ဖေ ယန်း ဖေ ဿဏ် ဖေ တိန်း ဖေ ဒေး ဖေ အိမ္ဗာ ကွန်း အုန်း ငိုင် မော် ချို ဟမ် ဖေ စောမ် မော် ဗိုင်း မော် ကွေ ဆွင်း သုဒ္ဓေါ တက္ခ ဖေ ဇာ ကက် မော် ရှင်း ပေါ် မော် ထွတ် ဖေ ခက် နစ် ဖေ\n",
      "Generated Text 2: ရဲ ဟန် လှဲန် ဖေ မဲန်း ဆွင်း ဖေ ဟင် မော် ကျေး ဆွင်း ဖေ ဖေ ငြိမ့် ဖေ မုန် ဖေ ဝေ ရေ့စ် ဖေ ချေ ကွာ မော် ဂျန် ဖေ ဋာ ဖေ ဖေ ဟူ ဖေ စိုး စိုး သစ္စာ ဿီ ဖေ စွမ်း ဖေ စန်း မဲန် ဖေ ဗင် ဖေ မြတ် ဖေ သန့် ဆန္ဒ ဆွင်း ဖေ အိန္ဒြ ဖေ ယူ\n",
      "Generated Text 3: ရဲ ချိန်း ဖေ ဝန် ဖေ တန် ကွမ် ဖေ နူး သိဓ္ဓတ် ဆွင်း ကွန်း အစ် ဟီး ဖေ ချို ကွာ မော် မျှော် ဖေ လှောင် စွမ်း မာ့ စွမ်း အူရ် မော် မန်း ဖေ ထွေ ဘွမ် တက္ခ ဖေ လမ့် မော် ငိုင် ဖေ စွန် မော် နမ် စွမ်း ဖေ ဖေ တိန့် တက္ခ ကွန်း သျွှန်း ဖေ နန္ဒ သွန်း ပြီး ဖေ\n",
      "Generated Text 4: ရဲ ရီ စော ဗျော ကွန်း ဧ ပြီ ဖေ ကြိုက် ဖေ အိဏ် ဖေ ဖေ မဲန် သုဒ္ဓေါ ဖေ သဒ္ဓါ ဘု ဖေ ဖုံး ဖေ ထွေ ဖေ ဟြေ ဆွင်း ဘွမ် ကွန်း ပုမ်း စွမ်း ဟောမ်း မော် ငြိမ်း ညု မော် ပျံ့ ဖေ စည် နတ် ဖေ လဲန်း ဘွမ် စွမ်း ဖေ ကြိုင် ဖေ ဂျူး မ ယော စွမ်း တောက် ဖေ\n",
      "Generated Text 5: ရဲ ရေ့စ် ဖေ ရှု နူး ဝံ လစ် ဖေ ရှိန် စည်း စွမ်း ဘွဲ ဖေ အာရ် ကွန်း ဖိန် ဘွမ် ဘွမ် ဆွင်း ဖေ ဖော် ဘွမ် ဆွင်း ဖေ ဘယ်လ် ရှား ဖေ ဖေ ကျော် ဂန္ဓာ မော် ဘောမ် မော် အဲမ် ဖေ မြတ် ရိန်း ဆွင်း ဖေ ကုန် မော် ဗား စွမ်း မဲ့ ဖေ အိန္ဓု စွမ်း ဖေ နိုင်း တု ဖေ\n",
      "Generated Text 6: ရဲ ခမ်း ဘက် ဖူ ဒွပ် တက္ခ စွမ်း ကုန် ဖေ ခန် ဖေ ဟမ်း ဖေ ရဲ ဘူး ဖေ ဘေး သုဒ္ဓေါ မော် ဘွယ် ဖေ ပြား တက္ခ တက္ခ ကွန်း ယယ် ဖေ ဖေ အာ ဖေ ငိုက် မော် ကွေ့ ဖေ အဲန်း ဖေ ပြောင်း သုဒ္ဓေါ ကွန်း ဖေ လွန်း ဖေ မံ ဖေ အဉ္စ ကျုံ ဖေ ရှိုင်းန်း မော် ကျဲ စွမ်း\n",
      "Generated Text 7: ရဲ သန္ဒြာ ဖေ ဖေ ရင့် လို့ ဖေ လွန် ဆုန်း ကွန်း ကျွန် တက္ခ ဖေ ဂျတ် စွမ်း တေ့ ဖေ သင်း ကေး စွမ်း ဒိမ်း ဖေ ပြီ မော် ကျွန် ကွန်း ဖေ ဖေ ကျွန် ဖေ ကုန် ဖေ ဖွား မော် ဆေး ဆွင်း မော် လှဲန် တက္ခ ဖေ ခမ့် စွမ်း ဖေ နှိုင်း ဖေ ကျေ ဖေ ကွီး မော် နာ့ ဖေ\n",
      "Generated Text 8: ရဲ အဲ လျှို ဖေ ခက်ခ် ဖေ မြို့ မောက် ဖေ ဏိ ဖေ ဆောမ်း ဆွင်း စွမ်း ဖေ သန် မျာ ဖေ လဲန်း ဖေ သျှံ မော် သိင်္ခ ဆွင်း မော် သွင့် သုဒ္ဓေါ မော် ကြိုင် ဖေ ဒုလ် တက္ခ သုဒ္ဓေါ တက္ခ ကွန်း ဖေ နိုင်း ဂျာ ကမ္ဘာ ဖေ ဘက် ဖေ ကျီး ဆွင်း ကွန်း ဘုတ် ဖေ ဂျ ဖေ စွယ် ဖေ\n",
      "Generated Text 9: ရဲ လာမ် အက် မော် ဒွပ် ဖေ ဂွမ် ဖေ ဝုန် ကျုံ ဖေ ထွဋ် မှုန် ဖေ ဇန် လျန် သီး မော် လိမ်း မော် ဓိ ဆွင်း မော် ရင် လန်း ဖေ ဆမ်း မော် ဟယ် မော် သျှန်း ဖေ အော် ဖေ နည် ဟုမ် ဖေ ယော ဖေ တော် ဒေါ ဖေ လောင်း စွမ်း ဖေ မှာ စွမ်း ဖေ အိမ့် ဖေ ပီ\n",
      "Generated Text 10: ရဲ စံ အဲမ် ဖေ လီ ဆွတ် စွမ်း ဒူး ဟိဏ်း ဖေ လှီး မော် ယတ် ဖေ ညွှန်း ကွန်း ရာဇ် ဆွင်း စွမ်း ဖေ ဇွန် တွန်း ဖေ ငြား ဖေ ပေါ် ဖေ ဖေ လွမ်း ဖေ လဲန်း ဆွင်း သုဒ္ဓေါ သုဒ္ဓေါ ဖေ ဒီ မြ ထိန် ဖေ မြက် ဟ လိုင်း ဖေ လိမ္မာ ဖေ သိမ့် ဖေ လဲ့ ကြို ဆွင်း မော်\n",
      "\n",
      "real\t0m1.897s\n",
      "user\t0m4.155s\n",
      "sys\t0m0.240s\n"
     ]
    }
   ],
   "source": [
    "!time python laphet.py --model_type transformer --generate --model ./model/name/transformer.model \\\n",
    "--seq_len 50 --prompt \"ရဲ\" --no_of_generation 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99afc8d0-bc9a-44fb-a889-35b6a3aba7bd",
   "metadata": {},
   "source": [
    "Transformer based LM ရဲ့ text generation ဥပမာတချို့ကတော့ အထက်မှာ မြင်ရတဲ့ အတိုင်းပါပဲ။  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1979a166-e6a5-41cf-ba29-8ba736b5df71",
   "metadata": {},
   "source": [
    "## Text Generation with Start-Word Input File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54738ee7-d9ba-4a7d-9aa2-f56c9f8d3417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ye/exp/name-lm/lib/laphet.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Random Prompt Generated: ခွါ\n",
      "Generated texts saved to ./output/name/transformer_gen_texts.txt\n",
      "\n",
      "real\t0m1.465s\n",
      "user\t0m3.738s\n",
      "sys\t0m0.214s\n"
     ]
    }
   ],
   "source": [
    "!time python laphet.py --model_type transformer --generate --model ./model/name/transformer.model \\\n",
    "--seq_len 2 --input ./data/myRoman/start_names.txt --no_of_generation 5 --output ./output/name/transformer_gen_texts.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802d288d-4e78-44c4-9fa7-a357a4cc052d",
   "metadata": {},
   "source": [
    "--output option သုံးပြီးတော့ ထွက်လာတဲ့ generated sentence တွေကို ဖိုင်ထဲမှာ သိမ်းခိုင်းထားတာမို့လို့ အဲဒီဖိုင်ကို cat command နဲ့ ရိုက်ထုတ်ပြခိုင်းပြီး ဘယ်လို စာကြောင်းတွေ ထွက်လာသလဲ ဆိုတာကို လေ့လာကြည့်ကြရအောင်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "acf0b272-e2ab-4dbb-a5cc-a8efbc1050c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ကျော် အဏ္ဏ ခွာ\n",
      "ကျော် ရူ ထင်\n",
      "ကျော် ခေါမ် ဆုံး\n",
      "ကျော် စဉ့် ဖေ\n",
      "ကျော် လစ် လောင်း\n",
      "မ မ ဝိန် တက္ခ\n",
      "မ မ ငဲ ဖေ\n",
      "မ မ ဖာ နောင့်\n",
      "မ မ လိန်း အွန်\n",
      "မ မ ဟွေ ကွန်း\n",
      "အေး နံ့ ဘောမ်\n",
      "အေး လိမ်း ဖေ\n",
      "အေး သန် အ\n",
      "အေး ထွတ် ရေ့စ်\n",
      "အေး သား ယား\n",
      "လှ လှ သေ့ တက္ခ\n",
      "လှ လှ ရဲ ဟမ်\n",
      "လှ လှ နှစ် ချင်း\n",
      "လှ လှ ရာဇ် ရွန်း\n",
      "လှ လှ နောင့် သျှင်\n",
      "ခွါ ဖေ အောင်\n",
      "ခွါ ဖေ မောက်\n",
      "ခွါ ဖေ သောင်း\n",
      "ခွါ ဖေ ဝင်\n",
      "ခွါ ဖေ လာန်\n",
      "မြ အေး ယာ နဲမ်\n",
      "မြ အေး ဦး မင်\n",
      "မြ အေး လွှမ်း ဧ\n",
      "မြ အေး ဆု ဘွိုင်\n",
      "မြ အေး ဿာ ဖေ\n",
      "သ ဋာ ဘု\n",
      "သ ဖျား တွေး\n",
      "သ ကျီး ဖေ\n",
      "သ ဣန္တာ မော်\n",
      "သ သင်္ကြန် သိုက်\n",
      "မောင် ကျူ မိုင်းလ်\n",
      "မောင် လမ့် ကစ်\n",
      "မောင် ဒန့် ဖေ\n",
      "မောင် အံ ဖေ\n",
      "မောင် ခေါင် တောင်း\n",
      "မြင့် မြင့် တက္ခ ဖေ\n",
      "မြင့် မြင့် ကျိမ်း တက္ခ\n",
      "မြင့် မြင့် အုတ် ဖေ\n",
      "မြင့် မြင့် ခေါ်လ် မော်\n",
      "မြင့် မြင့် လက္ခ ဖေ\n",
      "ရွှေ စန္ဒီ ကွေး\n",
      "ရွှေ ရှာ ဆွမ့်\n",
      "ရွှေ ယိန်း မွိုင်\n",
      "ရွှေ ဈာန် ဝါ\n",
      "ရွှေ စီ ညွန်\n",
      "အဂ္ဂ နဲ ဖေ\n",
      "အဂ္ဂ သျှ ဖေ\n",
      "အဂ္ဂ မြေး ဖေ\n",
      "အဂ္ဂ ဖိုး ခွေး\n",
      "အဂ္ဂ ဆမ်း ဖေ\n",
      "ဥက္ကာ ကမ် ထန်း\n",
      "ဥက္ကာ ဖီး ဟတ်\n",
      "ဥက္ကာ ဂျိမ်းစ် ဖေ\n",
      "ဥက္ကာ ရိုး တီး\n",
      "ဥက္ကာ ကြည့် ဖေ\n",
      "သိင်္ဂီ တုံ ရှဲမ်း\n",
      "သိင်္ဂီ ဘိုင် ဘွမ်\n",
      "သိင်္ဂီ လွေ ဖေ\n",
      "သိင်္ဂီ အိန္ဒု ဂျို\n",
      "သိင်္ဂီ ယန်း ရုဏ်း\n",
      "မေ ကျန်း အက္ခ\n",
      "မေ သော့ခ် ဖေ\n",
      "မေ သို ဖေ\n",
      "မေ စင်း ကွန်း\n",
      "မေ ချိုး ဖေ\n",
      "ခိုင် ပြောင်း တက္ခ\n",
      "ခိုင် စက်ဖ် ထောင်း\n",
      "ခိုင် မို့ ဆင့်\n",
      "ခိုင် ဖော် ဖေ\n",
      "ခိုင် ကီ လွဲ\n"
     ]
    }
   ],
   "source": [
    "!cat ./output/name/transformer_gen_texts.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7101c6dd-e6b3-4df1-8e14-1b87867d3cb8",
   "metadata": {},
   "source": [
    "## Testing/Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4ea2154e-7f50-41a6-bf8e-7b430d20de09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ye/exp/name-lm/lib/laphet.py:216: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Testing: 100%|██████████████████████████████████| 16/16 [00:00<00:00, 47.31it/s]\n",
      "Average Perplexity on Test Data: 1.0037\n",
      "Average Cross-Entropy on Test Data: 0.0037\n",
      "\n",
      "real\t0m1.302s\n",
      "user\t0m3.627s\n",
      "sys\t0m0.214s\n"
     ]
    }
   ],
   "source": [
    "!time python laphet.py --model_type transformer --test --model ./model/name/transformer.model \\\n",
    "--test_file ./data/myRoman/test_name.txt --seq_len 50 --batch_size 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb84c34f-0807-47a7-9c0d-cdd33213fc3c",
   "metadata": {},
   "source": [
    "## BERT based Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c855d88-d57f-4bc2-8d5e-4ef2af408b40",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4f87f05-102c-423e-8f83-198d89482ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 192.73it/s]\n",
      "Epoch 1, Training Loss: 0.2482\n",
      "Epoch 1/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 588.18it/s]\n",
      "Epoch 1, Validation Loss: 0.0448\n",
      "Best model saved at ./model/name/bert.model with validation loss: 0.0448\n",
      "Epoch 2/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 210.17it/s]\n",
      "Epoch 2, Training Loss: 0.0292\n",
      "Epoch 2/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 608.11it/s]\n",
      "Epoch 2, Validation Loss: 0.0217\n",
      "Best model saved at ./model/name/bert.model with validation loss: 0.0217\n",
      "Epoch 3/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 210.53it/s]\n",
      "Epoch 3, Training Loss: 0.0151\n",
      "Epoch 3/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 597.23it/s]\n",
      "Epoch 3, Validation Loss: 0.0139\n",
      "Best model saved at ./model/name/bert.model with validation loss: 0.0139\n",
      "Epoch 4/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 210.04it/s]\n",
      "Epoch 4, Training Loss: 0.0095\n",
      "Epoch 4/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 597.55it/s]\n",
      "Epoch 4, Validation Loss: 0.0100\n",
      "Best model saved at ./model/name/bert.model with validation loss: 0.0100\n",
      "Epoch 5/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 203.54it/s]\n",
      "Epoch 5, Training Loss: 0.0065\n",
      "Epoch 5/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 598.52it/s]\n",
      "Epoch 5, Validation Loss: 0.0076\n",
      "Best model saved at ./model/name/bert.model with validation loss: 0.0076\n",
      "Epoch 6/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 204.71it/s]\n",
      "Epoch 6, Training Loss: 0.0046\n",
      "Epoch 6/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 592.29it/s]\n",
      "Epoch 6, Validation Loss: 0.0062\n",
      "Best model saved at ./model/name/bert.model with validation loss: 0.0062\n",
      "Epoch 7/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 207.63it/s]\n",
      "Epoch 7, Training Loss: 0.0033\n",
      "Epoch 7/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 583.63it/s]\n",
      "Epoch 7, Validation Loss: 0.0052\n",
      "Best model saved at ./model/name/bert.model with validation loss: 0.0052\n",
      "Epoch 8/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 208.42it/s]\n",
      "Epoch 8, Training Loss: 0.0024\n",
      "Epoch 8/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 591.73it/s]\n",
      "Epoch 8, Validation Loss: 0.0047\n",
      "Best model saved at ./model/name/bert.model with validation loss: 0.0047\n",
      "Epoch 9/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 208.33it/s]\n",
      "Epoch 9, Training Loss: 0.0017\n",
      "Epoch 9/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 585.64it/s]\n",
      "Epoch 9, Validation Loss: 0.0044\n",
      "Best model saved at ./model/name/bert.model with validation loss: 0.0044\n",
      "Epoch 10/10 (Training): 100%|████████████████| 852/852 [00:04<00:00, 210.45it/s]\n",
      "Epoch 10, Training Loss: 0.0011\n",
      "Epoch 10/10 (Validation): 100%|████████████████| 32/32 [00:00<00:00, 601.57it/s]\n",
      "Epoch 10, Validation Loss: 0.0042\n",
      "Best model saved at ./model/name/bert.model with validation loss: 0.0042\n",
      "\n",
      "real\t0m43.480s\n",
      "user\t0m45.019s\n",
      "sys\t0m0.384s\n"
     ]
    }
   ],
   "source": [
    "!time python laphet.py --model_type bert --train --data ./data/myRoman/train_name.txt \\\n",
    "--dev_file ./data/myRoman/dev_name.txt --model ./model/name/bert.model --seq_len 50 --epochs 10 --batch_size 32 --lr 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd333c50-a1ed-4c2f-aac5-126f6aa090c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ye ye 11M Jan 27 01:39 ./model/name/bert.model\n",
      "-rw-rw-r-- 1 ye ye 24K Jan 27 01:38 ./model/name/bert.model.vocab\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ./model/name/bert*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af5b40b-472d-4723-be32-b25511ce48e6",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dc230982-4f76-4482-8843-99c1b5e4659c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ye/exp/name-lm/lib/laphet.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Generated Text 1: ရဲ ဘွယ် အဲင်း ချူး ခြူး ဖူ နန်းဒ် ဿ ချူး ချူး ချူး ချူး ချူး ချူး ဂိမ်း ဓ ချူး ချူး ချူး ချူး ကျိန်း ချူး ချူး ချူး နှဲမ်း ချူး ဿ ဿ ရဲ လျင် ကျိန်း ချူး ချူး နှဲမ်း ချူး ချူး ချူး နှဲမ်း ချူး ဿ ကျိန်း ကျိန်း ချူး ချူး ချူး ချူး ချူး ချူး ချူး ချူး နှဲမ်း\n",
      "Generated Text 2: ရဲ စု နောင် ဓု စန်း ဖုန် ချူး မျာ ရှိုး ချူး ဿ ချူး ချူး ကျိန်း ဂိမ်း ကြည့် ဿ ချူး ချူး ချူး ဿ ချူး နှဲမ်း ချူး ချူး ချူး ချူး နှဲမ်း ချူး ချူး ချူး နှဲမ်း ချူး ချူး ဿ ချူး ချူး ချူး ဿ ချူး ချူး ချူး အူရ် ကျိန်း ဿ ချူး ချူး ချူး ချူး ချူး ချူး\n",
      "Generated Text 3: ရဲ ကြွ စန္ဒီ မွင်း နိုး တုန် ကျူး ကျိန်း ရှိုး ချူး ချူး ချူး ချူး ကျိန်း ဿ နှဲမ်း ငြိမ် ရဲ အဉ္စ ချူး ဿ ချူး ဿ ချူး ချူး ချူး နှဲမ်း ချူး ချူး ချူး ချူး ဂိမ်း ခြယ် ချူး ဿ ချူး ချူး ချူး ချူး ဂိမ်း ချူး ချူး နောင် မို့ ချူး ချူး ချူး ချူး ဿ ချူး ချူး\n",
      "Generated Text 4: ရဲ ခန်း ဂန္ဓာ ချူး ပွား ဘင်း ချူး ကြော ချူး ဂိမ်း အာ ချူး ချူး နှဲမ်း ဒေါ ချူး နှဲမ်း ချက်ထ် နှဲမ်း ချူး နှဲမ်း ချူး နှဲမ်း ချူး ချူး ချူး ဂိမ်း ကျိမ်း ချူး ချူး ချူး ကျိန်း ကျိန်း ချူး ချူး ချူး ကျိန်း ဿ ချူး ချူး ချူး ချူး ဘာ သိန်း ရု ရဲ လိမ်း ကျိန်း ရဲ စုံ ကပ်\n",
      "Generated Text 5: ရဲ ဒြာ ညှာ ယွန်း စန် ကော် မ နို ဌေး ရွှေ သော် ချူး ချူး ချူး ကျိန်း ရှိုး နှဲမ်း သိုင်း ချူး ချူး ချူး ကျိန်း ဂိမ်း ခန့် စို ရဲ ကြေး ဂိမ်း ချောင်း နှဲမ်း ချူး ချူး ချူး ချူး ဿ ချူး ချူး ချူး နှဲမ်း ချူး ချူး ချူး ဇဉ် ချူး ချူး နှဲမ်း ချူး ချူး ချူး ချူး ချူး\n",
      "Generated Text 6: ရဲ အားရ် ချူး ရစ္စ ခြူ ဖုံး ချူး ဘင် ချူး ချူး ချူး ဿ ကျိန်း ချူး ချူး ချူး ချူး နှဲမ်း ကွယ် ချူး ချူး ချူး ဂိမ်း ကြို ရဲ သတ္တိ ချူး ချူး ချူး ချူး ချူး ချူး ချူး နှဲမ်း ချူး ချူး ကျိန်း ဿ ချူး ချူး ဂိမ်း မူလ္လာ ချူး ချူး ချူး နှဲမ်း ချူး ချူး ချူး ချူး ချူး\n",
      "Generated Text 7: ရဲ ထွဋ် အောလ် ဿ ကွာ သံ ရွက် ဿ ချူး ချူး ချူး ချူး ချူး ချူး ကျိန်း ဿ ချူး ချူး ချူး ချူး ချူး ချူး ချူး ချူး ချူး ချူး နှဲမ်း ချူး ချူး ချူး ချူး နှဲမ်း ချူး ချူး ချူး ချူး ဿ ချူး ချူး ဿ ချူး ချူး ဂျယ်လ် နှဲမ်း နန္ဒာ ယု ဧည့် ချူး ချူး ချူး ချူး\n",
      "Generated Text 8: ရဲ အဲမ် ဂိမ်း ကွန့် မဲလ် ချူး ဗ ဗန် ရို့စ် ချူး ကျိန်း ရဲ လျာ ချူး ချူး ချူး ချူး ကျိန်း ဂိမ်း ထပ် ကောလ် ချူး နှဲမ်း ချူး ချူး ချူး ဿ ချူး ချူး ဿ ဿ ချူး ချူး နှဲမ်း နှဲမ်း ချူး ချူး ဿ ချူး ချူး ဿ ချူး အက် နှဲမ်း ပါးရ် ချူး ချူး ချူး ချူး ချူး ချူး\n",
      "Generated Text 9: ရဲ ပေါင် လို့ ဂိမ်း မွိုင် ဿ သုန် ချ နှဲမ်း ကန့် ဂိမ်း ချူး ချူး ချူး ချူး ချူး ချူး ချူး ချူး ချူး ဂိမ်း အယ် ချူး ချူး ချူး ချူး နှဲမ်း ချူး ရဲ နှဲမ်း ချူး ချူး ချူး နှဲမ်း ချူး ချူး ချူး နှဲမ်း ချူး ရှိုး လွန် ချူး စော အဲန်း နှဲမ်း ချူး ချူး ချူး ချူး ချူး ချူး\n",
      "Generated Text 10: ရဲ ကြုတ် ချူး ဂျိမ်းစ် ချူး သံ ရိုင် ချူး ချူး ချူး ချူး ချူး ချူး ချူး နှဲမ်း ချူး နှဲမ်း ကွာ ချူး ချူး ချူး ချူး နှဲမ်း ချူး ချူး ချူး ချူး ချူး ချူး ချူး ချူး နှဲမ်း ချူး ချူး ဂိမ်း ကွေ့ ကောလ် ချူး နှဲမ်း ချူး ချူး ချူး ရုန်း ချူး ဿ ဿ ချူး ချူး ကျိန်း ချူး ချူး\n",
      "\n",
      "real\t0m1.939s\n",
      "user\t0m4.184s\n",
      "sys\t0m0.239s\n"
     ]
    }
   ],
   "source": [
    "!time python laphet.py --model_type bert --generate --model ./model/name/bert.model \\\n",
    "--seq_len 50 --prompt \"ရဲ\" --no_of_generation 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a48bbf4-71cc-44fd-9c9e-a7720ec04e2f",
   "metadata": {},
   "source": [
    "ဒီတခါတော့ \"ကျော်\" နဲ့ စတဲ့ နာမည်တွေကို generate လုပ်ခိုင်းကြည့်ရအောင်။ sequence length ကိုတော့ 5 ထားထားတယ်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dff2dada-1674-4069-aeb3-dd52bf25f8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ye/exp/name-lm/lib/laphet.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Generated Text 1: ကျော် တိုက် ဿ ဒါ ရဲ့ ကွယ်\n",
      "Generated Text 2: ကျော် ဘေး ကင်းမ် ချူး သိင်္ခ ဆွမ်း\n",
      "Generated Text 3: ကျော် ကျက် ချူး ညိန်း ချူး ကြင်း\n",
      "Generated Text 4: ကျော် ကမ်း နွန် ထိ ဂွမ် ချူး\n",
      "Generated Text 5: ကျော် ဖား ချူး ကုန် လမ် ချူး\n",
      "Generated Text 6: ကျော် ဿာ လည်း ချူး ဿ စော\n",
      "Generated Text 7: ကျော် လက် ကြွယ် သော့ ရွက် ချူး\n",
      "Generated Text 8: ကျော် ငယ် မတ် ဆိုက် နှဲမ်း သင်္ကေ\n",
      "Generated Text 9: ကျော် အိန္ဒြ ဆောင် ဘယ်လ် ကွိဇ် ကျိန်း\n",
      "Generated Text 10: ကျော် မှိုင်း နာ ရုဏ် ရှည် ချူး\n",
      "\n",
      "real\t0m1.399s\n",
      "user\t0m3.540s\n",
      "sys\t0m0.251s\n"
     ]
    }
   ],
   "source": [
    "!time python laphet.py --model_type bert --generate --model ./model/name/bert.model \\\n",
    "--seq_len 5 --prompt \"ကျော်\" --no_of_generation 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0143ea17-798f-43bc-9b17-30f53c777dba",
   "metadata": {},
   "source": [
    "ဒီတခါတော့ \"မြင့်\" နဲ့ စတဲ့ နာမည်တွေကို generate လုပ်ခိုင်းကြည့်ရအောင်။ sequence length ကိုတော့ 2 ပေးထားတယ်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2ec6a0f3-31a1-4a8b-a6d0-da79c898307e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ye/exp/name-lm/lib/laphet.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Generated Text 1: မြင့် ဇဉ် ရေ့စ်\n",
      "Generated Text 2: မြင့် တူး နပ်\n",
      "Generated Text 3: မြင့် ထွာ နှဲမ်း\n",
      "Generated Text 4: မြင့် ည ငွေ\n",
      "Generated Text 5: မြင့် ကောင်း ခူ\n",
      "Generated Text 6: မြင့် ကြင်း နောင့်\n",
      "Generated Text 7: မြင့် ကင်းမ် ချူး\n",
      "Generated Text 8: မြင့် ရှိုင်းန်း ဂိမ်း\n",
      "Generated Text 9: မြင့် မှိုင် ချူး\n",
      "Generated Text 10: မြင့် ဂျမ်း သဉ္ဇူ\n",
      "\n",
      "real\t0m1.300s\n",
      "user\t0m3.596s\n",
      "sys\t0m0.215s\n"
     ]
    }
   ],
   "source": [
    "!time python laphet.py --model_type bert --generate --model ./model/name/bert.model \\\n",
    "--seq_len 2 --prompt \"မြင့်\" --no_of_generation 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dcdccb-053a-45c9-8fe0-5c4f975715f2",
   "metadata": {},
   "source": [
    "## Text Generation with Start-Word Input File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cce68f95-42be-4bdc-af3d-89a663446196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ye/exp/name-lm/lib/laphet.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Random Prompt Generated: ခတ္တာ\n",
      "Generated texts saved to ./output/name/bert_gen_texts.txt\n",
      "\n",
      "real\t0m1.508s\n",
      "user\t0m3.760s\n",
      "sys\t0m0.235s\n"
     ]
    }
   ],
   "source": [
    "!time python laphet.py --model_type bert --generate --model ./model/name/bert.model \\\n",
    "--seq_len 2 --input ./data/myRoman/start_names.txt --no_of_generation 5 --output ./output/name/bert_gen_texts.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37e8cf00-591a-4e7c-a074-6f1b6d006f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ကျော် တင့် ပေါ\n",
      "ကျော် ဘက် ညှင်း\n",
      "ကျော် ဖေါ ချူး\n",
      "ကျော် သက် အဉ္ဇူ\n",
      "ကျော် ဣန္ဒ ချူး\n",
      "မ မ မ ကြိုင်း\n",
      "မ မ တုပ် ချူး\n",
      "မ မ ဖယ် ချူး\n",
      "မ မ မင်း လာဘ်\n",
      "မ မ ကျိန်း ချူး\n",
      "အေး မတ် ယော်\n",
      "အေး ဇာရ် ချူး\n",
      "အေး စက္ကန့် ချူး\n",
      "အေး သု ယက်\n",
      "အေး မြော် နှဲမ်း\n",
      "လှ လှ တက္ခ ချူး\n",
      "လှ လှ တင့် လောင်ဝ်\n",
      "လှ လှ ကောင်း ဒေါသ်\n",
      "လှ လှ ဖယ် ချူး\n",
      "လှ လှ သီ မိုင်\n",
      "ခတ္တာ အဉ္ဇူ ရဲ\n",
      "ခတ္တာ ဿန် ချူ\n",
      "ခတ္တာ ဆော် ဝါ\n",
      "ခတ္တာ ခိ ကြိုင်\n",
      "ခတ္တာ သင်္ကြန် ထောင်\n",
      "မြ အေး ရှမ်း အိမ်\n",
      "မြ အေး ကတ် ဂိမ်း\n",
      "မြ အေး တေး ချူး\n",
      "မြ အေး ဒါ စင်း\n",
      "မြ အေး လွန် လော\n",
      "သ ဆားရ် ဆို\n",
      "သ ရှိ ကြည့်\n",
      "သ ဖေါ ချူး\n",
      "သ သျှန်း ရန်း\n",
      "သ ကန်း ချူး\n",
      "မောင် ဂန္တ ဟွမ်\n",
      "မောင် ခတ္တာ စဲ\n",
      "မောင် ရိုး ဖိုး\n",
      "မောင် ခင် လှဲန်\n",
      "မောင် သက် ယား\n",
      "မြင့် မြင့် ရေ့စ် ချူး\n",
      "မြင့် မြင့် ပေါ့ ညှာ\n",
      "မြင့် မြင့် မီးရ် ဿ\n",
      "မြင့် မြင့် ကိုင်း ကောလ်\n",
      "မြင့် မြင့် ဝဏ္ဏ ကျွံ\n",
      "ရွှေ ပါ ကံ့\n",
      "ရွှေ ရှမ် ချူး\n",
      "ရွှေ အဉ္ဇ စို\n",
      "ရွှေ ကျီ ပိ\n",
      "ရွှေ ဝင့် လို့\n",
      "အဂ္ဂ ကွန့် ကပ်\n",
      "အဂ္ဂ မြော် နှဲမ်း\n",
      "အဂ္ဂ ကျောက် ကိန္န\n",
      "အဂ္ဂ နွန် ကယ်လ်\n",
      "အဂ္ဂ ကောင်း လှန်\n",
      "ဥက္ကာ ဠု ချူး\n",
      "ဥက္ကာ ဂျ ပွဲ\n",
      "ဥက္ကာ ဖု နှဲမ်း\n",
      "ဥက္ကာ အက္ခ ချူး\n",
      "ဥက္ကာ လွမ် ရှိုး\n",
      "သိင်္ဂီ တန့် အဲလ်\n",
      "သိင်္ဂီ ဇိန်း ချူး\n",
      "သိင်္ဂီ လာဘ် မိုက်\n",
      "သိင်္ဂီ ကွတ် ချူး\n",
      "သိင်္ဂီ ကျွင်း နှဲမ်း\n",
      "မေ ခွာ လိုင်း\n",
      "မေ လည်း ချူး\n",
      "မေ ဠာ ကျက်\n",
      "မေ ဇမ့် ဂိမ်း\n",
      "မေ ယန် ခန့်\n",
      "ခိုင် ဂျမ်း ဂျမ်\n",
      "ခိုင် ချဲ့ ချူး\n",
      "ခိုင် [UNK] ရဲ\n",
      "ခိုင် မှီ ဟင်း\n",
      "ခိုင် နည် တွမ်း\n"
     ]
    }
   ],
   "source": [
    "!cat ./output/name/bert_gen_texts.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50c643e-5a7f-4111-8a28-63fc6ee99327",
   "metadata": {},
   "source": [
    "## Testing/Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "503e69a0-529d-4fcf-acbb-877bea53a7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ye/exp/name-lm/lib/laphet.py:216: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Testing: 100%|██████████████████████████████████| 16/16 [00:00<00:00, 51.60it/s]\n",
      "Average Perplexity on Test Data: 1.0043\n",
      "Average Cross-Entropy on Test Data: 0.0043\n",
      "\n",
      "real\t0m1.257s\n",
      "user\t0m3.594s\n",
      "sys\t0m0.198s\n"
     ]
    }
   ],
   "source": [
    "!time python laphet.py --model_type bert --test --model ./model/name/bert.model \\\n",
    "--test_file ./data/myRoman/test_name.txt --seq_len 50 --batch_size 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe44c23-4664-4316-a1b9-52c370438e4d",
   "metadata": {},
   "source": [
    "## GPT based Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abb4cdd-2a44-4842-81b2-fd7cacfeb668",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e1a6cbd6-4b26-4f46-961a-4b8ce3ffaef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 200.41it/s]\n",
      "Epoch 1, Training Loss: 0.0759\n",
      "Epoch 1/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 579.82it/s]\n",
      "Epoch 1, Validation Loss: 0.0018\n",
      "Best model saved at ./model/name/gpt.model with validation loss: 0.0018\n",
      "Epoch 2/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 213.35it/s]\n",
      "Epoch 2, Training Loss: 0.0012\n",
      "Epoch 2/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 590.19it/s]\n",
      "Epoch 2, Validation Loss: 0.0005\n",
      "Best model saved at ./model/name/gpt.model with validation loss: 0.0005\n",
      "Epoch 3/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 204.90it/s]\n",
      "Epoch 3, Training Loss: 0.0004\n",
      "Epoch 3/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 561.17it/s]\n",
      "Epoch 3, Validation Loss: 0.0002\n",
      "Best model saved at ./model/name/gpt.model with validation loss: 0.0002\n",
      "Epoch 4/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 209.78it/s]\n",
      "Epoch 4, Training Loss: 0.0002\n",
      "Epoch 4/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 580.29it/s]\n",
      "Epoch 4, Validation Loss: 0.0001\n",
      "Best model saved at ./model/name/gpt.model with validation loss: 0.0001\n",
      "Epoch 5/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 214.95it/s]\n",
      "Epoch 5, Training Loss: 0.0001\n",
      "Epoch 5/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 573.45it/s]\n",
      "Epoch 5, Validation Loss: 0.0001\n",
      "Best model saved at ./model/name/gpt.model with validation loss: 0.0001\n",
      "Epoch 6/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 214.19it/s]\n",
      "Epoch 6, Training Loss: 0.0001\n",
      "Epoch 6/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 579.84it/s]\n",
      "Epoch 6, Validation Loss: 0.0000\n",
      "Best model saved at ./model/name/gpt.model with validation loss: 0.0000\n",
      "Epoch 7/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 212.09it/s]\n",
      "Epoch 7, Training Loss: 0.0000\n",
      "Epoch 7/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 581.63it/s]\n",
      "Epoch 7, Validation Loss: 0.0000\n",
      "Best model saved at ./model/name/gpt.model with validation loss: 0.0000\n",
      "Epoch 8/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 212.93it/s]\n",
      "Epoch 8, Training Loss: 0.0000\n",
      "Epoch 8/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 578.59it/s]\n",
      "Epoch 8, Validation Loss: 0.0000\n",
      "Best model saved at ./model/name/gpt.model with validation loss: 0.0000\n",
      "Epoch 9/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 210.82it/s]\n",
      "Epoch 9, Training Loss: 0.0000\n",
      "Epoch 9/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 580.05it/s]\n",
      "Epoch 9, Validation Loss: 0.0000\n",
      "Best model saved at ./model/name/gpt.model with validation loss: 0.0000\n",
      "Epoch 10/10 (Training): 100%|████████████████| 852/852 [00:03<00:00, 216.76it/s]\n",
      "Epoch 10, Training Loss: 0.0000\n",
      "Epoch 10/10 (Validation): 100%|████████████████| 32/32 [00:00<00:00, 574.80it/s]\n",
      "Epoch 10, Validation Loss: 0.0000\n",
      "Best model saved at ./model/name/gpt.model with validation loss: 0.0000\n",
      "\n",
      "real\t0m42.605s\n",
      "user\t0m44.227s\n",
      "sys\t0m0.357s\n"
     ]
    }
   ],
   "source": [
    "!time python laphet.py --model_type gpt --train --data ./data/myRoman/train_name.txt \\\n",
    "--dev_file ./data/myRoman/dev_name.txt --model ./model/name/gpt.model --seq_len 50 --epochs 10 --batch_size 32 --lr 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e0ded0fc-0959-4b24-b5d5-76cf2631e40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ye ye 11M Jan 27 01:51 ./model/name/gpt.model\n",
      "-rw-rw-r-- 1 ye ye 24K Jan 27 01:51 ./model/name/gpt.model.vocab\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ./model/name/gpt*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3306b1-d5f5-41b1-bc62-4516f5b44b10",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e9d9395-f4da-48d7-96c5-52722609606d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ye/exp/name-lm/lib/laphet.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Generated Text 1: ရဲ ပူး မစ် ကျူ ချန် မော် ကို မြ ဖွင့် သဉ္ဇူ မွမ်း ငွေ့ ဖာ သွေး ရန် ခွမ် ကွန့် ဂန္တ ကင်း နှင်း ဖယ် ဂျူး ဖိန် လှဲန် ဝယ်လ် ဘွိုင် ခဂ္ဂါ တုတ် ဘန့် မစ် တော မိုက် ဟွ ခေါ တိုင် ဆင် အင်း ညွန့် ရှင်း ဟန် ဿဏ် ဘွမ် ဓီ ပမ် ထွတ် ခန့် တံ့ သို ပု တောင်း ချူး\n",
      "Generated Text 2: ရဲ မင်္ဂ ဇ ဖျား လျှမ် ဣန္ဒ ကြေး ပဲန် ဖော် စွာ ပွဲ မိုက် လော် ကျိမ်း မြီ ကျွယ် ဖာ ဏ နတ် ချုံး ဖန့် ကျွယ် အိမ် လိတ် ထ လဲစ် ဂျာ ရှဲလ် ဝမ် ဥမ္မာ စံ သိုက် ခေါက် ဖီး ခွမ်း ချာ နာ အပ် သောင်း ကျွယ် လိုင်း ဖွေး လီ ဂျမ်း ပိုး ဂျား ဆင့် ထွန်း ဂျီ ကျစ် ပွဲ\n",
      "Generated Text 3: ရဲ ဗေး မန် ခတ် သဉ္ဇူ ဂွိ ငိုင် ရှင်း နူး ပေါ် သွန်း ဆဲ လမ်း ဆီ အဲင်း ဂျိုး ဏိ ကိန်း သျှင်း ဂျက်ခ် အဂ္ဂ ကျေ သီး နွံ ဆွိ သျှန်း ဝုန် ဒွပ် ရံ ဘောက် ချင်း ကုန် ရိုင်းန် ပွင့်် ရဲ ကွမ် ကိုက် ရွာ လေး ငါး အိန္ဒာ လျှံ ငြိမ် သော့ခ် ရော် ချ ညောင် ဖြင့် ကပ် လိမ်း ငြိမ့်\n",
      "Generated Text 4: ရဲ ခြိမ့် အင် တွယ် ကျွန် ဒု ခြယ် ချက်စ် စုံ ရက် ဆုန် ခွန် ဘွိုင် ရွမ်း စွမ် ဟယ် နှိုင်း ဒန် ဗုံ စန္ဒာ လူး ဇူ အိန္တာ ခြိမ့် ဒေါင့် အိန္ဒြာ ဘုန်း အိမ္ဗာ သိုင်း လှိုဏ်း အိင်္ခ မုန် အိမ္ဗာ ခက် ဒိုင် ချိုး ကြူး လာလ် ဂန့် ဓမ္မာ အန် ရွာ စွမ် ဇဉ် သျှင် ဖူ လဲလ် ဂမ် သိမ့် နန္ဒီ ဗျော\n",
      "Generated Text 5: ရဲ အုပ် ရမ်း အိင်္ခ ဆွန်း လွီ ဒိ အင်း လဲလ် ပြန့် ရှုံး လွန် နေး ခွါ သစ္စာ သင်္ကေ ဂျေ ချက်စ် ခွား ကြာ လဲ ချမ်း ဆောမ်း ရှောင် သို့ ဒိန်း ကျွံ ဂဂ္ဂါ သို့ ကျေး ငိုင် မာ့ ဂီ ဇွန် နယ် ဂွိ ဆွန် ရွမ် ရိပ် တီးလ် ရောင်းန် ဝါး ထာသ် ရက် ညွန် ထ ဝဏ္ဏ ကာလ် ရေ့စ် ဆွမ်း ဆောင်\n",
      "Generated Text 6: ရဲ ယိုင် မြို့ သိဏ်း ကြူ ဖန့် သစ္စာ ကောင်း နှဲမ် ကျိမ်း ယိုင် ကွမ်း ခါရ် နတ် ဠာ ခက် နှဲမ်း လွီ ဝယ် ဆွမ်း ဖြိုး ကယ် သဉ္ဇာ စော် ပါးရ် ရစ္စ ဝါး ကျား ည ဆွယ် သဉ္စာ ဂူ ဖန် လာမ် ကာလ် သင်္ကေ ဘုံ ဒိန် လာဘ် ယံ အိုမ် သံ ပါး တုပ် ဘွိုင်း ပြာ နှဲမ်း ကွန့် ကြိုး ဒင့် ဝ\n",
      "Generated Text 7: ရဲ ဖုန် အီ သောင်း နော လမ် ဘေ ဘို့ ဘု မှာ ရွေ့ ရွိုင် နိုး ဿန်း လှဲ ဂျီ လိန်း မုစ် အိဇ္ဇာ လည်း ဟိဏ်း ပွန်း တ မေ ဘီ မှန် ဖုန် ခေါ်လ် ညွှန့် ဘုတ် သိမ့် ရယ်လ် တုံ ကော့ ဆိုင် တံ ဇော် ဘေး ဘုတ် ပေး ဂူး ဒါး ပွင့် ချောက် နံ့ တု ငန် ဒါ အန်ဒ် ကေး သောင်း\n",
      "Generated Text 8: ရဲ မီးရ် ဘုဏ်း ချိ ယူး ဘွဲ တီလ် ဒါးလ် နာ သန္ဒြာ သက် သျှမ်း ကျိမ်း ဂုန် ဖန်း သွန်း ဇွန် တိ ဒိ နှင်မ် အဲန်း ဂေါ် ဗစ် ဇဉ် ဖုံး ရှု အယ်လ် ဒို့ဗ် ဋေ အပ် အက်စ် ဿဲ သျှ အေး ကွေး အိုး လာဘ် ဓမ္မာ ဉာဏ် စွယ် မက် ဒို့ဗ် ဥတ္တ ကြွမ် ကိုက် စမ်း ဘောမ် ဆိုး ကွယ် ခြိမ့် ဂမ်\n",
      "Generated Text 9: ရဲ သိမ်း ထု မဲ့ ရောင် ရာဇ် ချမ်း စုံ မင်း ဘွဲ့ နည် ရယ်လ် ဘ တွဲ ဝိ မြန် ဒူ ခီ ဆွမ့် ကွီ ဣ ခဲ ဗား လာဘ် ဟို့စ် ဂျက်ခ် ဂဲလ် ဟော ဇန် ခေး ဿဏ် ဂွိ ဂေး ဝန်း ထ ဇွန်း အောန် ပါရ် ထီး ဖူး ဒုံ ပန်း ခမ့် ယောင် ကျိမ် ကျန်း ဂျီး ဂန် စန် ဇေါင်း ပြိုင်\n",
      "Generated Text 10: ရဲ တိန်း ညု သိ မယ် မုန် မွှေး ချိ ရွှန်း ပေါ် လှောင် ကျိန် မှုန်း ဘွိုင်း ကမ် ကျန် ပြုံ ကော် ဩ နောင့် ပျံ့ မု ဘီလ် ညာ ဂိုး အုံး သစ် သင်း အေး လုတ် ပွဲ ဆမ် တွာ ခွာ ယဉ်း ချီ ရက် ဿန် ရွမ် ချွန် ဆွယ် ဟူ ဟိဏ်း ထပ် နီ ကျီး ကွ စီး ဂါး သျှန် စမ်း\n",
      "\n",
      "real\t0m1.886s\n",
      "user\t0m4.143s\n",
      "sys\t0m0.236s\n"
     ]
    }
   ],
   "source": [
    "!time python laphet.py --model_type gpt --generate --model ./model/name/gpt.model \\\n",
    "--seq_len 50 --prompt \"ရဲ\" --no_of_generation 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2a8776-883b-43e6-97a8-98a524656bf8",
   "metadata": {},
   "source": [
    "ဒီတခါတော့ --prompt အေး ဆိုတာနဲ့ --seq_len 2 ပဲ ထားပြီး generate လုပ်ခိုင်းကြည့်ရအောင်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8a859e36-6c50-468e-aba6-852fde9268ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ye/exp/name-lm/lib/laphet.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Generated Text 1: အေး ဆဲလ် ရှိုင်းန်း\n",
      "Generated Text 2: အေး စိန် တုန်\n",
      "Generated Text 3: အေး အက်စ် ဆူး\n",
      "Generated Text 4: အေး ဖွင့် ရိုင်းန်\n",
      "Generated Text 5: အေး ကွန့် ကွာ\n",
      "Generated Text 6: အေး ကွဲ လန့်\n",
      "Generated Text 7: အေး လု ကတ္တီ\n",
      "Generated Text 8: အေး သွင် တို\n",
      "Generated Text 9: အေး ဂျာ စဉ့်\n",
      "Generated Text 10: အေး ဆွယ် အာဖ်\n",
      "\n",
      "real\t0m1.310s\n",
      "user\t0m3.579s\n",
      "sys\t0m0.224s\n"
     ]
    }
   ],
   "source": [
    "!time python laphet.py --model_type gpt --generate --model ./model/name/gpt.model \\\n",
    "--seq_len 2 --prompt \"အေး\" --no_of_generation 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66346331-a3d1-4dc6-a55f-5f7be3be799d",
   "metadata": {},
   "source": [
    "ဒီတစ်ခါတော့ \"မြင့်\" နဲ့ စတဲ့ နာမည်တွေကို generate လုပ်ခိုင်းကြည့်မယ်။  \n",
    "sequence length ကို 2 ထားမယ်။ ပြီးတော့ no of generation ကိုတော့ 5 ပဲ ထားမယ်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d288bb12-9f5d-4864-bebd-1f8c8a5c147b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ye/exp/name-lm/lib/laphet.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Generated Text 1: မြင့် ကြိုး ကိုလ်\n",
      "Generated Text 2: မြင့် သိမ့် စိုး\n",
      "Generated Text 3: မြင့် စွဲ့ မျှား\n",
      "Generated Text 4: မြင့် ခုပ် အဂ္ဂါ\n",
      "Generated Text 5: မြင့် ကုံး ရိုင်း\n",
      "\n",
      "real\t0m1.318s\n",
      "user\t0m3.455s\n",
      "sys\t0m0.259s\n"
     ]
    }
   ],
   "source": [
    "!time python laphet.py --model_type gpt --generate --model ./model/name/gpt.model \\\n",
    "--seq_len 2 --prompt \"မြင့်\" --no_of_generation 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1694bb-cbea-4298-90ad-545eaa498878",
   "metadata": {},
   "source": [
    "## Text Generation with Start-Word Input File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e5d391bf-f33d-478e-a10e-9cd256df5f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ye/exp/name-lm/lib/laphet.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Random Prompt Generated: သော်\n",
      "Generated texts saved to ./output/name/gpt_gen_texts.txt\n",
      "\n",
      "real\t0m1.492s\n",
      "user\t0m3.790s\n",
      "sys\t0m0.238s\n"
     ]
    }
   ],
   "source": [
    "!time python laphet.py --model_type gpt --generate --model ./model/name/gpt.model \\\n",
    "--seq_len 2 --input ./data/myRoman/start_names.txt --no_of_generation 5 --output ./output/name/gpt_gen_texts.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7e444b-265c-40aa-a2a1-b03e605da31b",
   "metadata": {},
   "source": [
    "Save လုပ်ထားတဲ့ gpt_gen_texts.txt ဖိုင်ကို ကြည့်ကြည့်ရအောင်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a263ac2e-db03-46ac-a4e0-efab92429bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ကျော် တည် စက္ကန့်\n",
      "ကျော် ဗြာ ဥက္ကာ\n",
      "ကျော် ကန် ကွက်\n",
      "ကျော် ညိန်း ရယ်လ်\n",
      "ကျော် ဝမ် ငြိမ်\n",
      "မ မ ခါ ကျေး\n",
      "မ မ သု လဲန်း\n",
      "မ မ တုတ် လစ်\n",
      "မ မ ကျက် ဘီ\n",
      "မ မ နွမ် ငွေ့\n",
      "အေး ထား ခေါင်း\n",
      "အေး စင် ဂုံ\n",
      "အေး လာ စုက္က\n",
      "အေး အိန္ဒြာ ချားလ်\n",
      "အေး နဲမ် လွှမ်း\n",
      "လှ လှ လျှန် ဒူ\n",
      "လှ လှ ဟင်း ပါယ်\n",
      "လှ လှ ထဲမ်း အိမ်း\n",
      "လှ လှ ခေါ်လ် ရိုင်း\n",
      "လှ လှ ခန် စိမ့်\n",
      "သော် ဘန်း ဇေ\n",
      "သော် ပြာ ဒ\n",
      "သော် ပြောင်း ညွှန်း\n",
      "သော် ဗုံ ဇမ်\n",
      "သော် နာ့ ညိမ့်\n",
      "မြ အေး တွမ် ဝယ်လ်\n",
      "မြ အေး ထောင်း ထန်း\n",
      "မြ အေး ကွာ မြင်\n",
      "မြ အေး လျှမ် ထန်\n",
      "မြ အေး ကိမ်း ဇင်\n",
      "သ ဆန့် ဂျူး\n",
      "သ ရှိုင်းန်း ဘွယ်\n",
      "သ တိန့် ကျော့\n",
      "သ ကဉ္စ ခံ့\n",
      "သ လွန်း ကျဲ\n",
      "မောင် ဗာ လှဲ\n",
      "မောင် ကင်းမ် ကူး\n",
      "မောင် ကန်း ပါယ်\n",
      "မောင် အောင်း သို့\n",
      "မောင် ဗြာ ကွပ်\n",
      "မြင့် မြင့် နွမ် ရင်\n",
      "မြင့် မြင့် ရော် ဏ\n",
      "မြင့် မြင့် ကောန် ဇီ\n",
      "မြင့် မြင့် နဲမ်း ပုံ\n",
      "မြင့် မြင့် စုံ ပံ\n",
      "ရွှေ ဇူ ရှိန်\n",
      "ရွှေ နှင်း ဂဂ်\n",
      "ရွှေ ပွန်း ချောက်\n",
      "ရွှေ စိုး ညို့\n",
      "ရွှေ လင်္ကာ ရင်း\n",
      "အဂ္ဂ လိုင်း အန့်\n",
      "အဂ္ဂ မိုင် တွန်း\n",
      "အဂ္ဂ အဉ္ဇ ကာ\n",
      "အဂ္ဂ လွှင် ကျိမ်း\n",
      "အဂ္ဂ ခြာ ဇမ့်\n",
      "ဥက္ကာ ပယ်လ် ဂျန်\n",
      "ဥက္ကာ အဲင်း ဇာရ်\n",
      "ဥက္ကာ လဲန်း သျွှန်း\n",
      "ဥက္ကာ ဝင်း ယှဉ်\n",
      "ဥက္ကာ ကျော လ\n",
      "သိင်္ဂီ နှိုင်း ရေး\n",
      "သိင်္ဂီ သစ္စာ ဖေ\n",
      "သိင်္ဂီ ဇမ့် ကျိမ်\n",
      "သိင်္ဂီ ငြား ညား\n",
      "သိင်္ဂီ မြူ ပံ\n",
      "မေ ဘူး ယာန်\n",
      "မေ ကျက် ကြူး\n",
      "မေ ခေါန် ငြိမ့်\n",
      "မေ လမ့် ဆိုက်\n",
      "မေ ဖေ ကွန်\n",
      "ခိုင် ဖေါ ဖော်\n",
      "ခိုင် ကက် ဘွမ်\n",
      "ခိုင် ကိမ် လျံ\n",
      "ခိုင် မြေး ဖုန်\n",
      "ခိုင် ဒစ် ဥတ္တ\n"
     ]
    }
   ],
   "source": [
    "!cat ./output/name/gpt_gen_texts.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b39e0c-cc3e-4e73-97c8-f84e2fd65af1",
   "metadata": {},
   "source": [
    "## Bash Shell Script\n",
    "\n",
    "just for your knowledge ပါ။  \n",
    "အထက်မှာ ပြခဲ့တဲ့အတိုင်း မော်ဒယ် တစ်ခုစီကို coding လုပ်ရင်းနဲ့ စမ်းရတဲ့အခါမှာ အကြိမ်ကြိမ်အခါခါ run လိုက် coding ကို ဝင်ပြင်လိုက်လုပ်ရတာမို့လို့ command line argument တွေအတိုင်းအတာ တစ်ခုထိ သတ်မှတ်ပြီးသွားတဲ့အခါမှာ shell script ရေးလိုက်ပြီး run ပြီးမှ log တွေ၊ ထွက်လာတဲ့ output တွေကို manual ဝင်စစ်ကြည့်တာမျိုး လုပ်ခဲ့ရပါတယ်။ အဲဒီလို လုပ်မှလည်း command တွေကို ရိုက်ထည့်နေရတဲ့ အချိန်သက်သာပါတယ်။  \n",
    "\n",
    "လက်တွေ့ experiment တွေလုပ်တဲ့အခါမှာလည်း shel script ရေးတတ်ဖို့ လိုအပ်ပါတယ်။  \n",
    "\n",
    "Laphet LM Toolkit ကို coding လုပ်နေစဉ်မှာ သုံးခဲ့တဲ့ bash shell script က အောက်ပါအတိုင်းပါ။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8472f0c1-9643-4b37-aae3-327db6fd453d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "# Create the output and log directories if they don't exist\n",
      "mkdir -p model/name/\n",
      "mkdir -p output/name/\n",
      "mkdir -p log/name/\n",
      "\n",
      "# Function to train, generate text, and test a language model\n",
      "task() {\n",
      "  local model_type=$1\n",
      "  local model_file=\"./model/name/${model_type}.model\"\n",
      "  local output_file=\"./output/name/${model_type}_gen_texts.txt\"\n",
      "  local log_file=\"./log/name/${model_type}.log\"\n",
      "  local train_data=\"./data/myRoman/train_name.txt\"\n",
      "  local dev_data=\"./data/myRoman/dev_name.txt\"\n",
      "  local test_data=\"./data/myRoman/test_name.txt\"\n",
      "  local start_name=\"./data/myRoman/start_names.txt\"\n",
      "\n",
      "  {\n",
      "    echo \"Training ${model_type^} language model:\";\n",
      "    time python -u laphet.py --model_type $model_type --train --data $train_data \\\n",
      "      --dev_file $dev_data --model $model_file --seq_len 50 --epochs 10 --batch_size 32 --lr 0.0001;\n",
      "\n",
      "    echo \"Text generation:\";\n",
      "    time python -u laphet.py --model_type $model_type --generate --model $model_file \\\n",
      "      --seq_len 50 --prompt \"ရဲ\" --no_of_generation 10;\n",
      "\n",
      "    echo \"Batch text generation from file:\";\n",
      "    time python -u laphet.py --model_type $model_type --generate --model $model_file \\\n",
      "      --seq_len 2 --input $start_name --no_of_generation 5 --output $output_file;\n",
      "\n",
      "    echo \"Testing:\";\n",
      "    time python -u laphet.py --model_type $model_type --test --model $model_file \\\n",
      "      --test_file $test_data --seq_len 50 --batch_size 64 2>&1;\n",
      "  } | tee \"$log_file\"\n",
      "}\n",
      "\n",
      "# Run tasks for each model type in the specified order\n",
      "task mlp\n",
      "task bilstm\n",
      "task transformer\n",
      "task bert\n",
      "task gpt\n",
      "\n",
      "echo \"All tasks completed!\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat ./train_test_name.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a48326-0116-48e0-abe6-599aaeb52d90",
   "metadata": {},
   "source": [
    "## Running MLP, Bi-LSTM, Transformer, BERT and GPT Language Models Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373c0629-7838-4ef2-95c2-efaaee4b49c3",
   "metadata": {},
   "source": [
    "ဒီတခါတော့ Myanmar name dataset ကိုသုံးပြီး မော်ဒယ် ၅မျိုးစလုံးရဲ့ training, text generation နဲ့ testing/evaluation အကုန် အစအဆုံးကို အထက်က shell script ကိုသုံးပြီး run ကြည့်ပါမယ်။   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b585bee2-ed89-4bf4-8287-c559ba47fbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Mlp language model:\n",
      "Epoch 1/10 (Training): 100%|█████████████████| 852/852 [00:06<00:00, 130.69it/s]\n",
      "Epoch 1, Training Loss: 1.3057\n",
      "Epoch 1/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 498.28it/s]\n",
      "Epoch 1, Validation Loss: 1.0546\n",
      "Best model saved at ./model/name/mlp.model with validation loss: 1.0546\n",
      "Epoch 2/10 (Training): 100%|█████████████████| 852/852 [00:06<00:00, 138.64it/s]\n",
      "Epoch 2, Training Loss: 1.0531\n",
      "Epoch 2/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 511.96it/s]\n",
      "Epoch 2, Validation Loss: 1.0525\n",
      "Best model saved at ./model/name/mlp.model with validation loss: 1.0525\n",
      "Epoch 3/10 (Training): 100%|█████████████████| 852/852 [00:06<00:00, 138.08it/s]\n",
      "Epoch 3, Training Loss: 1.0522\n",
      "Epoch 3/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 505.81it/s]\n",
      "Epoch 3, Validation Loss: 1.0521\n",
      "Best model saved at ./model/name/mlp.model with validation loss: 1.0521\n",
      "Epoch 4/10 (Training): 100%|█████████████████| 852/852 [00:06<00:00, 136.86it/s]\n",
      "Epoch 4, Training Loss: 1.0520\n",
      "Epoch 4/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 520.73it/s]\n",
      "Epoch 4, Validation Loss: 1.0520\n",
      "Best model saved at ./model/name/mlp.model with validation loss: 1.0520\n",
      "Epoch 5/10 (Training): 100%|█████████████████| 852/852 [00:06<00:00, 138.06it/s]\n",
      "Epoch 5, Training Loss: 1.0519\n",
      "Epoch 5/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 507.64it/s]\n",
      "Epoch 5, Validation Loss: 1.0519\n",
      "Best model saved at ./model/name/mlp.model with validation loss: 1.0519\n",
      "Epoch 6/10 (Training): 100%|█████████████████| 852/852 [00:06<00:00, 137.54it/s]\n",
      "Epoch 6, Training Loss: 1.0519\n",
      "Epoch 6/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 510.47it/s]\n",
      "Epoch 6, Validation Loss: 1.0519\n",
      "Best model saved at ./model/name/mlp.model with validation loss: 1.0519\n",
      "Epoch 7/10 (Training): 100%|█████████████████| 852/852 [00:06<00:00, 134.33it/s]\n",
      "Epoch 7, Training Loss: 1.0519\n",
      "Epoch 7/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 512.87it/s]\n",
      "Epoch 7, Validation Loss: 1.0518\n",
      "Best model saved at ./model/name/mlp.model with validation loss: 1.0518\n",
      "Epoch 8/10 (Training): 100%|█████████████████| 852/852 [00:06<00:00, 135.54it/s]\n",
      "Epoch 8, Training Loss: 1.0518\n",
      "Epoch 8/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 512.65it/s]\n",
      "Epoch 8, Validation Loss: 1.0518\n",
      "Best model saved at ./model/name/mlp.model with validation loss: 1.0518\n",
      "Epoch 9/10 (Training): 100%|█████████████████| 852/852 [00:06<00:00, 139.46it/s]\n",
      "Epoch 9, Training Loss: 1.0518\n",
      "Epoch 9/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 519.27it/s]\n",
      "Epoch 9, Validation Loss: 1.0518\n",
      "Best model saved at ./model/name/mlp.model with validation loss: 1.0518\n",
      "Epoch 10/10 (Training): 100%|████████████████| 852/852 [00:06<00:00, 137.39it/s]\n",
      "Epoch 10, Training Loss: 1.0518\n",
      "Epoch 10/10 (Validation): 100%|████████████████| 32/32 [00:00<00:00, 510.78it/s]\n",
      "Epoch 10, Validation Loss: 1.0518\n",
      "Best model saved at ./model/name/mlp.model with validation loss: 1.0518\n",
      "\n",
      "real\t1m4.614s\n",
      "user\t1m6.129s\n",
      "sys\t0m0.390s\n",
      "Text generation:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Generated Text 1: ရဲ ထယ် ပြီ ကိ ဆူး ဗျက် သော့ ကိန်း ရှယ် ကူး အဂ္ဂ မှုန်း ကြွယ် ကင် ဇိ ဂျွန်း ဂန် အုံး မောင် မှီ ညိမ်း စွန်း ဆော် ထူး ငြိမ့် ပန် အိန္ဒြေ ညွှန့် ခက်ခ် ဂန္တ ပေး ချန်း ဗျက် ဂ အီ ထော ဘုံ ခတ္တာ တု သဉ္ဇ ဖျား ထန် မှီ [PAD] လင်း ပြီ လျှပ် ချယ် ဘေး သေး ဇင်း\n",
      "Generated Text 2: ရဲ အန် ရင်း ဆန်း အာဖ် အီ ဟမ် ဗျာလ် ခိ သုဒ္ဓေါ လွမ်း သဉ္ဇာ သည်း အိုး ပြည် ဖွာ ကျောက် ဗဲလ် ဆွယ် လှီး တိုင်း ဖန်း ထဲ ဝံ အိပ် ဇင်း ကျဲရ် ကြိုင်း အောင် မှာ မုခ် ကံ့ ဇက် ဆို ဖေ လာ အိန္ဒြ သော့ ထပ် မောင် ခန် လင်္ကာ ချစ် တုံ ဗျော ယောင် ခုပ် ထပ် ယျာ သော် ဏီ\n",
      "Generated Text 3: ရဲ ရှား ရို နှော မှောင် ဗျာလ် မြေ ပြန်း ခဏ် မဲ့ နဲ သေ့ သို ထယ် နဲ ကျင့် ရဲ့ ယိုင် ဟွမ်း ရော် ဂဲလ် ဖြူး ဖျား ကြား စန္ဒာ ကိုင် တည် ကောလ် ဇယ် လျော့ ထွေး ကြိုး ပိုက် ဘီ ကြိုင်း ဝဏ္ဏ ပါ့ မဉ္ဇူ သိုက် ညောင် လတ် ဗဲလ် စဉ့် ကုံး မိန် ဇမ္ဗူ ထည် တွဲ အိင်္ခ ဝါး မှူး\n",
      "Generated Text 4: ရဲ ဆိုး ကျိုင်း ခြာ ဗေး ကျင်း တောင် ချယ်လ် ဗိုင်း ဆန္ဒ ရဲ့ ငုံ မူး ပါးရ် ရှီး ဆုံး ဆွန် ရိန် လွှင် မင်း ဂင့် ဆား လွန်း သောင်း ထိုင် သွင့် ဟတ် ချက်ထ် ချင်း ပါယ် ထယ် ပေါ် အက္ခ ဆုန်း နှဲမ် မွန်း ကန် ရှဲလ် ဗဲလ် သွင့် ဆန့် မော် လန်း နှောင်း ဂျွန် ရောင် ကွန့် လိန် ပု ရွှန်း ဠာ\n",
      "Generated Text 5: ရဲ ကျွမ်း နွံ ထိုင် နွမ်း ရတ် ဖြင့် ရန်း မြ ယိုင် ကြ လျှို ဓူ ညို့ ဆင့် စီး လှေ လွမ်း ရော့ခ် နား စန်း မွန်း မွှေး ယိုင် ခုပ် ဘေ ကဉ္စ ဘီလ် ချောင် ကျေ ဇော် အက်စ် ခြာ ရေး အားရ် ဆို ဖို့ ချင် ဘွား လှီး ခေတ် ကိန်း ဝန် ကျိုင်း တေ သန္ဒာ ဂိုး စင်း နင် ရတ် သဉ္စာ\n",
      "Generated Text 6: ရဲ တိန်း ငိုင် ဟိန်း ဗိုင်း မီး အိဇ္ဇာ ကျူ ဓမ္မာ ခွေး အိန္မာ မံ သိဒ္ဓိ ကီလ် နောင် ရှုံး အိုင် မာ ဒင့် သက္က ဟွေ ဇုံ ခမ့် ဒေါ သွား ပွါ အေး လွန်း ခြူ သန္တာ လာန်း ပွင့် မုန်း ရော ဇမ် ဟို့စ် က ပါ့ ခေါမ် ခမ့် ရှဲလ် ညာ တီလ် စွန် ကြုံ ခါရ် ဖန် လာ မဲလ် ဖိန် ဆမ်\n",
      "Generated Text 7: ရဲ သောင်း ပြန့် ကယ် မယ် ထန် အိစ် တ လှိုဏ်း လိမ်း ဂတ် တိုး ဓ ပိုး ကိန်း ဝယ် ကျော် ဘုတ် ဂူး ချစ် ချယ်လ် ပုံ ရွမ် ဂဂ္ဂါး ချဲ့ ဘောမ် ဘီ ကွတ် အိန္တာ ထွန်း ချွတ် ချားလ် ဂူး တိမ်း တူး ခြူ ညက် သု ဖွေး ဆပ် အင်း ည မြေ့ ကစ် ငွေ လူ ရေ ဗ ပယ်လ် ဂဲလ် ကျော့်\n",
      "Generated Text 8: ရဲ စန္ဒ အဲ ထပ် အိန္ထ ဿန်း ခွန်း စူး ဗျာလ် ကျို လှောန် ခေါက် နို ကျော့ သိန်း နော် ဗစ် မြို့ စက်ဖ် ဆီး ဠာ မြင် ခေါင်း စဉ့် အိန္ဒြာ ဟက်ခ် ဇူ သက် ကျိန် လျင် ချဲ့ ဓု ညက် ဒေါ ကြား လဲန်း ကဲ ဇ သိမ် လွီ သင်း မှောင် နိုက် ရော့ဒ် ဒေါသ် ငဲ နှစ် ဗီ ဃာ ဟောမ်း သင့်\n",
      "Generated Text 9: ရဲ ခေါ နိုင်း တန့် စွမ် ခို ချုံ ဖန်း ကျိန်း မာ့ ထိုင် ညွှန့် သု ထွာ ကုံး ဘက် နှဲမ်း ဆယ် ဖွင့် ယော ဝတ် သင် ကြွမ် ကျီ ဆွန် ဘီလ် ချိုင်း ဖု ဣန္ဒ အစ် မုခ် မျှား ခတ် ပေါင် အက် ဟုမ် လွန် အန့် မှာ သည်း ဟို ချိန် ကိမ် ယှဉ် ကိစ္စ စန်း ဘွဲ့ ပိုက် ခုံ သွင့် အ\n",
      "Generated Text 10: ရဲ ဝတ် နန်းဒ် ခူ မျှော် အာ ကြံ ရောင်းန် လူး ရွတ် ကွန့် ဇိန်း လျှပ် ခွန် တေ စင်္ကြာ ဿန် ဇာ ပါရ် ရွမ် သူ ဖတ် မော နေး လှေး အူလ္လာ နီ ဝယ်လ် ဇာ ဖိန် လွင် ကြူး အက္ခ အားလ် ခေါက် ဗီ ဟင်း ဆာ လောဒ် အမ်း နဲ့ ထူး ဗုံ ဗစ် မိုင်း မုစ် ကြုတ် အက် ရတ် ဟောမ်း ကျော\n",
      "\n",
      "real\t0m1.846s\n",
      "user\t0m4.175s\n",
      "sys\t0m0.212s\n",
      "Batch text generation from file:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Random Prompt Generated: ခွန်း\n",
      "Generated texts saved to ./output/name/mlp_gen_texts.txt\n",
      "\n",
      "real\t0m1.286s\n",
      "user\t0m3.604s\n",
      "sys\t0m0.219s\n",
      "Testing:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:216: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Testing: 100%|██████████| 16/16 [00:00<00:00, 54.77it/s]\n",
      "Average Perplexity on Test Data: 1.1110\n",
      "Average Cross-Entropy on Test Data: 0.1053\n",
      "\n",
      "real\t0m1.225s\n",
      "user\t0m3.576s\n",
      "sys\t0m0.186s\n",
      "Training Bilstm language model:\n",
      "Epoch 1/10 (Training): 100%|██████████████████| 852/852 [00:15<00:00, 55.43it/s]\n",
      "Epoch 1, Training Loss: 0.4860\n",
      "Epoch 1/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 164.19it/s]\n",
      "Epoch 1, Validation Loss: 0.3186\n",
      "Best model saved at ./model/name/bilstm.model with validation loss: 0.3186\n",
      "Epoch 2/10 (Training): 100%|██████████████████| 852/852 [00:15<00:00, 56.44it/s]\n",
      "Epoch 2, Training Loss: 0.3130\n",
      "Epoch 2/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 163.60it/s]\n",
      "Epoch 2, Validation Loss: 0.3077\n",
      "Best model saved at ./model/name/bilstm.model with validation loss: 0.3077\n",
      "Epoch 3/10 (Training): 100%|██████████████████| 852/852 [00:15<00:00, 56.33it/s]\n",
      "Epoch 3, Training Loss: 0.3049\n",
      "Epoch 3/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 163.00it/s]\n",
      "Epoch 3, Validation Loss: 0.2988\n",
      "Best model saved at ./model/name/bilstm.model with validation loss: 0.2988\n",
      "Epoch 4/10 (Training): 100%|██████████████████| 852/852 [00:15<00:00, 56.21it/s]\n",
      "Epoch 4, Training Loss: 0.2843\n",
      "Epoch 4/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 162.10it/s]\n",
      "Epoch 4, Validation Loss: 0.2640\n",
      "Best model saved at ./model/name/bilstm.model with validation loss: 0.2640\n",
      "Epoch 5/10 (Training): 100%|██████████████████| 852/852 [00:15<00:00, 56.20it/s]\n",
      "Epoch 5, Training Loss: 0.2210\n",
      "Epoch 5/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 161.16it/s]\n",
      "Epoch 5, Validation Loss: 0.1808\n",
      "Best model saved at ./model/name/bilstm.model with validation loss: 0.1808\n",
      "Epoch 6/10 (Training): 100%|██████████████████| 852/852 [00:15<00:00, 56.16it/s]\n",
      "Epoch 6, Training Loss: 0.1609\n",
      "Epoch 6/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 162.19it/s]\n",
      "Epoch 6, Validation Loss: 0.1323\n",
      "Best model saved at ./model/name/bilstm.model with validation loss: 0.1323\n",
      "Epoch 7/10 (Training): 100%|██████████████████| 852/852 [00:15<00:00, 56.21it/s]\n",
      "Epoch 7, Training Loss: 0.1100\n",
      "Epoch 7/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 162.59it/s]\n",
      "Epoch 7, Validation Loss: 0.0848\n",
      "Best model saved at ./model/name/bilstm.model with validation loss: 0.0848\n",
      "Epoch 8/10 (Training): 100%|██████████████████| 852/852 [00:15<00:00, 56.29it/s]\n",
      "Epoch 8, Training Loss: 0.0722\n",
      "Epoch 8/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 163.26it/s]\n",
      "Epoch 8, Validation Loss: 0.0576\n",
      "Best model saved at ./model/name/bilstm.model with validation loss: 0.0576\n",
      "Epoch 9/10 (Training): 100%|██████████████████| 852/852 [00:15<00:00, 56.24it/s]\n",
      "Epoch 9, Training Loss: 0.0480\n",
      "Epoch 9/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 162.11it/s]\n",
      "Epoch 9, Validation Loss: 0.0425\n",
      "Best model saved at ./model/name/bilstm.model with validation loss: 0.0425\n",
      "Epoch 10/10 (Training): 100%|█████████████████| 852/852 [00:15<00:00, 56.17it/s]\n",
      "Epoch 10, Training Loss: 0.0348\n",
      "Epoch 10/10 (Validation): 100%|████████████████| 32/32 [00:00<00:00, 164.90it/s]\n",
      "Epoch 10, Validation Loss: 0.0339\n",
      "Best model saved at ./model/name/bilstm.model with validation loss: 0.0339\n",
      "\n",
      "real\t2m36.330s\n",
      "user\t2m37.374s\n",
      "sys\t0m0.887s\n",
      "Text generation:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "Generated Text 1: ရဲ အ မွေ အ ဣန္ဒ အ ဣန္ဒ ဣန္ဒ ဣန္ဒ ဣန္ဒ မွေ ဆီး ဆီး ဆီး အ ဣန္ဒ ဣန္ဒ ဣန္ဒ မွေ ဣန္ဒ ဂန္ဓ မွေ လို ဣန္ဒ ဘောက် ဣန္ဒ အ ဣန္ဒ ဂန္ဓ လို ဣန္ဒ မွေ ဣန္ဒ ကျစ် ဣန္ဒ ဣန္ဒ ကျစ် ဣန္ဒ မွေ မွေ အ မွေ ဘောက် ဣန္ဒ လို အ ဣန္ဒ ဣန္ဒ ဣန္ဒ ဣန္ဒ ဘောက်\n",
      "Generated Text 2: ရဲ ဣန္ဒ ဣန္ဒ ဘောက် လို လို ဆီး မွေ ဘောက် ဂန္ဓ မွေ ဂန္ဓ ဘောက် အ ဣန္ဒ ကျစ် အ ဣန္ဒ လို ဘောက် မွေ ကျစ် မွေ မွေ ဣန္ဒ ဣန္ဒ အ ဣန္ဒ မွေ အ မွေ ဂန္ဓ ဣန္ဒ ဣန္ဒ မွေ ဣန္ဒ ဣန္ဒ လို ဂန္ဓ မွေ ဣန္ဒ ဣန္ဒ ကျစ် မွေ ဣန္ဒ ဣန္ဒ အ ဣန္ဒ ဣန္ဒ [PAD] [PAD]\n",
      "Generated Text 3: ရဲ မွေ မွေ ဣန္ဒ ဣန္ဒ ဣန္ဒ ကျစ် အ ဣန္ဒ ဣန္ဒ ကျစ် အ ဣန္ဒ ဣန္ဒ ဂန္ဓ လို ဣန္ဒ ဣန္ဒ မွေ ကျစ် အ ဣန္ဒ ဣန္ဒ ကျစ် ဘောက် အ ကျစ် ဣန္ဒ မွေ ဣန္ဒ မွေ လို မွေ မွေ လို မွေ ဣန္ဒ အ မွေ မွေ ဂန္ဓ ဣန္ဒ ဣန္ဒ ဣန္ဒ ဣန္ဒ ဣန္ဒ ဂန္ဓ မွေ လို ဣန္ဒ [PAD]\n",
      "Generated Text 4: ရဲ မွေ ဣန္ဒ လို ဂန္ဓ ဘောက် ဣန္ဒ ဣန္ဒ လို လို ဣန္ဒ ဣန္ဒ ဣန္ဒ အ ဘောက် အ ဣန္ဒ ဣန္ဒ မွေ မွေ ဣန္ဒ မွေ အ ဣန္ဒ လို ဣန္ဒ ဘောက် ဘောက် မွေ လို ဣန္ဒ ဣန္ဒ အ လို ကျစ် အ ဘောက် အ အ ကျစ် အ လို မွေ မွေ ဂန္ဓ ဆီး လို မွေ အ ဣန္ဒ ဣန္ဒ\n",
      "Generated Text 5: ရဲ ဣန္ဒ လို လို အ အ ဣန္ဒ ဣန္ဒ ဣန္ဒ အ ဣန္ဒ ဣန္ဒ အ ဣန္ဒ လို မွေ အ မွေ ဘောက် မွေ ဣန္ဒ မွေ မွေ ကျစ် လို အ မွေ ဣန္ဒ လို မွေ ဣန္ဒ အ အ မွေ ဣန္ဒ အ ဣန္ဒ ဣန္ဒ မွေ ဘောက် မွေ ဣန္ဒ ဣန္ဒ ဣန္ဒ ဣန္ဒ [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Generated Text 6: ရဲ ဂန္ဓ ဘောက် ဂန္ဓ အ ဣန္ဒ ဣန္ဒ ဣန္ဒ မွေ ဣန္ဒ မွေ ဘောက် မွေ လို ဣန္ဒ အ မွေ ဘောက် မွေ ဣန္ဒ လို ဣန္ဒ ဘောက် မွေ ကျစ် အ ဆီး မွေ မွေ ဣန္ဒ လို ဣန္ဒ ဣန္ဒ ဣန္ဒ ဣန္ဒ ဣန္ဒ မွေ ဣန္ဒ မွေ ဂန္ဓ ဣန္ဒ ကျစ် ဣန္ဒ ဣန္ဒ ဣန္ဒ ဣန္ဒ ဣန္ဒ အ ဆီး ဣန္ဒ ဣန္ဒ\n",
      "Generated Text 7: ရဲ ဣန္ဒ အ မွေ ဣန္ဒ လို ကျစ် လို အ ဂန္ဓ အ ဣန္ဒ ဣန္ဒ ဣန္ဒ ဣန္ဒ ဣန္ဒ ဣန္ဒ အ လို ဣန္ဒ လို ကျစ် ဂန္ဓ ကျစ် ဂန္ဓ အ လို မွေ မွေ ဣန္ဒ ဣန္ဒ လို ကျစ် အ မွေ အ ဘောက် အ မွေ ဘောက် လို ဘောက် ကျစ် ကျစ် ဣန္ဒ ဣန္ဒ မွေ [PAD] [PAD] [PAD] [PAD]\n",
      "Generated Text 8: ရဲ မွေ လို ကျစ် အ ဣန္ဒ ဣန္ဒ ဣန္ဒ ဣန္ဒ အ မွေ ဣန္ဒ လို ကျစ် ဣန္ဒ ဆီး ဣန္ဒ ဣန္ဒ ဂန္ဓ ဣန္ဒ လို ဂန္ဓ ဣန္ဒ ဣန္ဒ မွေ မွေ လို ကျစ် မွေ ဣန္ဒ ကျစ် အ ဣန္ဒ မွေ လို ကျစ် ဣန္ဒ ဘောက် ကျစ် အ မွေ မွေ မွေ မွေ လို ဣန္ဒ ဣန္ဒ ဣန္ဒ [PAD] [PAD] [PAD]\n",
      "Generated Text 9: ရဲ မွေ ဂန္ဓ ဆီး မွေ ဂန္ဓ လို လို ဣန္ဒ ဘောက် အ မွေ ဘောက် ဣန္ဒ အ မွေ ဣန္ဒ ဘောက် ဣန္ဒ ဣန္ဒ မွေ ဣန္ဒ အ ကျစ် လို မွေ ဣန္ဒ အ ဂန္ဓ ဣန္ဒ လို ဣန္ဒ အ ဂန္ဓ အ ဣန္ဒ ဣန္ဒ ဣန္ဒ ဂန္ဓ အ အ အ ကျစ် အ လို အ လို ကျစ် မွေ မွေ ကျစ်\n",
      "Generated Text 10: ရဲ ဂန္ဓ ဣန္ဒ အ ဣန္ဒ မွေ ဣန္ဒ ဣန္ဒ လို ဣန္ဒ အ ဂန္ဓ ကျစ် အ ဣန္ဒ လို ဂန္ဓ ဣန္ဒ ဘောက် ဆီး ကျစ် ဣန္ဒ လို အ မွေ မွေ လို ဣန္ဒ ဘောက် မွေ အ ဘောက် မွေ လို ဣန္ဒ ဣန္ဒ မွေ ဣန္ဒ ဣန္ဒ အ ဣန္ဒ ဣန္ဒ ဣန္ဒ ဣန္ဒ ဂန္ဓ မွေ ဣန္ဒ ဣန္ဒ [PAD] [PAD] [PAD]\n",
      "\n",
      "real\t0m1.639s\n",
      "user\t0m3.928s\n",
      "sys\t0m0.243s\n",
      "Batch text generation from file:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Random Prompt Generated: ရီ\n",
      "Generated texts saved to ./output/name/bilstm_gen_texts.txt\n",
      "\n",
      "real\t0m1.481s\n",
      "user\t0m3.765s\n",
      "sys\t0m0.252s\n",
      "Testing:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:216: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Testing: 100%|██████████| 16/16 [00:00<00:00, 42.35it/s]\n",
      "Average Perplexity on Test Data: 1.0302\n",
      "Average Cross-Entropy on Test Data: 0.0297\n",
      "\n",
      "real\t0m1.505s\n",
      "user\t0m3.821s\n",
      "sys\t0m0.224s\n",
      "Training Transformer language model:\n",
      "Epoch 1/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 195.73it/s]\n",
      "Epoch 1, Training Loss: 0.2428\n",
      "Epoch 1/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 593.73it/s]\n",
      "Epoch 1, Validation Loss: 0.0430\n",
      "Best model saved at ./model/name/transformer.model with validation loss: 0.0430\n",
      "Epoch 2/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 208.94it/s]\n",
      "Epoch 2, Training Loss: 0.0290\n",
      "Epoch 2/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 575.39it/s]\n",
      "Epoch 2, Validation Loss: 0.0209\n",
      "Best model saved at ./model/name/transformer.model with validation loss: 0.0209\n",
      "Epoch 3/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 207.00it/s]\n",
      "Epoch 3, Training Loss: 0.0152\n",
      "Epoch 3/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 601.18it/s]\n",
      "Epoch 3, Validation Loss: 0.0133\n",
      "Best model saved at ./model/name/transformer.model with validation loss: 0.0133\n",
      "Epoch 4/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 206.37it/s]\n",
      "Epoch 4, Training Loss: 0.0096\n",
      "Epoch 4/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 598.96it/s]\n",
      "Epoch 4, Validation Loss: 0.0093\n",
      "Best model saved at ./model/name/transformer.model with validation loss: 0.0093\n",
      "Epoch 5/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 208.27it/s]\n",
      "Epoch 5, Training Loss: 0.0066\n",
      "Epoch 5/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 583.85it/s]\n",
      "Epoch 5, Validation Loss: 0.0070\n",
      "Best model saved at ./model/name/transformer.model with validation loss: 0.0070\n",
      "Epoch 6/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 208.72it/s]\n",
      "Epoch 6, Training Loss: 0.0047\n",
      "Epoch 6/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 579.41it/s]\n",
      "Epoch 6, Validation Loss: 0.0056\n",
      "Best model saved at ./model/name/transformer.model with validation loss: 0.0056\n",
      "Epoch 7/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 207.84it/s]\n",
      "Epoch 7, Training Loss: 0.0033\n",
      "Epoch 7/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 584.70it/s]\n",
      "Epoch 7, Validation Loss: 0.0048\n",
      "Best model saved at ./model/name/transformer.model with validation loss: 0.0048\n",
      "Epoch 8/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 208.81it/s]\n",
      "Epoch 8, Training Loss: 0.0024\n",
      "Epoch 8/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 576.99it/s]\n",
      "Epoch 8, Validation Loss: 0.0043\n",
      "Best model saved at ./model/name/transformer.model with validation loss: 0.0043\n",
      "Epoch 9/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 208.30it/s]\n",
      "Epoch 9, Training Loss: 0.0017\n",
      "Epoch 9/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 599.84it/s]\n",
      "Epoch 9, Validation Loss: 0.0039\n",
      "Best model saved at ./model/name/transformer.model with validation loss: 0.0039\n",
      "Epoch 10/10 (Training): 100%|████████████████| 852/852 [00:04<00:00, 208.20it/s]\n",
      "Epoch 10, Training Loss: 0.0012\n",
      "Epoch 10/10 (Validation): 100%|████████████████| 32/32 [00:00<00:00, 589.44it/s]\n",
      "Epoch 10, Validation Loss: 0.0038\n",
      "Best model saved at ./model/name/transformer.model with validation loss: 0.0038\n",
      "\n",
      "real\t0m43.419s\n",
      "user\t0m45.387s\n",
      "sys\t0m0.361s\n",
      "Text generation:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Generated Text 1: ရဲ သိမ် ဖား တော် ရူ မုန် ဟုမ် တော် လှိုင်း ရုဏ်း ရုဏ်း ချောင် ဂွိ စောလ် ရုဏ်း ရုဏ်း သိဉ္စည်း ရုဏ်း ရုဏ်း သိဉ္စည်း တော် ခေး ရှောင် ဂဂ် ရုဏ်း ရုဏ်း ချောင် ရုဏ်း ရုဏ်း ရှောင် ဂဂ် စောလ် ရှောင် ရုဏ်း ရှောင် ရုဏ်း ရုဏ်း ချောင် ရုဏ်း ရုဏ်း စောလ် ရှောင် ရုဏ်း ရုဏ်း ရှောင် ချောင် ရုဏ်း တော် ရုဏ်း ရုဏ်း ရှောင်\n",
      "Generated Text 2: ရဲ ယိမ့် ရုဏ်း ရှောင် ဘွိုင်း ရုဏ်း ရှောင် ရုဏ်း ရှောင် ရုဏ်း စောလ် ရုဏ်း ရုဏ်း တော် ဇံ ရုဏ်း ရှောင် ရုဏ်း စောလ် တော် ထက် ဆဲလ် ရုဏ်း စောလ် ရုဏ်း ဂဂ် ရုဏ်း သိဉ္စည်း ရှောင် ရှောင် ရုဏ်း ရုဏ်း ရှောင် ရုဏ်း လွန် ရုဏ်း ရုဏ်း ရုဏ်း တော် ရုဏ်း ရုဏ်း ချောင် ရုဏ်း ရှောင် ရုဏ်း ရုဏ်း ဂဂ် လွန် ရုဏ်း ရှောင် ရုဏ်း\n",
      "Generated Text 3: ရဲ ရိုင်းန် သိဉ္စည်း ရုဏ်း ရှောင် ဆွင်း ရုဏ်း ဂဂ် ရုဏ်း သိဉ္စည်း ဂဂ် ရုဏ်း ရှောင် သိဉ္စည်း ဂဂ် သိဉ္စည်း စောလ် တော် မိုင် ဗစ် ရုဏ်း စောလ် ရှောင် ရုဏ်း ရုဏ်း ရုဏ်း ဂဂ် ရုဏ်း ရုဏ်း ရုဏ်း ရှောင် ရုဏ်း ရုဏ်း ရုဏ်း ရုဏ်း ရုဏ်း ရှောင် တော် ရုဏ်း ဂဂ် ရုဏ်း ရုဏ်း လွန် ရုဏ်း လွန် ချောင် သိဉ္စည်း စောလ် ဂဂ် ရုဏ်း ဂဂ်\n",
      "Generated Text 4: ရဲ စည်း ဌေ ချောင် ရုဏ်း ရှောင် ရုဏ်း ရှောင် တော် စန္ဒ ကျူး ရှောင် သိဉ္စည်း ရုဏ်း ရုဏ်း ရုဏ်း ရုဏ်း ရှောင် ရုဏ်း လွန် ဂဂ် ရုဏ်း ချောင် ချောင် ရုဏ်း တော် ရှောင် ရုဏ်း ရှောင် ရုဏ်း ရုဏ်း သိဉ္စည်း တော် ဟ ညိမ့် တော် ရုပ် ရုဏ်း ရုဏ်း ရုဏ်း သိဉ္စည်း ချောင် ချောင် လွန် ရုဏ်း တော် ဗျာလ် တော် ရုဏ်း ရှောင် ရုဏ်း\n",
      "Generated Text 5: ရဲ ကြော့ ဂျမ်း ဒွပ် စောလ် ဇူး ယျန် ရုဏ်း ရုဏ်း ရုဏ်း ရုဏ်း တော် တီးလ် ရှောင် ရုဏ်း ရုဏ်း ရှောင် ရုဏ်း ရုဏ်း တော် အုန်း ခ ညား ရုဏ်း ရှောင် ရုဏ်း ရုဏ်း စောလ် တော် ဒူ ရုဏ်း ရုဏ်း တော် နော် အဲင်း ရှောင် စောလ် ရုဏ်း စောလ် ရုဏ်း ရှောင် ချောင် ရုဏ်း စောလ် ရုဏ်း ရှောင် ရုဏ်း တော် ရုဏ်း ရုဏ်း လွန်\n",
      "Generated Text 6: ရဲ သီ ခါး မွေး ယန်း ရယ်လ် ရုဏ်း ရုဏ်း ရုဏ်း ဂဂ် ဂဂ် တော် အိင်္ခ ရုဏ်း စောလ် ချောင် ရုဏ်း ရုဏ်း ရုဏ်း ရှောင် ရုဏ်း ရုဏ်း တော် စင်္ကြာ ရှောင် ရုဏ်း တော် ဘက် ရုဏ်း ရုဏ်း ရုဏ်း ရုဏ်း ရှောင် ရုဏ်း ရုဏ်း ရုဏ်း ရုဏ်း ရှောင် ရုဏ်း လွန် စောလ် စောလ် ရုဏ်း ရုဏ်း ဂဂ် ရုဏ်း သိဉ္စည်း ရုဏ်း ချောင် တော် ကင်းမ်\n",
      "Generated Text 7: ရဲ သိန်း ပါ့ တီ ကြုံ ရုဏ်း ရှောင် ရုဏ်း ရုဏ်း ဂဂ် တော် သွေး ညွှန့် ဂဂ် ချောင် တော် ယား ရုဏ်း ရုဏ်း တော် ဂျွန်း ရုဏ်း ဂဂ် ရုဏ်း ရှောင် ရုဏ်း လွန် ရုဏ်း ရုဏ်း တော် ရုဏ်း ရုဏ်း ချောင် ရုဏ်း လွန် ရုဏ်း တော် လာန် ရုဏ်း ဂဂ် ရုဏ်း တော် ခေါက် ရုဏ်း ဂဂ် ရုဏ်း ရုဏ်း ရုဏ်း စောလ် ရုဏ်း တော်\n",
      "Generated Text 8: ရဲ ပြည် ဓမ္မာ ရုဏ်း ရုဏ်း ရုဏ်း ရုဏ်း တော် ကျုံ ရုဏ်း ချောင် ရှောင် သိဉ္စည်း ရုဏ်း ဂဂ် ရုဏ်း ရုဏ်း ရှောင် စောလ် ရှောင် တော် လဲလ် တော် ဘီ သူ နွံ ရုဏ်း စောလ် ရုဏ်း ရုဏ်း တော် ပွဲ ရုဏ်း ရုဏ်း ရှောင် ရုဏ်း ဂဂ် ရုဏ်း ဂဂ် ရှောင် ရုဏ်း တော် ဂူ သိဉ္စည်း ရုဏ်း ရုဏ်း တော် ရုဏ်း တော် ကော့ ရုဏ်း\n",
      "Generated Text 9: ရဲ ရ လာလ် ဗွီ သုန် ရှုံး ရှောင် ရုဏ်း တော် ရွှေ့ ချောင် ဂဂ် ရှောင် သိဉ္စည်း ချောင် ချောင် တော် အစ္စ ရုဏ်း ချောင် တော် ဆု သိ ရုဏ်း လွန် ရုဏ်း တော် ကု ဂဂ္ဂါး ရုဏ်း ရုဏ်း ရှောင် တော် ရုံ စောလ် ရုဏ်း ရုဏ်း ရှောင် ရှောင် ရုဏ်း ချောင် ချောင် ဂဂ် ရုဏ်း တော် ဆမ် ရုဏ်း ရုဏ်း ဂဂ် ဂဂ် တော်\n",
      "Generated Text 10: ရဲ ပြုံ ရုဏ်း ရှောင် ထာရ် ရုဏ်း ရှောင် ရုဏ်း ရှောင် ရုဏ်း တော် ကြောင် ရုဏ်း ရုဏ်း ရုဏ်း သိဉ္စည်း သိဉ္စည်း ရုဏ်း ရုဏ်း ရုဏ်း ရုဏ်း ရှောင် ရှောင် စောလ် ရုဏ်း တော် တော် ဘွယ် ရှောင် တော် ရုဏ်း တော် လက္ခ တော် ရွိုင် ရုဏ်း စောလ် ရုဏ်း ဂဂ် ရှောင် ရုဏ်း ဂဂ် ရှောင် ရုဏ်း လွန် ရုဏ်း ရုဏ်း ရှောင် စောလ် ရှောင် ရုဏ်း\n",
      "\n",
      "real\t0m1.862s\n",
      "user\t0m4.172s\n",
      "sys\t0m0.232s\n",
      "Batch text generation from file:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Random Prompt Generated: ဆုံး\n",
      "Generated texts saved to ./output/name/transformer_gen_texts.txt\n",
      "\n",
      "real\t0m1.471s\n",
      "user\t0m3.791s\n",
      "sys\t0m0.217s\n",
      "Testing:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:216: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Testing: 100%|██████████| 16/16 [00:00<00:00, 51.35it/s]\n",
      "Average Perplexity on Test Data: 1.0037\n",
      "Average Cross-Entropy on Test Data: 0.0037\n",
      "\n",
      "real\t0m1.254s\n",
      "user\t0m3.602s\n",
      "sys\t0m0.192s\n",
      "Training Bert language model:\n",
      "Epoch 1/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 194.08it/s]\n",
      "Epoch 1, Training Loss: 0.2490\n",
      "Epoch 1/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 524.65it/s]\n",
      "Epoch 1, Validation Loss: 0.0447\n",
      "Best model saved at ./model/name/bert.model with validation loss: 0.0447\n",
      "Epoch 2/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 209.64it/s]\n",
      "Epoch 2, Training Loss: 0.0292\n",
      "Epoch 2/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 594.89it/s]\n",
      "Epoch 2, Validation Loss: 0.0215\n",
      "Best model saved at ./model/name/bert.model with validation loss: 0.0215\n",
      "Epoch 3/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 209.13it/s]\n",
      "Epoch 3, Training Loss: 0.0152\n",
      "Epoch 3/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 582.07it/s]\n",
      "Epoch 3, Validation Loss: 0.0138\n",
      "Best model saved at ./model/name/bert.model with validation loss: 0.0138\n",
      "Epoch 4/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 209.54it/s]\n",
      "Epoch 4, Training Loss: 0.0096\n",
      "Epoch 4/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 588.79it/s]\n",
      "Epoch 4, Validation Loss: 0.0098\n",
      "Best model saved at ./model/name/bert.model with validation loss: 0.0098\n",
      "Epoch 5/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 208.82it/s]\n",
      "Epoch 5, Training Loss: 0.0066\n",
      "Epoch 5/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 589.30it/s]\n",
      "Epoch 5, Validation Loss: 0.0073\n",
      "Best model saved at ./model/name/bert.model with validation loss: 0.0073\n",
      "Epoch 6/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 208.56it/s]\n",
      "Epoch 6, Training Loss: 0.0047\n",
      "Epoch 6/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 588.00it/s]\n",
      "Epoch 6, Validation Loss: 0.0058\n",
      "Best model saved at ./model/name/bert.model with validation loss: 0.0058\n",
      "Epoch 7/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 209.29it/s]\n",
      "Epoch 7, Training Loss: 0.0033\n",
      "Epoch 7/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 585.58it/s]\n",
      "Epoch 7, Validation Loss: 0.0048\n",
      "Best model saved at ./model/name/bert.model with validation loss: 0.0048\n",
      "Epoch 8/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 203.71it/s]\n",
      "Epoch 8, Training Loss: 0.0024\n",
      "Epoch 8/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 581.93it/s]\n",
      "Epoch 8, Validation Loss: 0.0043\n",
      "Best model saved at ./model/name/bert.model with validation loss: 0.0043\n",
      "Epoch 9/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 205.28it/s]\n",
      "Epoch 9, Training Loss: 0.0017\n",
      "Epoch 9/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 595.12it/s]\n",
      "Epoch 9, Validation Loss: 0.0040\n",
      "Best model saved at ./model/name/bert.model with validation loss: 0.0040\n",
      "Epoch 10/10 (Training): 100%|████████████████| 852/852 [00:04<00:00, 204.96it/s]\n",
      "Epoch 10, Training Loss: 0.0012\n",
      "Epoch 10/10 (Validation): 100%|████████████████| 32/32 [00:00<00:00, 600.38it/s]\n",
      "Epoch 10, Validation Loss: 0.0038\n",
      "Best model saved at ./model/name/bert.model with validation loss: 0.0038\n",
      "\n",
      "real\t0m43.497s\n",
      "user\t0m45.376s\n",
      "sys\t0m0.350s\n",
      "Text generation:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Generated Text 1: ရဲ ကြေး ချင် ပံ ဂန္ဓာ ဂန္ဓာ ကျူ ဂန္ဓာ ယ ချူ ယ ဘူး ဂန္ဓာ ယ မြ သိင်္ခ ဂန္ဓာ ဂန္ဓာ ကျူ ဂန္ဓာ ယ ဖုန်း ကန် ဂန္ဓာ အိမ် သ ဘို့ ထာ ဂန္ဓာ ဂန္ဓာ ဂန္ဓာ ယ ရော် ဂန် ကျူ ကျူ နှဲမ် ယ ရု ဂန္ဓာ ယ ခိုင် စဲ ခံ ဂန္ဓာ ကျူ လု ငြိမ် နစ် ဇမ်း ဂန္ဓာ\n",
      "Generated Text 2: ရဲ ဟိမ်း ဂန္ဓာ ဂန္ဓာ ဂန္ဓာ ဂန္ဓာ ဂန္ဓာ ဂန္ဓာ ဇမ်း ဂန္ဓာ ကျူ ဂန္ဓာ ကျူ ဂန္ဓာ ဇမ်း ယ ဟင် ငြိမ် ထာ ဂန္ဓာ ဂန္ဓာ ဂန္ဓာ ယ ယက် ကျူ ဂန္ဓာ အိမ် ဗျော ထာ ဂန္ဓာ ကျူ ဂန္ဓာ အိမ် ခူး ဂန္ဓာ ခံ ကျူ ယ အောင်း ငြိမ် ခံ ယ ကော ဂန္ဓာ ဂန္ဓာ ဂန္ဓာ ကျူ ဂန္ဓာ ဂန္ဓာ ကျူ ယ\n",
      "Generated Text 3: ရဲ ဖား ဂန္ဓာ ဂန္ဓာ ဂန္ဓာ ဂန္ဓာ ကျူ ဂန္ဓာ ဂန္ဓာ ဇမ်း ဂန္ဓာ ဂန္ဓာ ဂန္ဓာ ယ စု လျှို ယ ဘွဲ့ ဉာဏ် ချိ ထာ ဂန္ဓာ ယ ကဲ ပို နှဲမ်း ဂန္ဓာ ငြိမ် ဇမ်း ကျူ ဂန္ဓာ ငြိမ် ငြိမ် ဂန္ဓာ ကျူ ဂန္ဓာ ယ နင် ကျူ ကျူ ဂန္ဓာ ယ မဲ့ ယ အံ ကျူ လု ကျူ ကျူ ခံ အိမ်\n",
      "Generated Text 4: ရဲ ပွင့် ချောက် ဂန္ဓာ ဂန္ဓာ ဂန္ဓာ ဂန္ဓာ ဂန္ဓာ ဂန္ဓာ ဂန္ဓာ အိမ် ဒိမ် ဂန္ဓာ ငြိမ် ယ သျှင် ဂန္ဓာ ကျူ ကျူ ဂန္ဓာ အိမ် ဂန္ဓာ ယ သိုက် နန်း ဂန္ဓာ ကျူ ယ နွန် ဇ ပစ် ခံ ဇမ်း ငြိမ် ဂန္ဓာ ထာ နှဲမ် ဂန္ဓာ ခံ ကျူ ယ ဗ နစ် ကျူ ဂန္ဓာ ကျူ လု ဂန္ဓာ ဂန္ဓာ ခံ ထာ\n",
      "Generated Text 5: ရဲ အီ စု ဿန်း ဂန္ဓာ ငြိမ် အိမ် ငြိမ့် ငြိမ် ယ သဉ္စာ ငြိမ် အိမ် ဣန္ဒြေ ဂန္ဓာ ခံ ကျူ ကျူ ဂန္ဓာ ယ တီးလ် ကျူ ကျူ ဂန္ဓာ ဂန္ဓာ ကျူ ကျူ ဂန္ဓာ အိမ် ဆုံး ဂန္ဓာ ဇမ်း ဂန္ဓာ ဂန္ဓာ ယ မြီ ကျူ ကျူ ဂန္ဓာ ကျူ အိမ် တင်း ဂန္ဓာ အိမ် ဒ ဘု ဂန္ဓာ ယ နန္ဒီ ကြည် ရဲ\n",
      "Generated Text 6: ရဲ ဆွမ် ဂန္ဓာ ဂန္ဓာ ငြိမ် ဂန္ဓာ ကျူ ဂန္ဓာ ကျူ ဂန္ဓာ ခံ ကျူ ဂန္ဓာ ယ ဓါန် ဂန္ဓာ ဂန္ဓာ ဂန္ဓာ ဇမ်း ကျူ အိမ် ဂန္ဓာ ကျူ ငြိမ် ဂန္ဓာ အိမ် ရိုး မှိုင်း ချူး ကျူ ယ ချုံး ဇမ်း ဂန္ဓာ ဂန္ဓာ ယ ပြန် ဂန္ဓာ ခံ ယ သစ် သောက် အိမ် ဘူး ဂန္ဓာ ဂန္ဓာ အိမ် အိန္ဓု ကျူ ဂန္ဓာ ဂန္ဓာ\n",
      "Generated Text 7: ရဲ ရွယ် မို ဝင့် သော် ရှု ထား အိန္ဒြာ ဖော် ဂန္ဓာ ယ လျှမ် ဇမ်း ယ တော် ဂန္ဓာ ဂန္ဓာ ကျူ ဂန္ဓာ ခံ ကျူ အိမ် ဇင် ဆည်း ပါယ် ယ ဝ ထွဏ်း ဂန္ဓာ ဂန္ဓာ ဂန္ဓာ ထာ ဂန္ဓာ အိမ် မြို့ ကျူ နှဲမ် ပိုင် ရှိမ်း ယ လွန် ဗာ ဂန္ဓာ ယ ဆောမ်း ဂန္ဓာ ဂန္ဓာ ခံ ကျူ ယ အုတ်\n",
      "Generated Text 8: ရဲ ဒို ဇမ်း ဟို့စ် ဂန္ဓာ ငြိမ် ဂန္ဓာ ကျူ ဂန္ဓာ ကျူ ယ ရွတ် ဂန္ဓာ ဂန္ဓာ ငြိမ် ဂန္ဓာ ဂန္ဓာ ကျူ ဂန္ဓာ ဇမ်း ငြိမ် ကျူ ဂန္ဓာ ဂန္ဓာ ကျူ ဂန္ဓာ ခံ အိမ် ဟွ ဂန္ဓာ ဂန္ဓာ ငြိမ် ကျူ ဂန္ဓာ ခံ ငြိမ် ကျူ ဂန္ဓာ ငြိမ် ကျူ ကျူ ဂန္ဓာ ငြိမ် ဂန္ဓာ ငြိမ် ခံ ငြိမ် အိမ် ထိုက် ပုံ ဂန္ဓာ\n",
      "Generated Text 9: ရဲ မဲလ် ကျူ ရင်း သိုင်း ခင် ငြိမ့် ဂန္ဓာ ထာ ဂန္ဓာ အိမ် သဉ္စာ ခံ အိမ် ဂျမ်း ခံ ငြိမ် ငြိမ် ခံ အိမ် သိန်း ရည် ဂန္ဓာ ယ စန်း ဟို ဂန္ဓာ ခံ ဇမ်း ဇမ်း အိမ် ဝိုင်း ဂန္ဓာ ဇမ်း ကျူ ငြိမ် ငြိမ် ခံ ငြိမ် ဇမ်း အိမ် ဟာ ခါ အိမ် လှိုင်း ချောင် အိမ် လျာ အံ့ ဂျား ဂန္ဓာ\n",
      "Generated Text 10: ရဲ ဆံ ဖုန် ဂန္ဓာ ဂန္ဓာ ဂန္ဓာ ဂန္ဓာ ငြိမ် ဂန္ဓာ ဂန္ဓာ ခံ ကျူ ယ နပ် ကျူ အိမ် ဆုန်း ဂန္ဓာ ကျူ ဂန္ဓာ ဇမ်း ယ ကျင် ဂန္ဓာ ဂန္ဓာ အိမ် ဟတ် ခံ ဂန္ဓာ ယ ဆောင်း ဂန္ဓာ ဂန္ဓာ ငြိမ် ဂန္ဓာ ငြိမ် ကျူ ဂန္ဓာ ခံ ဂန္ဓာ ယ ကွတ် ကျူ ဂန္ဓာ ခံ ထာ နှဲမ် ဂန္ဓာ ဂန္ဓာ အိမ် တိုး\n",
      "\n",
      "real\t0m1.862s\n",
      "user\t0m4.167s\n",
      "sys\t0m0.231s\n",
      "Batch text generation from file:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Random Prompt Generated: ဒါးလ်\n",
      "Generated texts saved to ./output/name/bert_gen_texts.txt\n",
      "\n",
      "real\t0m1.441s\n",
      "user\t0m3.727s\n",
      "sys\t0m0.223s\n",
      "Testing:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:216: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Testing: 100%|██████████| 16/16 [00:00<00:00, 51.34it/s]\n",
      "Average Perplexity on Test Data: 1.0038\n",
      "Average Cross-Entropy on Test Data: 0.0038\n",
      "\n",
      "real\t0m1.236s\n",
      "user\t0m3.579s\n",
      "sys\t0m0.195s\n",
      "Training Gpt language model:\n",
      "Epoch 1/10 (Training): 100%|█████████████████| 852/852 [00:04<00:00, 204.81it/s]\n",
      "Epoch 1, Training Loss: 0.0677\n",
      "Epoch 1/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 589.66it/s]\n",
      "Epoch 1, Validation Loss: 0.0016\n",
      "Best model saved at ./model/name/gpt.model with validation loss: 0.0016\n",
      "Epoch 2/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 218.84it/s]\n",
      "Epoch 2, Training Loss: 0.0011\n",
      "Epoch 2/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 588.83it/s]\n",
      "Epoch 2, Validation Loss: 0.0004\n",
      "Best model saved at ./model/name/gpt.model with validation loss: 0.0004\n",
      "Epoch 3/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 218.79it/s]\n",
      "Epoch 3, Training Loss: 0.0004\n",
      "Epoch 3/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 590.49it/s]\n",
      "Epoch 3, Validation Loss: 0.0002\n",
      "Best model saved at ./model/name/gpt.model with validation loss: 0.0002\n",
      "Epoch 4/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 219.98it/s]\n",
      "Epoch 4, Training Loss: 0.0002\n",
      "Epoch 4/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 591.60it/s]\n",
      "Epoch 4, Validation Loss: 0.0001\n",
      "Best model saved at ./model/name/gpt.model with validation loss: 0.0001\n",
      "Epoch 5/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 219.99it/s]\n",
      "Epoch 5, Training Loss: 0.0001\n",
      "Epoch 5/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 587.42it/s]\n",
      "Epoch 5, Validation Loss: 0.0000\n",
      "Best model saved at ./model/name/gpt.model with validation loss: 0.0000\n",
      "Epoch 6/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 219.83it/s]\n",
      "Epoch 6, Training Loss: 0.0000\n",
      "Epoch 6/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 589.46it/s]\n",
      "Epoch 6, Validation Loss: 0.0000\n",
      "Best model saved at ./model/name/gpt.model with validation loss: 0.0000\n",
      "Epoch 7/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 219.08it/s]\n",
      "Epoch 7, Training Loss: 0.0000\n",
      "Epoch 7/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 589.03it/s]\n",
      "Epoch 7, Validation Loss: 0.0000\n",
      "Best model saved at ./model/name/gpt.model with validation loss: 0.0000\n",
      "Epoch 8/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 218.50it/s]\n",
      "Epoch 8, Training Loss: 0.0000\n",
      "Epoch 8/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 590.87it/s]\n",
      "Epoch 8, Validation Loss: 0.0000\n",
      "Best model saved at ./model/name/gpt.model with validation loss: 0.0000\n",
      "Epoch 9/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 215.60it/s]\n",
      "Epoch 9, Training Loss: 0.0000\n",
      "Epoch 9/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 586.78it/s]\n",
      "Epoch 9, Validation Loss: 0.0000\n",
      "Best model saved at ./model/name/gpt.model with validation loss: 0.0000\n",
      "Epoch 10/10 (Training): 100%|████████████████| 852/852 [00:03<00:00, 219.38it/s]\n",
      "Epoch 10, Training Loss: 0.0000\n",
      "Epoch 10/10 (Validation): 100%|████████████████| 32/32 [00:00<00:00, 590.98it/s]\n",
      "Epoch 10, Validation Loss: 0.0000\n",
      "Best model saved at ./model/name/gpt.model with validation loss: 0.0000\n",
      "\n",
      "real\t0m41.369s\n",
      "user\t0m42.861s\n",
      "sys\t0m0.378s\n",
      "Text generation:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Generated Text 1: ရဲ သျှန်း ထန် အိမ့် ပ သု ဟယ် ဇင် ကိစ္စ ကန် ဂေါင် အစ္စ လူ ဗင် ပြန်း ကြိုက် ညှာ ကြွ သန္ဒာ ခတ္တာ ရိုင်း အောန် လွှာ မဲလ် ကြွယ် ကွိဇ် ကျား သည်း စောမ် [PAD] နမ် ပုမ်း အဲလ် တည် ကမ် တိုင်း မွေး ကျိုင်း ပြည့် ဓူ ထန်း မီ အိမ့် သျှမ်း မှူး ဖြိုး သု မူး စီ တင် အိန္မာ\n",
      "Generated Text 2: ရဲ မြက် ကြို တောင်း ခံ့ အိင်္ခ နမ် နော ဟေ ဂျူး တီလ် ဒိမ့် ဆူ ဖွား လျော့ တုံး ကျဲရ် လုတ် ချယ်လ် ဂွိ ကင် ဖွယ် အဲလ် ဓမ္မာ လျံ ဝ ဝိ ငိုင် နှိုင်း ညှာ ဟွမ် လဲလ် လဲ့ ဖိန် ကျော နိုက် ဘယ်လ် ဝါလ် ဂျို မြ ညင် ကောလ် စောမ် ဆံ မှု သက် ဒွန်း အက္ခ မက် မာ စည်း\n",
      "Generated Text 3: ရဲ လက်ျာ ထင် အိန္တ တွဲ သိမ် ဟာ ကဲ ထိန် ရှောင် ဒွတ် နန် ထိန် သမ္မာ စုက္က ရှာ ဗာ ရွာ ဟက်ခ် ဗန်း နွမ်း ဆိုက် သင့် ထွေး ကတ် ခေါက် အဲ ရိ ရင်န် ရောင် တိ လျှံ ဖယ် အိန္နီ ဟေး အုံး သွေး သော့ မောင်း အော် ဂဂ္ဂါး ယက် လျှပ် ချောင်း ကျူ လဲစ် ဝတ် မော် ပြန့် အယ် စန္ဒီ\n",
      "Generated Text 4: ရဲ သိဏ်း မွမ် ဆယ် သော့ စဉ့် အမ္မ ရေ မင်္ဂ ဂျီး ထိန် မျိုး ရှာ ထာ မြက် ခူး ခိ တယ်လ် လက်ျာ အုံ ကျင် သျှ ရှား ငါး ပံ နဲမ်း ချုံ ထွတ် ဇယ် မ ဆေး အိန္ဒု ငဲ နား လျှံ ကြံ့ ကျွယ် ညက် မဉ္ဇူ တေ သဉ္ဇူ ထိုက် သိုက် လှိုင် ဘန့် မော နယ် ရောင်းန် သစ် ဇင်း လက္ခ\n",
      "Generated Text 5: ရဲ ရာဇ် ခေါလ် ဂျေ ကု ထဲမ်း ရောင်းန် မွှန်း ကော အဲင်န် ခြူး တို သဲ ညွန့် ကြော ဇေ ဒေါင့် ဗုံ ဟူ ရစ် ရိန် အော စို ခေါမ်း နွံ ဘိုင် လောင်း တိန့် ညောင် ကျင်း ဗျော သင်း ကွီး မိုင်း ကျော ရူ ခံ့ မောင်း ဖ ဂူး အိမ် တွမ်း ခွေး ရဲမ် ကြင်း အံ ငယ် စိ ထာရ် ဂျာလ် သဉ္ဇ\n",
      "Generated Text 6: ရဲ ဇမ် လာ ထွယ် ဝင် ဥမ္မာ ပပ်ဖ် နစ် ကျား ဟုန် ရိုင် ဟုမ် ချားလ် ဆမ်း လျံ ဟောမ်း မှိုင်း နင် ခင် သျှ ရေ့ဒ်ဗ် လဲ့ ဒေါ ရှိတ် လက္ခ ပွင့်် စမ်း အိုမ် အို ခြိမ့် ခင် စောလ် နု နွဲ့ ဖော် ကြောင် စိမ်း မဲ့ နာ့ ချန်း လ ကျောက် ဠာ ထီး အိဇ္ဇာ လှောန် ဆောင်း လျှို မှိုင် ပံ အက်\n",
      "Generated Text 7: ရဲ နောင့် ဂီ တန် ပါရ် ဝိ မိ အပ် ကွယ် ဂျော် စန် အဂ္ဂ ဘာ ဂိုး ဒြာ ဘုံ ကင် ဖွား ယူ ဟို့စ် ရွက် ယိမ့် ဂတ် ဗင် သော့ အောလ် မွန်း ဟီး နာ ဝယ်လ် ကျင်း ဆား အဲင်း ပင် စင်္ကြာ ဟောမ်း ချောင်း ဇေါင်း ချိ ခုပ် ဆီး လျှံ ခိုင် ဆိုက် အဲန်း ကောင်း ဇုံ မဲ့ ပြောင် ခေါမ်း ဘွိုင်း\n",
      "Generated Text 8: ရဲ ထွေ ဆားရ် ပေး အုပ် နွန်း အယ် ချမ်း သျှ ကွေ့ နဲမ် ရှမ်း ခူး ဖွာ ခယ် မိုက် ဒမ်း ဂျို ကိမ်း ဂဂ္ဂါ ကြံ့ ချို တွေ ဗျာလ် ပြိုင် မိုက် ဆိုင်း ထော် ဆွယ် နွေ စမ်း တန့် ယူ သောက် အိန္ဓု ကွတ် အေး ချန်း ဟီး ဗန် လဲန်း ကော့ ကျွယ် တီးလ် ပြန် သိဒ္ဓိ စွာ ဝဏ် ဂျူး ဆံ လှောင်\n",
      "Generated Text 9: ရဲ ရှင်း ကွန် ဂျူ လဲစ် ကုန် အိန္နီ သွန်း ဗဲလ် မိန်း သြ လိန် မဲန်း ခံ့ ရ ဒွန်း ကြံ ကြွက် ဂိုးလ် ခြာ ကျင် လုံ ရှား ဆုံး နံ့ ဇာ ဥမ္မာ အော သေး ဝမ်း ထိပ် တောင် နေး ချေ အား ယိန်း ကြံ သောက် ဥက္ကာ သန် ယှဉ် ကွန့် ကိ လိန်း လွန်း ကိ တေ့ ရဲ့ လင် သတ္တိ လက်ျာ\n",
      "Generated Text 10: ရဲ ကြိုး မိန်း ရာ တေ့ ကြော ဆင့် ထ ခူး မွမ်း ချက်ထ် ဗျာ ရှယ် သွဲ့ လှောန် နှစ် ကီ ဗွီ ဆောင် ဖြာ မိ သီ စဲ သား ပွါ ပြုံး တင်း စေး မွမ်း ကြော ထန်း မှိုင်း ညိမ့် စက်ဖ် ကြင်း ကြူ မွေ တီး အိန္တ ခယ် ကွပ် ဒို သဉ္ဇာ ဖြာ ရီး ခြယ် တွဲ မွေ့ ဘောမ် နု ပယ်လ်\n",
      "\n",
      "real\t0m1.844s\n",
      "user\t0m4.149s\n",
      "sys\t0m0.236s\n",
      "Batch text generation from file:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Random Prompt Generated: လျံ\n",
      "Generated texts saved to ./output/name/gpt_gen_texts.txt\n",
      "\n",
      "real\t0m1.449s\n",
      "user\t0m3.758s\n",
      "sys\t0m0.232s\n",
      "Testing:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:216: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Testing: 100%|██████████| 16/16 [00:00<00:00, 50.30it/s]\n",
      "Average Perplexity on Test Data: 1.0000\n",
      "Average Cross-Entropy on Test Data: 0.0000\n",
      "\n",
      "real\t0m1.273s\n",
      "user\t0m3.617s\n",
      "sys\t0m0.197s\n",
      "All tasks completed!\n"
     ]
    }
   ],
   "source": [
    "!./train_test_name.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b45fb58-9f9c-4c85-bf13-990ac3764df6",
   "metadata": {},
   "source": [
    "## GPU Usage Information\n",
    "\n",
    "လက်ရှိ ရေးထားတဲ့ Laphet LM Toolkit က Pytorch library ကို သုံးထားပါတယ်။ Neural network ကို အခြေခံတဲ့ language modeling လုပ်တာမို့လို့ GPU ပေါ်မှာ run မှ မြန်ပါလိမ့်မယ်။ တကယ်လို့ GPU မရှိရင် ဒါမှမဟုတ် GPU က စက်မှာရှိနေပေမဲ့ setup လုပ်ထားတဲ့ Python environment က အကြောင်းတခုခုကြောင့် GPU ကို ခေါ်မသုံးနိုင်ရင်တော့ CPU ပေါ်မှာပဲ Laphet က run ပေးသွားပါလိမ့်မယ်။  \n",
    "\n",
    "အထက်က Shell script ကို run နေစဉ်မှာ GPU usage ကို တချက်ကြည့်ကြည့်တော့ အောက်ပါအတိုင်းပါ။ "
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf2817ff-2653-4fcd-b2d1-bacfb4ea62c1",
   "metadata": {},
   "source": [
    "(base) ye@lst-hpc3090:~$ nvidia-smi\n",
    "Mon Jan 27 02:21:31 2025\n",
    "+---------------------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
    "|-----------------------------------------+----------------------+----------------------+\n",
    "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                                         |                      |               MIG M. |\n",
    "|=========================================+======================+======================|\n",
    "|   0  NVIDIA GeForce RTX 3090 Ti     Off | 00000000:01:00.0 Off |                  Off |\n",
    "| 32%   44C    P8              24W / 480W |    471MiB / 24564MiB |      0%      Default |\n",
    "|                                         |                      |                  N/A |\n",
    "+-----------------------------------------+----------------------+----------------------+\n",
    "\n",
    "+---------------------------------------------------------------------------------------+\n",
    "| Processes:                                                                            |\n",
    "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
    "|        ID   ID                                                             Usage      |\n",
    "|=======================================================================================|\n",
    "|    0   N/A  N/A     32486      G   /usr/lib/xorg/Xorg                          157MiB |\n",
    "|    0   N/A  N/A     32759      G   /usr/bin/gnome-shell                         72MiB |\n",
    "|    0   N/A  N/A     33671      G   ...56,262144 --variations-seed-version       37MiB |\n",
    "|    0   N/A  N/A     34918      G   ...irefox/5647/usr/lib/firefox/firefox      163MiB |\n",
    "|    0   N/A  N/A     36812      G   /usr/bin/gnome-control-center                20MiB |\n",
    "+---------------------------------------------------------------------------------------+\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b919e3d2-2bd2-4ca1-83f3-5787faa41c40",
   "metadata": {},
   "source": [
    "## FYI\n",
    "\n",
    "ဒီ notebook ကို အစကနေ အဆုံးထိ သေချာဖတ်လာတယ် ဆိုရင်တော့ NLP, AI အနည်းဆုံးတော့ မြန်မာစာကို သုံးပြီး language model ဆောက်တာနဲ့ ပတ်သက်ပြီး စိတ်ဝင်စားတယ်လို့ ယူဆပါတယ်။ \n",
    "\n",
    "တခု သိစေချင်တာက Laphet LM Toolkit က NLP/AI fundamental education အတွက် ရည်ရွယ်ပြီး တပတ်လောက်နဲ့ အကြမ်းပြီးအောင် ရေးထားတာမို့လို့ production အတွက် မသုံးစေချင်ပါဘူး။ Language modeling နဲ့ ပတ်သက်ပြီး ပထမဆုံး လေ့လာတဲ့သူတွေအတွက် လွယ်ကူအောင် တတ်နိုင်သမျှ ရှင်းရှင်းလေးရေးထားတာမို့ပါ။ အဲဒါတောင်မှ တကယ်တမ်း ရေးထားတဲ့ Laphet LM code အကုန် နဲ့ background theory ကို ထဲထဲဝင်ဝင် နားလည်ဖို့ ဆိုရင် ကျောင်းသားပေါ်မူတည်ပြီး သုံးလ၊ လေးလ ကြာသွားနိုင်ပါတယ်။ အနည်းဆုံးတော့ မြန်မာကျောင်းသားတွေအတွက်က မြန်မာနာမည်တွေကို သုံးပြီးတော့ မော်ဒယ်ဆောက်ပြ၊ စာကြောင်း အသစ်တွေကို generate လုပ်ပြ၊ testing/evaluation လုပ်ပြထားတာမို့လို့ ဒီ example notebook ကို အခြေခံပြီး NLP/AI သုတေသန အတွက် အရေးကြီးတဲ့ language modeling ဆိုတာကို နည်းနည်းပါးပါး တီးမိခေါက်မိရှိသွားရင်ပဲ ဝမ်းသာပါတယ်လို့။  \n",
    "\n",
    "ရဲကျော်သူ  \n",
    "LU Lab., Myanmar  \n",
    "27 Jan 2025  \n",
    "Email: ykt.nlp.ai@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1c9f08-0200-4c1b-88d1-d68065695b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
