{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f0e9fb3-5cb3-4769-8214-8bb74126d94a",
   "metadata": {},
   "source": [
    "# Laphet (Version 0.7) with Myanmar Names Dataset\n",
    "## Training with fasttext_no_freeze    \n",
    "\n",
    "Shell script နဲ့ပဲ MLP, Bi-LSTM, Transformer, BERT, GPT အခြေခံတဲ့ language modelအကုန်ဆောက်ပြီး၊ name generation, testing အဆင့်ဆင့် လုပ်သွားပါမယ်။   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1982968b-4ddf-4d5e-9703-c12aa09c774e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ye/exp/name-lm/lib\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3546849c-7dbd-4fe3-950c-677006cf1c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "# Updated for Laphet LM Toolkit Version 0.7\n",
      "# Last updated: 27 Jan 2025\n",
      "\n",
      "# Create the output and log directories if they don't exist\n",
      "# _\n",
      "mkdir -p model/name/\n",
      "mkdir -p output/name/\n",
      "mkdir -p log/name/\n",
      "\n",
      "# Function to train, generate text, and test a language model\n",
      "task() {\n",
      "  local model_type=$1\n",
      "  local model_file=\"./model/name/${model_type}.nofz.model\"\n",
      "  local output_file=\"./output/name/${model_type}_nofz_gen_texts.txt\"\n",
      "  local log_file=\"./log/name/${model_type}.nofz.log\"\n",
      "  local train_data=\"./data/myRoman/train_name.txt\"\n",
      "  local dev_data=\"./data/myRoman/dev_name.txt\"\n",
      "  local test_data=\"./data/myRoman/test_name.txt\"\n",
      "  local start_name=\"./data/myRoman/start_names.txt\"\n",
      "\n",
      "  {\n",
      "    echo \"Training ${model_type^} language model:\";\n",
      "    time python -u laphet.py --model_type $model_type --train --data $train_data \\\n",
      "      --dev_file $dev_data --model $model_file --seq_len 50 --epochs 10 --batch_size 32 \\\n",
      "      --lr 0.0001 --embedding_method fasttext_no_freeze \\\n",
      "      --fasttext_model ./fasttext-model/myfasttext_v1.bin --embed_dim 100;\n",
      "\n",
      "    echo \"Text generation:\";\n",
      "    time python -u laphet.py --model_type $model_type --generate --model $model_file \\\n",
      "      --seq_len 50 --prompt \"ရဲ\" --no_of_generation 10 \\\n",
      "      --embedding_method fasttext_no_freeze\n",
      "\n",
      "    echo \"Batch text generation from file:\";\n",
      "    time python -u laphet.py --model_type $model_type --generate --model $model_file \\\n",
      "      --seq_len 2 --input $start_name --no_of_generation 5 --output $output_file \\\n",
      "      --embedding_method fasttext_no_freeze;\n",
      "\n",
      "    echo \"Testing:\";\n",
      "    time python -u laphet.py --model_type $model_type --test --model $model_file \\\n",
      "      --test_file $test_data --seq_len 50 --batch_size 64 \\\n",
      "      --embedding_method fasttext_no_freeze 2>&1;\n",
      "  } | tee \"$log_file\"\n",
      "}\n",
      "\n",
      "# Run tasks for each model type in the specified order\n",
      "task mlp\n",
      "task bilstm\n",
      "task transformer\n",
      "task bert\n",
      "task gpt\n",
      "\n",
      "echo \"All tasks completed!\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat ./train_test_name_nofz.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58075a28-7a75-4a59-897b-9d7802293cfa",
   "metadata": {},
   "source": [
    "bash shell script ကို လေ့လာကြည့်ရင် မြင်ပါလိမ့်မယ်။  \n",
    "Laphet (version 0.6) ကို run တုန်းကနဲ့ မတူတာက အောက်ပါ command line argument သုံးခုပါ။  \n",
    "\n",
    "1. --embedding_method fasttext_no_freeze \n",
    "2. --fasttext_model ./fasttext-model/myfasttext_v1.bin   \n",
    "3. --embed_dim 100  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16472c2d-9e6f-4795-b2ee-3ad324a523d3",
   "metadata": {},
   "source": [
    "## Fasttext Model\n",
    "\n",
    "ဒီ test run မှာ သုံးမယ့် fasttext embedding model က [Ngapi](https://github.com/ye-kyaw-thu/NgaPi) code တုန်းက သုံးခဲ့တဲ့ မော်ဒယ်နဲ့ အတူတူပါပဲ။ စုစုပေါင်း စာကြောင်းရေ 358,047 (သုံးသိန်း ငါးသောင်းကျော်), ဝဏ္ဏ အရေအတွက် 9,723,255 (ကိုးသိန်းခုနှစ်ထောင်ကျော်) နဲ့ ဆောက်ခဲ့ပါတယ်။ စာကြောင်းတွေကို syllable unit ဖြတ်ထားပြီး 100 dimension နဲ့ ဆောက်ထားတဲ့ မော်ဒယ်ပါ။  \n",
    "\n",
    "Model download link:\n",
    "[https://huggingface.co/ye-nlp/mySyllableFastText-Version1](https://huggingface.co/ye-nlp/mySyllableFastText-Version1)\n",
    "\n",
    "myfasttext_v1.bin ဖိုင်ဆိုက်က ကြီးလို့ HuggingFace ရဲ့ personal account မှာပဲတင်ပေးထားလိုက်တယ်။\n",
    "\n",
    "**embedding model က word နဲ့ ဖြတ်ထားရင် training, dev, test ဒေတာတွေကိုလည်း word unit နဲ့ ဖြတ်ပေးထားရပါမယ်။ fasttext embedding model ကို syllable unit နဲ့ ဖြတ်ဆောက်ထားရင် training, dev, test ဒေတာတွေကလည်း syllable ဖြတ်ထားမှ embedding မော်ဒယ်ကို apply လုပ်သွားမှာပါ။ ထိုနည်းလည်းကောင်း dimension command line argument ကိုလည်း ဆောက်ခဲ့တဲ့ မော်ဒယ်နဲ့ ညှိပေးထားရပါလိမ့်မယ်။   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22f149ef-6af9-484a-93ca-9701c46dc823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ye ye 766M Jan 27 16:37 ./fasttext-model/myfasttext_v1.bin\n",
      "-rw-rw-r-- 1 ye ye 3.9M Jan 27 16:37 ./fasttext-model/myfasttext_v1.vec\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ./fasttext-model/myfasttext*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e2ca0c-111d-428f-a81e-5b5ddd73b60e",
   "metadata": {},
   "source": [
    "training လုပ်တဲ့အခါမှာ .bin ဖိုင်ကို သုံးပါမယ်။  \n",
    ".vec ဖိုင်ကတော့ text ဖိုင်မို့လို့ syllable တစ်လုံးချင်းစီရဲ့ vector information ကို ဖတ်လို့ရပါတယ်။  \n",
    "အရင်ဆုံး ဖိုင်ရဲ့ ထိပ်ဆုံး စာကြောင်း ၁၀ကြောင်းကို လေ့လာကြည့်ရအောင်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "739d2cf3-3903-423c-a659-f60376a5d23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3462 100\n",
      "အ -0.020812677 0.014222041 0.14707279 -0.1842381 -0.061052196 -0.057658885 -0.03292892 0.04936385 -0.025804132 0.0734657 -0.1159874 0.016686555 0.35442472 -0.14443621 0.05544194 0.12364729 -0.023075808 0.09519182 -0.045482293 0.029036311 -0.2193143 0.18958911 0.18115446 0.2333122 0.1195823 -0.008966078 0.411379 -0.08511002 0.047515854 -0.09509543 0.08582706 0.03881732 -0.055743393 0.03412059 -0.16639902 -0.28278458 -0.032576233 0.10848193 -0.020877324 -0.0009929277 -0.06336136 -0.14327583 -0.031124137 -0.08016338 -0.024092454 0.07601534 0.065982565 0.17565352 -0.10458869 0.18354851 0.1652404 0.09512043 -0.083493486 0.24238697 -0.17059515 0.010160673 -0.09070958 0.1116292 -0.037382837 0.2967968 -0.14358653 0.04922141 -0.22735184 0.01362576 -0.07403269 0.07475961 -0.19550946 -0.08912936 0.06503683 -0.14732634 -0.042020865 0.16236758 0.0344707 0.110176384 -0.04351531 0.02504056 -0.017584132 -0.019345423 0.14525683 0.018760469 -0.11468452 -0.16687019 0.12602636 -0.11606391 -0.05526773 0.0042534173 0.12149795 -0.09459259 -0.10891135 -0.2414366 0.073258676 -0.0504788 0.15406191 -0.024610322 0.015399458 -0.1084087 0.104009554 -0.05159897 -0.21134643 -0.029999733\n",
      "</s> 0.12382664 -0.012683906 0.041837506 -0.06987271 0.06381257 0.06208927 -0.23126368 0.048813067 0.08809406 0.039452787 -0.22591248 0.10878711 0.24657933 -0.09025508 -0.20819944 0.11296403 -0.0023698541 0.13694344 0.046330955 -0.06459741 -0.011776806 0.0020629307 0.008789067 0.26550153 -0.022911312 -0.04013552 0.0279873 0.017961724 -0.0054563517 -0.026302485 0.08658377 -0.102739446 -0.0013639664 0.20668857 0.004934055 -0.34088972 0.2774442 0.08034218 0.16066907 -0.21243756 0.0037596314 0.058731575 -0.049128115 -0.0017906616 0.094759576 0.062752426 -0.058349565 0.05442252 0.02527177 0.28109205 -0.17506446 -0.24817337 -0.2785353 0.036080763 -0.07960388 -0.19838692 -0.09586938 0.032010466 -0.12380073 0.13872214 -0.096330285 0.08983679 0.10626658 0.06370716 0.091440745 -0.0612045 0.0082077 0.0670313 -0.017856117 -0.21964775 0.05315741 0.0147147095 -0.1176217 0.06689351 0.045692213 -0.027084365 -0.12495102 -0.038943823 0.19913141 0.10390068 0.11612357 0.051901486 0.17593633 0.18200813 -0.24298528 0.14925897 0.012650026 0.18348004 0.019809598 -0.4322835 -0.13959268 -0.20270965 0.15223348 -0.13839447 0.2104736 -0.09130107 -0.1292427 0.19842337 -0.32999054 -0.07565341\n",
      "မ -0.037138704 -0.13569695 0.05291237 -0.23952962 0.054309398 0.08480413 -0.12574023 -0.10288342 0.26802805 -0.023060258 -0.19200593 0.048837014 0.13388237 -0.10156472 -0.27330744 0.06254955 -0.018021502 0.10738753 -0.08699856 -0.11971502 -0.02427984 0.00821751 0.011763198 0.22179054 0.0405163 -0.064645365 0.21057953 -0.20626605 0.052216925 0.06893001 -0.083571464 0.062132645 -0.03155385 0.1259717 -0.14362349 -0.29381698 -0.024351114 0.09014881 -0.02725529 -0.084978566 -0.034774803 -0.046036735 -0.14072639 0.124127895 -0.096729 0.16550906 0.078789495 0.18324527 0.059834424 0.07983999 -0.22204566 -0.0071226573 -0.22143735 0.14136066 -0.18776268 0.111439355 -0.034212455 0.29030272 0.062479146 0.13921164 -0.011364475 0.16420348 -0.18552603 0.2543297 -0.0671265 -0.1643539 -0.1521545 0.011511192 -0.14606753 -0.18639424 -0.091895506 -0.038037926 -0.013226733 -0.020700991 -0.1304299 -0.10411659 -0.123490945 -0.121870376 0.025200529 -0.0728125 0.02042448 0.0319191 0.16621827 -0.0046351263 -0.07936244 -0.02828452 -0.07946257 -0.013573024 0.0023430604 -0.2846415 0.004855334 -0.1849191 0.26290923 0.06771301 0.33243358 -0.018295549 0.14210498 0.07429257 -0.16856532 -0.097810596\n",
      "ပါ -0.087525435 -0.005859427 0.27533922 -0.02983224 -0.039899968 0.049487114 -0.28226385 0.17397852 0.23602515 0.00026850402 -0.25732568 -0.12463488 0.08218895 -0.03002106 -0.11644097 0.11331933 0.16041115 0.2823048 0.0058015343 -0.008242266 -0.11977239 -0.16394351 -0.11037723 0.23661324 -0.08783595 0.09576425 0.299117 0.003330242 0.076135896 -0.13499334 -0.089114785 0.10768247 -0.102942936 0.3175604 -0.06907454 -0.26737332 0.19487469 0.027710423 0.1234796 -0.27797264 -0.036803883 0.07294426 -0.19873166 -0.06823772 -0.111085676 0.123619474 0.28799415 0.13046129 -0.09571865 0.33422554 -0.04376065 -0.2152585 -0.35091978 0.013717361 -0.1434667 -0.2915153 -0.10823727 0.048322715 -0.12467216 0.2949836 -0.18683922 0.20867643 -0.096441984 0.16219223 0.038168233 -0.20211723 -0.061449233 0.10116825 -0.10512587 -0.18431446 -0.0693818 0.022668384 -0.018073462 0.12479973 -0.0061559975 -0.021700172 -0.057297543 -0.051328972 0.18727888 0.15065491 0.001404902 -0.0042740926 0.17474222 -0.043993764 -0.036044426 -0.06262929 -0.017722342 -0.1013968 0.16547391 -0.31008813 -0.01926384 0.019985143 -0.077733725 -0.16357918 0.00094194524 0.031407647 0.01720908 0.1017039 -0.21075726 0.054990195\n",
      "က 0.005586397 0.0035553724 0.043903466 -0.025929756 0.06820154 -0.083473936 0.17526793 0.025444353 -0.010341607 0.012500547 -0.06879764 -0.022912554 0.19046825 -0.09192437 -0.065295674 -0.0124853905 -0.05358848 0.14326698 -0.021700917 -0.008445582 -0.054013252 0.019059066 0.09665468 0.22297117 -0.042007785 0.0563076 0.42052028 -0.13233158 0.22632253 -0.013369214 0.006161142 -0.07444376 -0.22130388 -0.016274836 -0.11054453 -0.21350713 -0.012493099 0.1371899 0.043665145 -0.021117441 -0.068028174 -0.04764892 0.010197798 0.035215147 -0.040331736 0.10699217 0.20265245 0.24131921 0.09565459 0.1330294 0.012323478 0.13944894 -0.04777919 0.14558257 -0.009986118 -0.11140704 0.076862484 0.059137706 -0.15367246 0.1172542 -0.039038908 0.0800514 -0.16803804 0.18416142 -0.046993427 -0.09745307 -0.039417863 -0.049574837 -0.055808738 -0.009096504 -0.020848284 0.19776654 0.15017495 -0.013011406 -0.09384664 0.021649998 -0.13679193 -0.13376203 -0.022702852 0.07466504 -0.111704424 -0.077716 -0.06293553 0.14709842 -0.0823473 0.17380673 -0.022408854 0.00034506433 -0.19590604 -0.08407478 0.14193982 0.0018730997 0.27397293 -0.07504713 0.024243716 0.19164222 0.12516136 -0.0275762 -0.31775403 -0.32855007\n",
      "ကို -0.14035897 -0.20247672 0.1522462 -0.1592438 -0.04335637 -0.10129674 0.0289356 0.05071132 0.0889965 -0.00135214 -0.16407943 0.04276938 0.216871 -0.16061687 -0.07371625 0.13684046 -0.16825767 0.09134262 0.024781587 0.13245153 -0.24981527 0.023143714 0.1167979 0.15466931 -0.071643785 0.089075245 0.37485343 -0.09469601 0.120481886 -0.23762815 -0.004829833 -0.10042644 -0.09305838 0.12268869 -0.18135175 -0.22339243 0.070216134 0.10949483 0.11248172 -0.13408911 -0.03096802 0.03587532 -0.0010756084 0.025387011 -0.22672552 0.036987174 0.045254923 0.15705995 0.03835295 0.21106799 0.07006357 0.024549434 -0.116572715 0.2365292 -0.0064354967 -0.27123913 -0.04282965 0.046844672 -0.0775909 0.32956553 0.039943602 0.05636056 -0.24621639 0.23866582 -0.16478834 0.10037286 -0.03135763 -0.06522189 0.047627356 0.06016024 -0.03588742 -0.00063734397 0.04921951 0.08579688 -0.05137061 -0.06604894 -0.1606001 0.05543119 0.1622271 0.055894613 0.009143041 0.10874284 0.15345165 0.11906961 -0.041506276 0.01619666 -0.22009136 -0.007732209 -0.019190013 -0.3299635 0.00041829105 -0.07723701 0.16245684 0.03912612 0.11016564 -0.008738305 0.16529053 0.059800748 -0.14611718 -0.098225154\n",
      "တယ် -0.120471336 -0.018285215 0.4533828 0.056147113 -0.063245565 0.053406563 -0.4467594 0.0973573 0.015560304 -0.0075013405 -0.25234514 -0.058425974 0.17098938 -0.23994355 -0.1640212 0.27626455 0.07986635 -0.119295485 -0.0050384915 -0.11835963 -0.0015431303 -0.12790558 0.018034093 0.47423318 0.09921052 0.04763681 0.30432615 -0.08247365 0.12788221 -0.12415005 0.10119429 0.11169708 -0.0354309 0.25630134 -0.13584085 -0.4440856 0.24584708 0.11716656 0.13736127 -0.12940744 -0.011258109 0.0792069 -0.16058801 -0.044098046 -0.290039 0.12187289 0.26664132 0.25621757 -0.043904074 0.501729 -0.024915602 -0.21647009 -0.10493446 -0.030752532 0.065629736 -0.4260809 -0.06419717 0.009782156 0.07937679 0.16467118 -0.15726167 0.038465332 -0.15767308 -0.021764314 0.04305435 -0.18023114 -0.24379285 -0.1954492 -0.09574732 -0.059373423 0.23023994 0.10441988 0.109726496 0.06956385 -0.012988484 0.14208709 -0.11922363 -0.18472713 0.1308994 0.26774776 -0.12838815 0.18306153 0.12675257 0.09087505 0.008301395 0.0007042864 -0.24252665 -0.2013461 0.06217788 -0.20095687 -0.09003493 -0.11727926 0.017054338 -0.09944423 -0.103094645 0.14915675 0.09124262 0.13907568 -0.37772167 -0.110662974\n",
      "နေ 0.048886072 -0.011819106 0.2975276 -0.0012909761 0.1251401 -0.028090375 -0.095248684 -0.0032416787 0.12339536 -0.0053562075 -0.22194068 -0.12946838 0.25370762 -0.21229751 -0.05537299 0.037339985 -0.041386064 0.06714039 -0.18557784 0.083090864 -0.09687073 0.023984643 0.075407386 0.22928321 0.024193095 -0.09934579 0.28638634 0.09949465 -0.01919273 -0.13266549 -0.09923762 0.074267074 -0.08712657 0.13067636 -0.20511693 -0.36451292 0.28716242 -0.19483468 0.009250808 0.013777632 -0.11485828 -0.007749319 -0.025535172 0.030564219 -0.17353758 0.11538676 0.13587792 0.2224195 -0.04777381 0.2729874 0.01848652 -0.095303684 -0.22759122 0.24076937 -0.05552526 -0.16929159 0.032177873 0.05935123 0.053086184 0.20018654 0.040758073 -0.0027874839 -0.0646288 0.21544237 -0.046396684 0.15841709 -0.116035566 -0.075150385 0.094882146 -0.06554534 -0.030115541 -0.034544855 -0.051330484 0.057215557 0.033348918 0.17677371 -0.24633877 -0.06970134 0.18098429 0.05667135 0.001614477 -0.0012523048 -0.04237651 -0.04455544 -0.09252065 0.19407815 -0.022971122 0.04657116 0.07657422 -0.11040982 -0.1414829 0.01112334 0.3202184 -0.0647468 0.033276737 -0.07872544 0.1207119 -0.05889726 -0.2059288 -0.13019425\n",
      "ရ 0.07895931 0.021591492 -0.00974522 -0.1954571 0.03715715 0.19192086 -0.16420113 -0.048558295 0.180944 -0.039754268 -0.21430117 0.015529577 0.24136762 0.01799596 -0.04952926 0.083865896 -0.07847873 0.113229685 -0.1036828 0.14505091 -0.15163416 0.13571873 -0.036331203 0.26130563 0.022977222 -0.017934687 0.14438695 -0.15869294 0.16259226 0.10760036 -0.057033528 0.04902984 -0.16630113 0.04820086 -0.03314672 -0.096001126 0.065662146 0.01041087 0.072664514 -0.03414534 -0.0017841728 0.02442407 -0.1967488 -0.10730509 -0.04234231 -0.048308313 0.08167268 0.14075202 -0.04791197 0.095709346 -0.00039508834 -0.028387519 -0.12931135 0.07175967 -0.2577539 -0.09668729 0.019835126 0.08390751 -0.14297912 0.3197953 -0.3027686 0.2652532 -0.10551424 0.14783493 0.03529992 0.04610823 -0.0746163 0.032330126 0.015001297 -0.23282209 -0.10659642 0.09913879 -0.058567397 0.107539795 0.16343871 0.045880172 -0.36562073 -0.1150111 0.079135254 -0.081988245 -0.14062381 0.21396255 0.0070283376 0.09891861 -0.15961233 -0.014829058 -0.040204123 -0.041554965 0.064516455 -0.17597377 -0.17241801 -0.27929875 0.18177998 -0.17023832 0.058134444 0.050726775 0.02103829 0.16006836 0.0056325197 -0.13922656\n"
     ]
    }
   ],
   "source": [
    "!head ./fasttext-model/myfasttext_v1.vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff5f83a-9efa-45dd-89c2-d83f580aabd0",
   "metadata": {},
   "source": [
    "Vector ဖိုင်ရဲ့ နောက်ဆုံးပိုင်းကိုလည်း တချက် ကြည့်ကြည့်ရအောင်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "758ed2af-ea04-4fa3-944f-0146247a6f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "လဗ္ဘေ 0.1830714 0.22337396 -0.21023625 -0.045918267 0.26395327 0.015270137 -0.27974412 -0.0021621864 0.36375126 0.25287792 -0.3485732 0.31900573 0.76218 -0.584555 0.2602841 0.2150892 0.015093825 0.40335682 -0.0021270078 -0.0102439625 -0.27154714 -0.24530803 -0.30234715 0.8159268 -0.33370203 0.16331537 -0.08953913 -0.15671305 0.073804915 0.21522263 0.37621176 -0.4310723 -0.07006551 0.19596152 0.26038486 -0.34378362 -0.29537085 0.2091432 0.28675535 0.13887826 0.22702347 -0.4010916 0.23250727 -0.37237856 0.3132686 -0.61562485 -0.258343 0.14362666 -0.036417037 -0.5316609 0.029325252 0.17908096 -0.42861366 0.21407056 -0.19330813 0.17727767 0.2880356 -0.028847774 -0.08432743 0.3579867 0.035279304 0.4984944 0.051906973 0.46864054 -0.03723403 -0.00057201437 0.34042454 0.23796026 -0.16938731 -0.42765442 0.023206659 0.11070449 0.43708295 -0.18668526 -0.28554085 0.1419076 -0.3099975 -0.31298527 -0.082222976 -0.35318598 0.26455504 -0.077361144 0.28766176 -0.2408238 -0.009982903 0.060138658 0.02775521 0.0734009 -0.24349132 0.13439271 0.35626617 -0.41808903 -0.067227684 0.034056876 -0.21464583 0.2795677 -0.1496724 -0.001305461 0.24437293 -0.02882282\n",
      "တဗ္ဗံ 0.104341894 0.19125508 0.13042389 0.05782834 0.14539906 0.05196335 -0.4010302 -0.0027961615 0.20104143 0.5516942 -0.377521 0.13971536 0.6555644 -0.5689611 0.039594356 0.24281874 -0.0017498931 0.59031504 -0.51997936 0.09937805 -0.20728718 -0.08825751 -0.09554912 0.90628475 -0.4524254 -0.0925517 -0.17027739 -0.41588265 -0.07899862 0.3201917 0.085372254 -0.10582247 -0.058678895 0.4305951 0.26684707 -0.3368737 -0.18324028 0.27057683 0.07485149 0.30443588 -0.12275765 -0.46582893 0.0936307 -0.16258475 0.23796187 -0.6366647 -0.23609927 0.056917246 -0.071175635 -0.35178915 0.1887115 0.17389835 -0.45525342 0.13894099 -0.34651613 0.1562809 0.23965026 -0.10183493 -0.18022542 0.25411746 0.041324563 0.6663802 -0.020847818 0.47111678 0.003833798 0.1815742 0.6562791 0.40081605 -0.24699491 -0.18109284 0.13477024 0.06575044 0.21532612 -0.16761641 -0.6348698 0.16235743 -0.33110952 -0.4635248 -0.30593476 -0.2975592 -0.04197147 0.077429645 0.24227196 -0.069967195 -0.11728464 -0.15494616 -0.1308245 0.09756822 -0.44089395 0.26098505 0.26574934 -0.27187836 0.15250646 0.23580317 -0.2323804 0.25942865 -0.3661681 -0.0639105 0.6016198 -0.1822776\n",
      "စုက္က 0.20521365 0.09438536 -0.0264808 0.13624255 0.14474016 -0.03511443 0.053657748 -0.39148733 0.17815137 0.15941456 -0.31022483 0.15797757 0.30702072 0.021061974 -0.079983346 -0.08149047 0.10008772 0.2109896 -0.017679496 -0.067980796 -0.21406952 -0.043480843 0.13753532 0.5135827 -0.32427675 0.22002983 0.25263333 -0.27144453 0.50699496 -0.078765735 -0.14859308 0.015984282 -0.27738523 0.23826288 0.07659247 -0.4837527 -0.11766404 0.09542528 -0.104246795 -0.23281375 -0.24899693 -0.17460649 0.22916813 -0.17444521 -0.016369514 -0.16771527 -0.12921186 0.111947216 -0.20651351 0.016459227 -0.02513503 -0.16615811 -0.34267616 0.36001614 -0.38686684 -0.12285696 -0.09103212 -0.21198098 0.20011766 0.16460988 -0.08295597 -0.038331605 -0.35282165 -0.10300383 0.2651734 -0.09020426 -0.0653542 -0.077462964 -0.0649436 0.10342922 0.06834048 -0.21099071 0.0051885867 -0.07131982 0.03668426 0.002504321 -0.41786012 -0.019796338 -0.2614099 -0.63675374 -0.075255126 -0.09076484 -0.29956767 0.049946487 -0.09959397 -0.054288324 0.17055716 0.05418735 -0.11283664 0.15269355 0.3066885 -0.12543567 0.017158978 -0.279656 0.15705477 0.007428575 0.10790944 0.076289125 0.20892316 0.012310111\n",
      "လိုတ် -0.08159438 -0.20415902 0.08390559 -0.23229901 0.17286961 -0.046563964 -0.07453947 -0.07180177 0.21920165 -0.07911644 -0.27955252 -0.11124981 0.31730735 -0.06747491 -0.25757474 0.08881594 0.02707368 -0.023569206 0.12820752 0.0693024 -0.105688356 0.0827992 0.004581297 0.27952996 0.06366298 0.03809198 0.23756494 -0.16370168 0.014405136 0.101150535 -0.052265797 -0.0024518033 -0.16780704 0.0840801 -0.1519936 -0.22041984 0.042650286 0.16544747 0.062777676 0.060937647 -0.0190463 0.05588926 -0.19766779 0.082015045 0.090781614 -0.036571644 0.079534404 0.0291194 -0.015827712 0.03523335 -0.057715848 -0.08483462 -0.17581896 -0.01810925 0.006911449 -0.17935926 0.037554838 -0.03391355 0.18425168 0.14735813 -0.008329449 0.25559965 -0.028825384 0.3703595 0.11743349 -0.20505811 0.052377116 0.019328142 -0.05090016 0.08268529 0.09549898 -0.014900943 -0.011471555 0.03565844 0.06655583 -0.089241095 -0.15974851 -0.11255197 -0.005470011 0.12715787 -0.075542584 0.009496979 0.07481394 0.19817366 -0.1335583 0.13124664 -0.027208515 0.005170904 0.18741743 -0.24395773 0.04886307 0.0015358826 0.1001949 -0.13496271 0.13095634 -0.12854894 -0.005651166 0.08019046 -0.15187743 -0.19446106\n",
      "ဏုပ္ပတ္တိ 0.3501218 0.089501746 0.047717825 0.056334473 -0.28651705 -0.07172957 -0.53005856 0.19796218 0.27060035 -0.27476907 0.06414387 0.13052648 0.18087743 0.3805313 0.14581233 0.36809355 -0.13729829 0.2917144 -0.22279517 -0.23711899 -0.24374458 0.026259076 0.0121544 0.039941616 -0.25216064 0.26695874 -0.011435159 -0.22070435 0.267071 -0.09881403 0.13359104 0.07627199 -0.11827025 -0.12857144 -0.10465869 -0.44881585 -0.34499747 0.099971846 0.14436224 -0.073556855 -0.1781766 -0.44428462 0.205006 -0.22097915 -0.066753335 -0.49147233 -0.17217974 0.22944547 -0.023725104 -0.3640966 0.03791675 -0.3185305 -0.07893197 -0.18784721 0.08002684 0.5451927 0.6577787 0.06713744 -0.61491555 0.3444274 -0.056561 0.40221798 -0.0077686673 0.33652842 -0.09437028 0.1907099 0.025995536 0.082187556 -0.4249811 -0.11514057 0.07528894 0.32158607 0.04553038 -0.46819073 -0.25386876 0.07705777 0.3082277 -0.060321737 -0.07269798 -0.41349214 0.04830942 -0.27053112 0.36000076 0.026555449 -0.1886671 0.18298982 -0.19947037 -0.14815599 -0.24087936 -0.3910367 0.3775682 -0.12904929 -0.12892447 -0.30745527 -0.45360485 -0.402538 -0.29686493 0.08447591 0.09767929 -0.5436254\n",
      "ဝှတ် 0.02758753 -0.15060519 0.14588787 -0.043258354 0.3405714 -0.01742934 -0.18019146 -0.020686675 0.21251664 0.09934935 -0.27755767 0.060743447 0.30125418 -0.23129933 -0.15978675 0.14479063 -0.0034814496 0.025731066 0.08803448 0.31623507 -0.1399345 0.19704355 -0.03097078 0.41997027 -0.15364106 0.1153584 0.21238808 -0.23511061 0.14599136 -0.025738763 0.18608963 0.014891977 -0.24958628 0.26489416 -0.12570451 -0.3569646 -0.0069069266 0.06377732 0.20491958 -0.19011545 0.011684109 -0.040676728 -0.22436604 0.16927488 -0.064592525 0.036799617 0.011346676 0.22024024 0.10157181 -0.023126602 -0.20438683 0.12155544 -0.18126822 0.18481195 0.14200135 -0.024017464 0.05219787 -0.25642163 0.15153566 0.0012593378 0.14028844 -0.12778367 -0.09779356 0.13523449 0.20480473 0.048122864 0.23353304 0.0712795 0.02926962 0.3613201 0.008634497 0.032550633 -0.14960386 -0.077190764 -0.31261346 -0.10371513 -0.17810982 -0.25970915 0.036655236 -0.0017336983 -0.1416196 -0.16660058 -0.019589085 0.22240618 0.072392516 0.10111122 -0.15118693 -0.06683828 -0.10874457 0.054666154 0.07962736 0.1843549 0.06512564 -0.1267258 -0.00013410368 -0.057222627 -0.2669123 -0.23537938 -0.077235736 -0.24162766\n",
      "ပဏ္ဍိတ် 0.0025043502 -0.060064316 -0.06813489 0.30839548 0.06430216 -0.113338314 -0.06638431 0.06941075 0.09951032 0.17169707 -0.2391629 0.15856552 0.11117749 -0.09454439 0.03018526 0.011150449 -0.048310757 0.36279157 -0.12869504 -0.049381465 -0.17166963 -0.31276476 0.23749802 0.22095466 -0.25056428 0.33512762 0.22583468 -0.1278927 0.3693094 0.15029365 0.09613863 0.07775229 0.15843852 0.15890059 -0.063755915 -0.18066671 -0.1275286 0.124549404 -0.1329327 -0.38371295 0.030525394 -0.28563446 -0.10947442 -0.2360589 -0.026754754 -0.18372989 -0.3147558 0.075161144 0.12536447 -0.14165257 0.27402952 0.13388348 -0.2879775 -0.15354446 -0.06693468 0.2623265 0.44279662 -0.09946116 -0.27976093 0.152054 -0.25790054 0.17472774 -0.084198155 0.43096784 -0.042418867 -0.08193529 0.267759 0.1602906 -0.44913876 -0.037324484 0.030120147 -0.16256492 -0.06934526 -0.26430917 -0.35658216 0.17871025 -0.15837069 -0.28825358 -0.13675393 -0.32872695 0.23964392 -0.100895405 0.08881996 -0.18317753 -0.29040632 -0.020396985 -0.009924469 0.1313332 -0.006028076 0.01859618 0.39343694 0.050504122 0.39792293 -0.25913554 0.048784677 -0.051296525 0.028461726 0.03865738 -0.124041386 -0.2742954\n",
      "ဝေ့စ် 0.23391351 0.12337126 0.2734134 -0.28896248 -0.41600576 0.121599086 -0.076327786 -0.39324117 0.55085456 -0.086254425 -0.61185914 0.061210483 0.7160943 -0.22875571 -0.23023061 -0.14831327 -0.18326917 -0.38169178 0.42031354 0.23869596 -0.01710078 0.46364063 0.08974114 0.46426997 0.021778928 0.12262411 0.2903504 -0.29043195 0.42067945 -0.27386087 0.16680756 -0.39108822 -0.07689704 0.23875578 0.41634604 -0.55327183 0.4108625 -0.11565947 0.3319508 0.0039666733 0.3152592 0.066436574 -0.4386897 0.18710916 0.0033058706 0.077781886 0.085583195 0.036545344 0.06687406 0.27792835 -0.054621954 0.37697712 -0.014155657 -0.4846648 0.69187677 0.061245915 0.34485063 0.026134381 0.23928532 0.19078575 -0.24015456 -0.13988778 0.40994498 0.23778518 0.041180104 -0.064155795 0.08515805 0.20663483 0.31581345 0.47018296 0.7155985 -0.07775527 -0.32899857 0.30599692 0.08820922 0.13410524 -0.3475354 -0.078497835 0.093686916 -0.07813864 -0.37873736 -0.105501965 -0.08444989 -0.0017433128 -0.18402274 0.08527053 -0.041258708 0.11692058 -0.34836394 -0.024061138 0.16846007 0.26734293 0.114269905 0.42951083 0.04326676 0.24877658 -0.17724453 -0.194292 -0.5371715 -0.43304682\n",
      "ကုက္ကုစ္စ 0.20503645 0.15331632 -0.15970503 0.058487777 0.0704556 0.040250007 -0.057481445 -0.19448644 0.020324072 0.1995402 -0.2651161 0.08778776 0.492468 -0.4066327 0.21996026 0.005628406 0.13258024 0.30738834 -0.22437084 -0.056189228 -0.04698509 -0.102357104 -0.2062008 0.6472072 -0.166485 -0.016427102 -0.0023509995 -0.38404915 0.050420344 0.054055043 0.036625206 -0.105569884 -0.0617861 0.26237494 0.20200852 -0.23733056 -0.19193488 -0.118142016 0.06812437 -0.0043337005 -0.16681324 -0.33212236 0.11405078 -0.2597478 0.056086473 -0.18921973 -0.12715465 0.089052096 0.066308506 -0.008295855 0.19987626 0.2084764 -0.29262674 0.03353294 -0.18312646 0.17448477 0.22600481 -0.12456949 -0.03204798 0.119025365 -0.045889482 0.29576102 -0.17617704 0.24285811 -0.08315565 -0.026916811 0.23069657 0.20583649 -0.10801239 -0.21444231 0.06975542 -0.021206027 -0.048869215 -0.11130478 -0.1625409 0.067400046 -0.36800623 -0.30127418 -0.22657417 -0.39045128 0.07454491 -0.14564534 -0.05906972 0.02826118 -0.23768945 -0.008176513 0.01061538 0.1910325 -0.16913289 0.25863695 0.20419958 -0.12588626 0.1592865 -0.11190364 0.062089868 -0.09833311 -0.19556148 0.13379087 0.16463295 -0.2665381\n",
      "ဝိစ္စ -0.1554334 0.024039373 -0.037652735 -0.08088405 0.114527725 -0.04556298 -0.12290039 0.027864732 -0.012984173 -0.14834854 -0.17392732 0.06465291 0.349792 -0.40594053 -0.18451852 0.015245712 -0.20358084 0.10143587 -0.09219152 -0.00018691421 0.0982844 -0.07419096 0.016758386 0.19423854 -0.28043476 0.07282302 0.031581007 -0.41939217 -0.09923038 0.023396729 -0.038892724 -0.018286848 0.052159194 -0.002797238 0.067191646 -0.26512334 -0.14520617 0.041473567 0.032450594 0.041059792 -0.24224874 -0.1667705 -0.07869364 0.037051402 0.093970105 0.09377576 -0.12896098 0.100080885 -0.0014752866 0.20813134 -0.21149127 -0.028489823 -0.0072847083 -0.25623962 -0.2686316 0.32496127 0.15802495 -0.13391279 -0.033091173 0.35086453 -0.04957518 0.2369229 -0.13104267 0.22426327 0.12991577 0.0077484106 0.018055715 0.12655622 -0.16785504 -0.38114867 -0.072523266 0.012895191 -0.13524209 -0.115947194 -0.0045707147 0.25616738 -0.22794566 -0.3789474 0.3271211 -0.16168465 -0.060372643 -0.19626084 0.051042553 -0.29317805 -0.21256202 0.059377223 -0.012677662 0.11013025 -0.11636968 -0.13076161 -0.120241344 0.12137503 0.5251231 -0.17200543 0.34827095 -0.07514057 -0.13512692 -0.11572279 -0.14420164 -0.36492413\n"
     ]
    }
   ],
   "source": [
    "!tail ./fasttext-model/myfasttext_v1.vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e169cbe9-5f55-485e-b02f-8ee4ee3557af",
   "metadata": {},
   "source": [
    "Bash shell script ကို စ run ပြီ။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9d994c0-6648-4469-bf37-a1e269437b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Mlp language model:\n",
      "Epoch 1/10 (Training): 100%|█████████████████| 852/852 [00:06<00:00, 131.07it/s]\n",
      "Epoch 1, Training Loss: 2.5647\n",
      "Epoch 1/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 497.57it/s]\n",
      "Epoch 1, Validation Loss: 1.0576\n",
      "Best model saved at ./model/name/mlp.nofz.model with validation loss: 1.0576\n",
      "Epoch 2/10 (Training): 100%|█████████████████| 852/852 [00:05<00:00, 142.39it/s]\n",
      "Epoch 2, Training Loss: 1.0535\n",
      "Epoch 2/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 501.33it/s]\n",
      "Epoch 2, Validation Loss: 1.0549\n",
      "Best model saved at ./model/name/mlp.nofz.model with validation loss: 1.0549\n",
      "Epoch 3/10 (Training): 100%|█████████████████| 852/852 [00:06<00:00, 139.39it/s]\n",
      "Epoch 3, Training Loss: 1.0524\n",
      "Epoch 3/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 513.98it/s]\n",
      "Epoch 3, Validation Loss: 1.0545\n",
      "Best model saved at ./model/name/mlp.nofz.model with validation loss: 1.0545\n",
      "Epoch 4/10 (Training): 100%|█████████████████| 852/852 [00:06<00:00, 141.39it/s]\n",
      "Epoch 4, Training Loss: 1.0521\n",
      "Epoch 4/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 523.23it/s]\n",
      "Epoch 4, Validation Loss: 1.0543\n",
      "Best model saved at ./model/name/mlp.nofz.model with validation loss: 1.0543\n",
      "Epoch 5/10 (Training): 100%|█████████████████| 852/852 [00:06<00:00, 138.38it/s]\n",
      "Epoch 5, Training Loss: 1.0520\n",
      "Epoch 5/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 519.92it/s]\n",
      "Epoch 5, Validation Loss: 1.0543\n",
      "Best model saved at ./model/name/mlp.nofz.model with validation loss: 1.0543\n",
      "Epoch 6/10 (Training): 100%|█████████████████| 852/852 [00:06<00:00, 139.30it/s]\n",
      "Epoch 6, Training Loss: 1.0520\n",
      "Epoch 6/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 520.47it/s]\n",
      "Epoch 6, Validation Loss: 1.0542\n",
      "Best model saved at ./model/name/mlp.nofz.model with validation loss: 1.0542\n",
      "Epoch 7/10 (Training): 100%|█████████████████| 852/852 [00:06<00:00, 135.50it/s]\n",
      "Epoch 7, Training Loss: 1.0519\n",
      "Epoch 7/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 524.88it/s]\n",
      "Epoch 7, Validation Loss: 1.0542\n",
      "Best model saved at ./model/name/mlp.nofz.model with validation loss: 1.0542\n",
      "Epoch 8/10 (Training): 100%|█████████████████| 852/852 [00:06<00:00, 138.43it/s]\n",
      "Epoch 8, Training Loss: 1.0519\n",
      "Epoch 8/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 534.72it/s]\n",
      "Epoch 8, Validation Loss: 1.0542\n",
      "Best model saved at ./model/name/mlp.nofz.model with validation loss: 1.0542\n",
      "Epoch 9/10 (Training): 100%|█████████████████| 852/852 [00:06<00:00, 138.69it/s]\n",
      "Epoch 9, Training Loss: 1.0519\n",
      "Epoch 9/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 533.09it/s]\n",
      "Epoch 9, Validation Loss: 1.0542\n",
      "Best model saved at ./model/name/mlp.nofz.model with validation loss: 1.0542\n",
      "Epoch 10/10 (Training): 100%|████████████████| 852/852 [00:06<00:00, 138.44it/s]\n",
      "Epoch 10, Training Loss: 1.0519\n",
      "Epoch 10/10 (Validation): 100%|████████████████| 32/32 [00:00<00:00, 508.15it/s]\n",
      "Epoch 10, Validation Loss: 1.0541\n",
      "Best model saved at ./model/name/mlp.nofz.model with validation loss: 1.0541\n",
      "\n",
      "real\t1m4.453s\n",
      "user\t1m6.785s\n",
      "sys\t0m2.511s\n",
      "Text generation:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Generated Text 1: ရဲ ဒူ ဂန် ရုံး ကြူ ကြော ခြည် ဇမ့် ရား ကု ယူး ဟွေ ထိုး ထွဋ် ကြံ မှူး တက္ခ အဂ္ဂ ရွမ် ဖီး ဂျွန်း အု ကွန် ဇမ်း ရေ့ဒ်ဗ် ဣန္တာ ခိ ချားလ် ချူ ချူး မြ ဏ ဂန့် ရှဲလ် ဘေ ဂိုး ကတ္တီ ပါယ် စော စွာ ပွင့် စွန် ပေး ကိစ္စ သို ဂိတ် ဂျူး မဉ္ဇူ ပြုံး ထိုး ဝမ်း\n",
      "Generated Text 2: ရဲ မြေ ဘတ် ဆွမ့် ရေ့ဒ်ဗ် စမ်း ဝါလ် သမ္ဘူ ပေါင် မှီ ဋေ ကုံး ဆွေ ဖုဏ်း သံ လဲ့ ကွယ် ယောင် ဂျိုး တွမ် ညို့ ရှား မြင့် စံ သင်္ချာ ဧည့် အို မင်္ဂ သင်္ခ သံ ဥတ္တ ဂျို ရွှန်း စုံ လာမ် ထီး နွမ်း ကောင် ဆင်း ဝိန် ကဉ္စ အုတ် ဖိုး ချစ် ပြေ ပွါ ရှဲ ပီ ဗြ ဘွိုင်း ကျီ\n",
      "Generated Text 3: ရဲ လျှပ် ဃာ ဆာ ည အိန် ဟီး ကျ ဗီ ဒမ်း ကွန့် ကြင် ခေ စောလ် ရှာ ရစ် ဖြူး လက်စ် အားရ် သိမ် ဇင်း ကီး ကွမ်း ထိုက် ရွာ မိန် ဗေး ရေ ဒင်း ရှဲလ် နှီး ရွှေ့ ဂူ လွေ ကျန်း မြို့ တာ ဖွယ် သိမ့် ငိုက် လှီး ကို ကိမ် ဂျူး နှင်း လိ ကြံ လက္ခ တိန့် နမ် ပိုက်\n",
      "Generated Text 4: ရဲ လန် ဂုန် အိန် သိဒ္ဓိ ရိုး ဒူ ဂျန် ဇေါင်း ဇံ ဂျို အိဏ် လယ် နှဲမ်း ဖောင် ဿန်း မြဉ္ဇူ ဗေ မိန်း ခယ် ဂျက်ခ် ဆွင်း ခွမ်း ဂဲလ် မွမ် ရှန်း လာန် ကြ ဆွေ မူလ္လာ သြ ယိန်း လျာ ခုပ် ကြွမ် ကစ္စ ဆဲ ငြိမ့် ရှီ သီ ဂေါ် ပုံ သိမ့် ကြွက် မွမ်း ဒူး ကျွဲ ဒုလ် ခန် ရှင် အန်ဒ်\n",
      "Generated Text 5: ရဲ ပြန့် ဇေ ခို ဆာ စော် ရွက် ဒို့ဗ် ထိ ရွန်း နာ သေး စော် ဒေ ကွိဇ် ဘိုင် မစ် ချိုင်း ဇီ အိန္မာ ကျိုင်း ငု ဦး ရှု အက်စ် ဋေ အပ် ဗြာ မောင်း ဒေါင့် ဒစ် ဥက္ကာ သင့် ရိမ် ဟေး ရှိန် ဘွဲ့ ကျွဲ ဓီ လဲလ် ကျောင် လိမ်း ဒိုင် ဆွမ်း မှောင် က မျှော် နန် သျှမ်း လန့် ဆွင်\n",
      "Generated Text 6: ရဲ စွန် ချမ်း ထွဏ်း ဆောင် ရယ် နှဲမ် အိန္ဒြ ကျွယ် ထိုက် တိုက် ဂျယ် စိမ်း နန်းဒ် ဟိဏ်း ကြား ခင်း စ လိတ် ကြိုက် ဘတ် စက္ကန့် ထောင်း သဉ္ဇူ ကျောင်း ကြွ အေ ကောလ် ရှန်း ချား တွမ် ကန်း ဘွယ် ရှိမ်း ကက် နူး အဲ ပေါ် ထောင် နွေး ခွါ ရန်း ကီလ် ဂျွန်း ရုံ ဝိုင် ဂ ကြောင် ဂျူး ဂီ မို့စ်\n",
      "Generated Text 7: ရဲ ခြိမ့် အဲလ် ကုမ္မာ ဆိန်း ဣန္ဒ ယိမ့် ရု ငြိမ်း ရှိုး ဒေ့ဗ် တြီ ဟံ ကိန်း ဘယ်လ် ဒေ့ဗ် ဖိန် လှီး ဘင် ဇန္ဒား နွံ သေး ဘို ကိန္န လု ညွတ် သျှမ် ခမ်း မှူး ဂင့် ယော် ရှည် ဒု ခတ် ဗျော လွေ ဂို ကျင်း ဒေါသ် ခွား ဟွ သျှား ညား ဇမ္ဗူ ချိ ကြာ ပြောင်း ဝါး တုန် နှိုင်း စင်္ကြာ\n",
      "Generated Text 8: ရဲ ဟုန်း ဟင်း ချုံး ဒိတ် ခါ တောက် တိ အုန်း ပြုံး လူ စိုက် ဂျော် ဖြိုး ဖွေး ဖြင့် အိန္ဒာ ကွမ်း ခက် သိဉ္စည်း ပယ်လ် ဗို မွန်း လှောန် အမ္မ ပြန့် ဂျူ ဟီး ရှိန်း မြစ် ဒင့် ရိုင် နူး ဘက် သြ ဂီ ဟောက် ရွှေ့ လုတ် အီ ထား လော့ ကျင်း ကစ္စ ကျောက် လုံ ယန်း ဆပ် ကျစ် တုံး ကြာ\n",
      "Generated Text 9: ရဲ မိုင်းလ် ရုတ်စ် လျာ ချူ ခဏ် စင်္ကြာ ညွန် မူ ခိုင် ဇူး ကိုင် ညောင် လျော့ လဒ် အိန် ခမ့် ပါ့ ပယ် စောမ် လည်း ဂေ ယျာ သား ထော် သက္က ရွာ ရင့် ဘီ ပုမ်း နား ဆောင်း ပွါ ပေး စိုက် ညွန့် နော် ခဏ် ဿဏ် ဟွ ပုမ်း ဖုန်း ဒို့ဗ် ဘေ သွား မွေ့ မဲန် အဂ္ဂါ မုစ် ပါ လိန်း\n",
      "Generated Text 10: ရဲ မြန် ထူး ဂေ စီ ဂေ မီး ဗ လျာ ရှဲ လော့ လျှမ်း မြ ဒေ့ဗ် အူလ္လာ ဝိုင်း အင် ဒိမ့် လင်္ကာ ဇဉ် ဂ ဗြာ လျှို ပြုံ ထိုး မင်း အန် ရေ့စ် ကြယ် ဖျား မန်း တီးလ် ယုံ တုန် ခွား ယို ညောင် ဘေ မာရ် ဒယ်လ် ထွာ ဟုန် နာမ် နော် နို ပါးရ် ဝန် ဖို့ လင် ကက် သေ့\n",
      "\n",
      "real\t0m2.532s\n",
      "user\t0m5.308s\n",
      "sys\t0m2.351s\n",
      "Batch text generation from file:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Random Prompt Generated: ဖောင်\n",
      "Generated texts saved to ./output/name/mlp_nofz_gen_texts.txt\n",
      "\n",
      "real\t0m1.982s\n",
      "user\t0m4.807s\n",
      "sys\t0m2.358s\n",
      "Testing:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:429: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Testing: 100%|██████████| 16/16 [00:00<00:00, 52.73it/s]\n",
      "Average Perplexity on Test Data: 1.1139\n",
      "Average Cross-Entropy on Test Data: 0.1079\n",
      "\n",
      "real\t0m1.896s\n",
      "user\t0m4.732s\n",
      "sys\t0m2.326s\n",
      "Training Bilstm language model:\n",
      "Epoch 1/10 (Training): 100%|██████████████████| 852/852 [00:15<00:00, 54.71it/s]\n",
      "Epoch 1, Training Loss: 0.5006\n",
      "Epoch 1/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 170.19it/s]\n",
      "Epoch 1, Validation Loss: 0.3250\n",
      "Best model saved at ./model/name/bilstm.nofz.model with validation loss: 0.3250\n",
      "Epoch 2/10 (Training): 100%|██████████████████| 852/852 [00:15<00:00, 55.98it/s]\n",
      "Epoch 2, Training Loss: 0.3151\n",
      "Epoch 2/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 161.88it/s]\n",
      "Epoch 2, Validation Loss: 0.3100\n",
      "Best model saved at ./model/name/bilstm.nofz.model with validation loss: 0.3100\n",
      "Epoch 3/10 (Training): 100%|██████████████████| 852/852 [00:15<00:00, 55.97it/s]\n",
      "Epoch 3, Training Loss: 0.3075\n",
      "Epoch 3/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 164.37it/s]\n",
      "Epoch 3, Validation Loss: 0.3060\n",
      "Best model saved at ./model/name/bilstm.nofz.model with validation loss: 0.3060\n",
      "Epoch 4/10 (Training): 100%|██████████████████| 852/852 [00:15<00:00, 56.23it/s]\n",
      "Epoch 4, Training Loss: 0.3033\n",
      "Epoch 4/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 160.81it/s]\n",
      "Epoch 4, Validation Loss: 0.3013\n",
      "Best model saved at ./model/name/bilstm.nofz.model with validation loss: 0.3013\n",
      "Epoch 5/10 (Training): 100%|██████████████████| 852/852 [00:15<00:00, 56.14it/s]\n",
      "Epoch 5, Training Loss: 0.2916\n",
      "Epoch 5/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 159.96it/s]\n",
      "Epoch 5, Validation Loss: 0.2791\n",
      "Best model saved at ./model/name/bilstm.nofz.model with validation loss: 0.2791\n",
      "Epoch 6/10 (Training): 100%|██████████████████| 852/852 [00:15<00:00, 56.31it/s]\n",
      "Epoch 6, Training Loss: 0.2704\n",
      "Epoch 6/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 165.37it/s]\n",
      "Epoch 6, Validation Loss: 0.2568\n",
      "Best model saved at ./model/name/bilstm.nofz.model with validation loss: 0.2568\n",
      "Epoch 7/10 (Training): 100%|██████████████████| 852/852 [00:15<00:00, 55.98it/s]\n",
      "Epoch 7, Training Loss: 0.2315\n",
      "Epoch 7/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 158.96it/s]\n",
      "Epoch 7, Validation Loss: 0.1922\n",
      "Best model saved at ./model/name/bilstm.nofz.model with validation loss: 0.1922\n",
      "Epoch 8/10 (Training): 100%|██████████████████| 852/852 [00:15<00:00, 55.70it/s]\n",
      "Epoch 8, Training Loss: 0.1660\n",
      "Epoch 8/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 162.08it/s]\n",
      "Epoch 8, Validation Loss: 0.1338\n",
      "Best model saved at ./model/name/bilstm.nofz.model with validation loss: 0.1338\n",
      "Epoch 9/10 (Training): 100%|██████████████████| 852/852 [00:15<00:00, 56.08it/s]\n",
      "Epoch 9, Training Loss: 0.1118\n",
      "Epoch 9/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 167.76it/s]\n",
      "Epoch 9, Validation Loss: 0.0890\n",
      "Best model saved at ./model/name/bilstm.nofz.model with validation loss: 0.0890\n",
      "Epoch 10/10 (Training): 100%|█████████████████| 852/852 [00:15<00:00, 55.34it/s]\n",
      "Epoch 10, Training Loss: 0.0788\n",
      "Epoch 10/10 (Validation): 100%|████████████████| 32/32 [00:00<00:00, 166.66it/s]\n",
      "Epoch 10, Validation Loss: 0.0671\n",
      "Best model saved at ./model/name/bilstm.nofz.model with validation loss: 0.0671\n",
      "\n",
      "real\t2m37.752s\n",
      "user\t2m39.357s\n",
      "sys\t0m3.032s\n",
      "Text generation:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "Generated Text 1: ရဲ တောင် အူလ္လာ အဲ အူလ္လာ အူလ္လာ အူလ္လာ အူလ္လာ အူလ္လာ သိဉ္စည်း ဗွီ သိဉ္စည်း အူလ္လာ အူလ္လာ အူလ္လာ ရွာ ဗွီ ဗွီ ကျစ် တောင် သော့ သော့ ရွာ ကျစ် အူလ္လာ သော့ ဟို အူလ္လာ ဟို ရွာ ရွာ အူလ္လာ အူလ္လာ အူလ္လာ [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Generated Text 2: ရဲ ဗွီ အူလ္လာ အူလ္လာ အူလ္လာ ရွာ အူလ္လာ သော့ အူလ္လာ အူလ္လာ အူလ္လာ ကျစ် ရွာ ဟို သိဉ္စည်း တောင် အူလ္လာ အူလ္လာ အူလ္လာ တောင် အူလ္လာ အူလ္လာ အူလ္လာ ကျစ် သော့ ကျစ် ကျစ် ရွာ သိဉ္စည်း ဗွီ ရွာ အူလ္လာ သော့ ဟို သော့ ဟို ဟို ကျစ် ကျစ် သော့ ရွာ အူလ္လာ ရွာ အူလ္လာ အူလ္လာ ကျစ် ဗွီ ဗွီ သိဉ္စည်း ရွာ ကျစ်\n",
      "Generated Text 3: ရဲ သော့ ရွာ အူလ္လာ အူလ္လာ အူလ္လာ အူလ္လာ အူလ္လာ အူလ္လာ သိဉ္စည်း သော့ သော့ သော့ အူလ္လာ သိဉ္စည်း အူလ္လာ ရွာ အူလ္လာ အူလ္လာ အူလ္လာ ရွာ ရွာ သိဉ္စည်း သိဉ္စည်း ကျစ် ဟို ဗွီ ကျစ် အူလ္လာ ကျစ် ဟို သော့ ဗွီ ရွာ ရွာ အူလ္လာ ရွာ ဗွီ အူလ္လာ အူလ္လာ အူလ္လာ ရွာ ရွာ ရွာ အူလ္လာ အူလ္လာ ရွာ အူလ္လာ သိဉ္စည်း ဗွီ သော့\n",
      "Generated Text 4: ရဲ ဗွီ ရွာ အူလ္လာ အူလ္လာ အူလ္လာ အူလ္လာ သိဉ္စည်း သော့ ဗွီ အူလ္လာ အူလ္လာ အူလ္လာ ကျစ် အူလ္လာ သော့ အူလ္လာ အူလ္လာ ဟို ရွာ ရွာ ဗွီ သော့ ကျစ် ဗွီ ကျစ် အူလ္လာ ဗွီ ရွာ သိဉ္စည်း ဗွီ အူလ္လာ အူလ္လာ အူလ္လာ အူလ္လာ အူလ္လာ အူလ္လာ အူလ္လာ အူလ္လာ အူလ္လာ အူလ္လာ သော့ သော့ အူလ္လာ ဗွီ အူလ္လာ အူလ္လာ သော့ အူလ္လာ အူလ္လာ ရွာ\n",
      "Generated Text 5: ရဲ အူလ္လာ အူလ္လာ အူလ္လာ ရွာ အူလ္လာ ရွာ အူလ္လာ သိဉ္စည်း ရွာ ဟို ရွာ ဗွီ ဟို အူလ္လာ သော့ တောင် ဗွီ ဗွီ ဗွီ ရွာ အူလ္လာ အူလ္လာ သိဉ္စည်း သိဉ္စည်း သော့ သော့ ရွာ အူလ္လာ ရွာ အူလ္လာ အူလ္လာ အူလ္လာ အူလ္လာ အူလ္လာ အူလ္လာ အူလ္လာ သိဉ္စည်း ရွာ အူလ္လာ သိဉ္စည်း အူလ္လာ အူလ္လာ သိဉ္စည်း သော့ ရွာ သော့ အူလ္လာ အူလ္လာ အူလ္လာ အူလ္လာ\n",
      "Generated Text 6: ရဲ သိဉ္စည်း သော့ ကျစ် ဗွီ ရွာ ကျစ် ဗွီ အူလ္လာ သော့ ဗွီ သိဉ္စည်း ကျစ် သော့ ကျစ် ရွာ အူလ္လာ ရွာ ရွာ ရွာ အူလ္လာ အူလ္လာ ဗွီ အူလ္လာ အူလ္လာ ကျစ် သိဉ္စည်း ရွာ ဟို ရွာ ကျစ် ဟို ဗွီ သော့ သိဉ္စည်း ကျစ် သော့ ရွာ ဗွီ ဟို ရွာ အူလ္လာ အူလ္လာ အူလ္လာ သိဉ္စည်း အူလ္လာ အူလ္လာ သော့ ကျစ် သိဉ္စည်း အူလ္လာ\n",
      "Generated Text 7: ရဲ အူလ္လာ အူလ္လာ ရွာ အူလ္လာ အူလ္လာ သိဉ္စည်း ရွာ အူလ္လာ ကျစ် သိဉ္စည်း သိဉ္စည်း ရွာ ရွာ ကျစ် သော့ အူလ္လာ ကျစ် သိဉ္စည်း ရွာ ကျစ် သိဉ္စည်း သိဉ္စည်း အူလ္လာ အူလ္လာ အူလ္လာ သိဉ္စည်း ကျစ် ဟို ဟို အူလ္လာ ရွာ အူလ္လာ အူလ္လာ အူလ္လာ ကျစ် ဟို ဟို သော့ ဟို အူလ္လာ ရွာ အူလ္လာ အူလ္လာ အူလ္လာ သိဉ္စည်း အူလ္လာ ဗွီ သိဉ္စည်း အူလ္လာ အူလ္လာ\n",
      "Generated Text 8: ရဲ ဗွီ ရွာ ကျစ် သော့ အူလ္လာ အူလ္လာ သိဉ္စည်း ဗွီ အူလ္လာ အူလ္လာ ကျစ် ကျစ် အူလ္လာ သော့ ဟို သော့ ဟို ရွာ သော့ ကျစ် သော့ သိဉ္စည်း အူလ္လာ ရွာ သော့ အူလ္လာ ရွာ ဗွီ အူလ္လာ အူလ္လာ အူလ္လာ သိဉ္စည်း အူလ္လာ အူလ္လာ [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Generated Text 9: ရဲ ရွာ သိဉ္စည်း အူလ္လာ ဟို အူလ္လာ သိဉ္စည်း သော့ ဟို အူလ္လာ သော့ သိဉ္စည်း အူလ္လာ ရွာ သိဉ္စည်း အူလ္လာ ဗွီ အူလ္လာ သိဉ္စည်း သိဉ္စည်း အူလ္လာ သိဉ္စည်း ဗွီ ရွာ အူလ္လာ တောင် အူလ္လာ အူလ္လာ အူလ္လာ ကျစ် သိဉ္စည်း သိဉ္စည်း ရွာ ရွာ အူလ္လာ အူလ္လာ အူလ္လာ ရွာ တောင် ဟို ဗွီ ကျစ် ရွာ အူလ္လာ သိဉ္စည်း ဗွီ ဟို သိဉ္စည်း ကျစ် အူလ္လာ ဗွီ\n",
      "Generated Text 10: ရဲ ကျစ် ရွာ တောင် သိဉ္စည်း ရွာ ဗွီ အူလ္လာ ဟို ဗွီ ရွာ ရွာ ရွာ ဗွီ အူလ္လာ တောင် အူလ္လာ သိဉ္စည်း အူလ္လာ သော့ ကျစ် ဗွီ ရွာ ကျစ် သိဉ္စည်း တောင် အူလ္လာ သိဉ္စည်း ဗွီ သော့ အူလ္လာ အူလ္လာ အူလ္လာ အူလ္လာ အူလ္လာ အူလ္လာ အူလ္လာ အူလ္လာ ရွာ ဗွီ အူလ္လာ ရွာ သော့ အူလ္လာ အူလ္လာ သိဉ္စည်း သိဉ္စည်း အူလ္လာ အူလ္လာ အူလ္လာ အူလ္လာ\n",
      "\n",
      "real\t0m2.299s\n",
      "user\t0m5.040s\n",
      "sys\t0m2.422s\n",
      "Batch text generation from file:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "Random Prompt Generated: ဆော်\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "All logits are -Inf after filtering! Fallback to raw logits.\n",
      "Generated texts saved to ./output/name/bilstm_nofz_gen_texts.txt\n",
      "\n",
      "real\t0m2.152s\n",
      "user\t0m4.853s\n",
      "sys\t0m2.430s\n",
      "Testing:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:429: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Testing: 100%|██████████| 16/16 [00:00<00:00, 42.17it/s]\n",
      "Average Perplexity on Test Data: 1.0630\n",
      "Average Cross-Entropy on Test Data: 0.0611\n",
      "\n",
      "real\t0m2.169s\n",
      "user\t0m4.992s\n",
      "sys\t0m2.387s\n",
      "Training Transformer language model:\n",
      "Epoch 1/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 220.67it/s]\n",
      "Epoch 1, Training Loss: 0.7195\n",
      "Epoch 1/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 611.54it/s]\n",
      "Epoch 1, Validation Loss: 0.2932\n",
      "Best model saved at ./model/name/transformer.nofz.model with validation loss: 0.2932\n",
      "Epoch 2/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 230.26it/s]\n",
      "Epoch 2, Training Loss: 0.1756\n",
      "Epoch 2/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 604.94it/s]\n",
      "Epoch 2, Validation Loss: 0.0860\n",
      "Best model saved at ./model/name/transformer.nofz.model with validation loss: 0.0860\n",
      "Epoch 3/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 233.79it/s]\n",
      "Epoch 3, Training Loss: 0.0680\n",
      "Epoch 3/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 628.10it/s]\n",
      "Epoch 3, Validation Loss: 0.0461\n",
      "Best model saved at ./model/name/transformer.nofz.model with validation loss: 0.0461\n",
      "Epoch 4/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 241.48it/s]\n",
      "Epoch 4, Training Loss: 0.0386\n",
      "Epoch 4/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 569.09it/s]\n",
      "Epoch 4, Validation Loss: 0.0314\n",
      "Best model saved at ./model/name/transformer.nofz.model with validation loss: 0.0314\n",
      "Epoch 5/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 238.03it/s]\n",
      "Epoch 5, Training Loss: 0.0258\n",
      "Epoch 5/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 626.62it/s]\n",
      "Epoch 5, Validation Loss: 0.0233\n",
      "Best model saved at ./model/name/transformer.nofz.model with validation loss: 0.0233\n",
      "Epoch 6/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 242.91it/s]\n",
      "Epoch 6, Training Loss: 0.0188\n",
      "Epoch 6/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 580.23it/s]\n",
      "Epoch 6, Validation Loss: 0.0181\n",
      "Best model saved at ./model/name/transformer.nofz.model with validation loss: 0.0181\n",
      "Epoch 7/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 236.65it/s]\n",
      "Epoch 7, Training Loss: 0.0144\n",
      "Epoch 7/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 625.63it/s]\n",
      "Epoch 7, Validation Loss: 0.0151\n",
      "Best model saved at ./model/name/transformer.nofz.model with validation loss: 0.0151\n",
      "Epoch 8/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 240.64it/s]\n",
      "Epoch 8, Training Loss: 0.0112\n",
      "Epoch 8/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 621.06it/s]\n",
      "Epoch 8, Validation Loss: 0.0120\n",
      "Best model saved at ./model/name/transformer.nofz.model with validation loss: 0.0120\n",
      "Epoch 9/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 249.35it/s]\n",
      "Epoch 9, Training Loss: 0.0090\n",
      "Epoch 9/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 620.78it/s]\n",
      "Epoch 9, Validation Loss: 0.0110\n",
      "Best model saved at ./model/name/transformer.nofz.model with validation loss: 0.0110\n",
      "Epoch 10/10 (Training): 100%|████████████████| 852/852 [00:03<00:00, 246.12it/s]\n",
      "Epoch 10, Training Loss: 0.0073\n",
      "Epoch 10/10 (Validation): 100%|████████████████| 32/32 [00:00<00:00, 622.28it/s]\n",
      "Epoch 10, Validation Loss: 0.0097\n",
      "Best model saved at ./model/name/transformer.nofz.model with validation loss: 0.0097\n",
      "\n",
      "real\t0m38.569s\n",
      "user\t0m40.854s\n",
      "sys\t0m2.442s\n",
      "Text generation:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Generated Text 1: ရဲ ခက် ဒေ အိန္ဒု ရှဲ ဒိုး ပုံ့ အိုင် ရှဲ ဆွတ် ရှဲ နှဲမ် တန့် ကန့် မြဲ နော် ကွန့် သြ နဲမ် မဲန် ပွန် လွဲ တီးလ် ရှဲ ဂန္ဓာ ဇမ် ဇောင်း ဆည်း ပုံ့ စဉ့် အန့် ဆင့် ကွမ်း စာ ဒိမ်း ဥက္ကာ ကွယ် နှစ် ကျော နင် ဂျွန်း လျင် ကွန့် မှိုင် ရှဲ ဖုဏ်း ကင် ရှဲ ဉာဏ် ရှဲ ခုပ်\n",
      "Generated Text 2: ရဲ တီလ် ဒိုး ပီး ပုံ့ ခွန်း ရှဲ ပုံ့ ချား စွန် ရှဲ ကီလ် ဂျီး အိန္ဒာ ကြံ ပြောင် စိုက် နောင် ချမ်း နွမ်း သျှမ်း မှုန်း သင့် ရေ့ဒ်ဗ် ဗျာလ် နင်္ဂ ဝင့် မျာ ရှဲ မူး လှိုင်း သေး ဖန် ရှား စက္ကန့် ဟံ ယှဉ် ခွေ ချင် လော် ရှဲ သေ့ ကစ် ချွတ် ဂူး လက်စ် ဝိုက် ဂီ ဝိုက် ရှဲ မိုး\n",
      "Generated Text 3: ရဲ ရစ္စ အွန် ပုံ့ ခွန်း ရှဲ ပီး ရှဲ ရှဲ ဟေ ခွန်း ဟင်း မိုး သိပ္ပံ ရုတ်စ် မွင်း ကွေ့ သိုက် အဉ္စ ကော် ကြူး ရှဲ နန့် ရှဲ ဟုန် သဒ္ဒါ ရွာ ဟယ် ရှဲ ဆူး လိ ကောက် ဖိန် ဒိုး အော် ဏီ တို တန့် ရှဲ ဇီ ရှဲ ထာ ဒွပ် ရှဲ ရှဲ ပပ်ဖ် ကြူး ရှဲ ရိုင်း ရှဲ ဖ\n",
      "Generated Text 4: ရဲ သက် ဒု ပုံ့ ရှဲ အိုင် ရှဲ ခွန်း ရှဲ လို့ ခွန်း ဒန် နိုး ဒုံ လောဒ် ချိန်း ဆေး နိုး မဲန် နင် ထိန် ရှဲ နွေ ရှဲ ပယ်လ် ဟင်လ် လောင်း ကြိုး ရှဲ ထက် ဟမ်း ဂျယ် လွင် ရှဲ ဂေ ယျ ခေါင် ဟမ် ရှဲ ခြည် ရှဲ ချင် သင်္ခ ရှဲ ရှဲ ဇန် လွန်း ရှဲ မောင်း ရှဲ ဘယ်\n",
      "Generated Text 5: ရဲ ကျော ခွန်း လူ ကောန် ခွန်း ရှဲ ဒိုး ရှဲ ခင် ရှဲ ဇွန်း ဥမ္မာ တီလ် ဂျား ကွန့် ဖု ထက် ဋာ သုန် ဝေ ကွာ ဆပ် ကပ် ညု ဖွေး ဂျူး ဟ ဂူး ကျုံ ဒွန်း ကုန် ယား ယော ဟို့စ် ညို ကြိုင်း ဆန့် ရှဲ အဉ္ဇူ ရှဲ ခုံ နာမ် ရှဲ ရှဲ ဉာဏ် ဘုံ ရှဲ နီ ရှဲ ကွေ့\n",
      "Generated Text 6: ရဲ သာ ဇုန် ရှဲ ခွန်း ရှဲ ဂူး အိုင် ရှဲ ဆဲ ခွန်း ဒိုး နွေး ဝါး သိမ့် မို့ ငြိမ်း ရှဲ ဖြိုး ခေါင် ညောင် ဂျူ ဒေါင် လျှပ် ရှဲ ဒိန်း ထည် လျှမ်း ရှဲ ရား ချဲ့ ရှဲ ဟို ဖတ် ကျီ ဝဏ္ဏ ဂူး ခေါမ် ချိန် လင်္ကာ ရှဲ ဟဲ ဒ ရဲ ခွန်း ထင် ချိတ် ညွှန်း ရှဲ ရှဲ ဆယ်\n",
      "Generated Text 7: ရဲ ကိုင်း ဂူး ဒိုး ဒိုး ခွန်း ပုံ့ ဂူး ဂူး ရှဲ ရှဲ ဝင်း ဒယ်လ် တွယ် ဒွန်း အို ဗီ မွမ် ပါ ဣန္ဒ မိုင်းလ် ဇော် ဘုဏ်း တန် ရှဲ ဟို့စ် ဘတ် တုံ ခွန်း ရှိုင်း တုန်း ချက်စ် ငုံ တက္ခ [PAD] စိန် ရေး ရင့် ကတ် လာ ဂူး ကျိမ် ကုန် အီး ရှဲ သား ထိုက် ရှဲ အယ်လ် ရှဲ လာမ်\n",
      "Generated Text 8: ရဲ ကော် [PAD] မောင်း မြူ အိုင် ရှဲ ရှဲ ရှဲ ငြိမ့် ရှဲ လုတ် ဇူ လွေ ကျွန် အုပ် ကြို ထိုင် တုန်း မဲန်း သိမ်း ကြိုး ဥဂ္ဂါ ရှဲ ဘို့ ခါ ဆာ ဘယ်လ် ဒိုး ဣန္ဒာ ပယ်လ် ရင့် ကျွမ်း သိမ့် ဘဲလ် လန် ဒွပ် ရ လွှင် လဲ ရှဲ ဝံ ဒိန် ဂူး ခွန်း ဆွေး စဉ် ရှဲ ကပ် ရှဲ ဂိမ်း\n",
      "Generated Text 9: ရဲ စိမ် ဂူး ရှဲ ဒိုး အိုင် ရှဲ မြူ ခွန်း ဘုတ် ရှဲ တိမ်း မွိုင် အူလ္လာ လိုင်း ထီး ရှဲလ် ငါး မွေ့ အိဏ်း မု လွှင် ဖို့ ကမ္ဘာ ထောင် မာ လွယ် ဒို ရှဲ ထိပ် တီး ကတ် ဖော ကော့ စေး မွန် ဂိမ် ထော် ပြုံး အော် ရှဲ တီး ပါးရ် ဒိုင်း မွန်း ရှဲ ထိ ဆန် ရှဲ ရှဲ ရွက်\n",
      "Generated Text 10: ရဲ ဒါ ကြို ရှဲ ရှဲ မြူ ရှဲ ဂူး ရှဲ သတ် ရှဲ ဂင့် ဖေ ညု ချိုင်း ဖို့ ချက်စ် ဂတ် ဘယ်လ် ဇီ ထီး ဒါးလ် ခဲ သာ အဉ္စ ခဏ် ကျောက် ကိ မြူ ဖန့် ပီး ကုံး ဂျတ် ဝိ ပါ့ ငွေ ချမ်း အုပ် မင်္ဂ ဘီ ဂူး ဆွယ် ရွမ်း ဟ ရှဲ သန်း ရှဲ ရှဲ ကျီး အိုင် လက်ျာ\n",
      "\n",
      "real\t0m2.592s\n",
      "user\t0m5.406s\n",
      "sys\t0m2.363s\n",
      "Batch text generation from file:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Random Prompt Generated: ပ\n",
      "Generated texts saved to ./output/name/transformer_nofz_gen_texts.txt\n",
      "\n",
      "real\t0m2.134s\n",
      "user\t0m4.920s\n",
      "sys\t0m2.417s\n",
      "Testing:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:429: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Testing: 100%|██████████| 16/16 [00:00<00:00, 49.02it/s]\n",
      "Average Perplexity on Test Data: 1.0086\n",
      "Average Cross-Entropy on Test Data: 0.0085\n",
      "\n",
      "real\t0m1.910s\n",
      "user\t0m4.684s\n",
      "sys\t0m2.409s\n",
      "Training Bert language model:\n",
      "Epoch 1/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 216.89it/s]\n",
      "Epoch 1, Training Loss: 0.7259\n",
      "Epoch 1/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 630.94it/s]\n",
      "Epoch 1, Validation Loss: 0.2386\n",
      "Best model saved at ./model/name/bert.nofz.model with validation loss: 0.2386\n",
      "Epoch 2/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 230.21it/s]\n",
      "Epoch 2, Training Loss: 0.1530\n",
      "Epoch 2/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 628.00it/s]\n",
      "Epoch 2, Validation Loss: 0.0788\n",
      "Best model saved at ./model/name/bert.nofz.model with validation loss: 0.0788\n",
      "Epoch 3/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 235.89it/s]\n",
      "Epoch 3, Training Loss: 0.0636\n",
      "Epoch 3/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 631.75it/s]\n",
      "Epoch 3, Validation Loss: 0.0439\n",
      "Best model saved at ./model/name/bert.nofz.model with validation loss: 0.0439\n",
      "Epoch 4/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 244.13it/s]\n",
      "Epoch 4, Training Loss: 0.0370\n",
      "Epoch 4/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 621.60it/s]\n",
      "Epoch 4, Validation Loss: 0.0304\n",
      "Best model saved at ./model/name/bert.nofz.model with validation loss: 0.0304\n",
      "Epoch 5/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 242.13it/s]\n",
      "Epoch 5, Training Loss: 0.0252\n",
      "Epoch 5/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 611.92it/s]\n",
      "Epoch 5, Validation Loss: 0.0230\n",
      "Best model saved at ./model/name/bert.nofz.model with validation loss: 0.0230\n",
      "Epoch 6/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 233.12it/s]\n",
      "Epoch 6, Training Loss: 0.0184\n",
      "Epoch 6/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 629.89it/s]\n",
      "Epoch 6, Validation Loss: 0.0185\n",
      "Best model saved at ./model/name/bert.nofz.model with validation loss: 0.0185\n",
      "Epoch 7/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 241.40it/s]\n",
      "Epoch 7, Training Loss: 0.0142\n",
      "Epoch 7/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 619.27it/s]\n",
      "Epoch 7, Validation Loss: 0.0154\n",
      "Best model saved at ./model/name/bert.nofz.model with validation loss: 0.0154\n",
      "Epoch 8/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 235.42it/s]\n",
      "Epoch 8, Training Loss: 0.0112\n",
      "Epoch 8/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 611.98it/s]\n",
      "Epoch 8, Validation Loss: 0.0131\n",
      "Best model saved at ./model/name/bert.nofz.model with validation loss: 0.0131\n",
      "Epoch 9/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 229.19it/s]\n",
      "Epoch 9, Training Loss: 0.0090\n",
      "Epoch 9/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 615.47it/s]\n",
      "Epoch 9, Validation Loss: 0.0113\n",
      "Best model saved at ./model/name/bert.nofz.model with validation loss: 0.0113\n",
      "Epoch 10/10 (Training): 100%|████████████████| 852/852 [00:03<00:00, 234.71it/s]\n",
      "Epoch 10, Training Loss: 0.0074\n",
      "Epoch 10/10 (Validation): 100%|████████████████| 32/32 [00:00<00:00, 647.32it/s]\n",
      "Epoch 10, Validation Loss: 0.0101\n",
      "Best model saved at ./model/name/bert.nofz.model with validation loss: 0.0101\n",
      "\n",
      "real\t0m39.107s\n",
      "user\t0m41.296s\n",
      "sys\t0m2.497s\n",
      "Text generation:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Generated Text 1: ရဲ ချော် မယ် ဒိတ် မူ ယ ရာဇ် ရှမ် ဝန် ပွ ဒိတ် ကျင် ဒိတ် ဒိတ် နူး ရင် ဒိတ် မြူး ဟင်း သိဓ္ဓတ် မွမ်း ဒိတ် ကျေ ဒိတ် ဒိတ် ရုံး ထန် အက် ရှမ် ကုန် အိန္ဒာ မိန် ဒိတ် ဒိတ် ဇိတ် ဘ ဒိတ် ထန် ဒိတ် ဒွန်း ထန် အဲင်း ဒိတ် ဒိတ် ဆုမ်း ဘိ အုပ် စင် ဒိတ် စေ ဒိတ်\n",
      "Generated Text 2: ရဲ နာမ် ရှမ် ဒိတ် မောရ် သဉ္ဇ ထန် ဒိတ် ခု ဒိတ် ဒိတ် မြစ် ကာ ဒိတ် နိုင်း ခုပ် ဒိတ် လောင်ဝ် ဟိန်း ဌေ ဂျီး ဒိတ် ဈာန် ဒိတ် ထန် ချက်စ် နဲမ်း ဆပ် ဒိတ် ရုဏ်း မန် တိုက် ဒိတ် ဒိတ် လစ် ပြည် ဒိတ် ဒိတ် ဒိတ် နော် ကာ မာ ပွ ထန် စီး ကို ဂဲလ် ဟဲ မွင်း မီး ရှည်\n",
      "Generated Text 3: ရဲ ယယ် ဒိတ် ဂုန် ဒိတ် ဗေ နဲမ်း နဲမ်း ဂျူး ယှဉ် ဒိတ် ကျူ ဒိတ် ဒိတ် ချား ခွါ ဒိတ် ရေ အော် လိမ်း ဒိမ်း ထန် ပျို ဒိတ် ပွ ဝိုင် ဒိတ် မွေ့ ဒိတ် ဦး ဒိတ် ယဉ် လုံ ဒိတ် ဟူး သိမ့် ဒိတ် ကာ ဒိတ် အံ ဒိတ် နွမ်း ထန် ပွ ရည် လျှံ ဒိုင် ဘင်း ဒိတ် လမ်း ထန်\n",
      "Generated Text 4: ရဲ တယ်လ် ဒိတ် ဗျာ ချောင်း ဒိတ် ဒိတ် ဒိတ် ထယ် ဆပ် ဒိတ် ဉာဏ် ထန် ဒိတ် ညွှန့် ဒိတ် ဒိတ် နာမ် လိုင် ကပ် အိဇ္ဇာ ဒိတ် ရှိမ်း ထန် ဒိတ် ဘို ထန် မိုင်းလ် ဒိတ် ချွန်း ယာန် ရမ် ဒိတ် ပွ ကဲ ရိမ် ပွ ဒိတ် ထန် မိ ရှမ် ဟိန်း ထန် ရှမ် ခဲ အဲင်န် တီးလ် ခက်ခ် ပိုင် ဒိတ် ကိုင်း\n",
      "Generated Text 5: ရဲ ထာသ် ရှမ် ဒိတ် ဆိုင်း လာန်း ထန် ဒိတ် နှဲမ် ဘယ် ဒိတ် အန် ပွ ဒိတ် လိုင် ဗစ် ဒိတ် ဟဲ တြီ အိန္ဒြေ ကြ ဒိတ် သောင်း ထန် ဒိတ် လက် ပွ ဂဲလ် နဲမ်း ကျင့် ဝိုက် သီး ဒိတ် ဒိတ် ရှု သုံး ဒိတ် ထန် ဒိတ် ရင့် ဒိတ် ကြင်း ပွ ဒိတ် ယိန်း နောင် အဏ္ဏ ညိမ့် ဒိတ် ခြယ် ဒိတ်\n",
      "Generated Text 6: ရဲ ဂန္ဓ ပွ ပွ နဲမ်း နဲမ်း မယ် ဒိတ် ကီလ် ဒိတ် ဒိတ် ရိမ် ထန် ထန် ဆယ် ကော ဒိတ် အိန္မာ ချောင်း ဘွဲ အင် နဲမ်း နန့် ဒိတ် ဒိတ် အိုင် ဒိတ် သောင်း ထန် ဒိတ် ချွန် မွန်း ထန် ဒိတ် ဂျွန် ပြောင် ထန် ပွ ဒိတ် ဂျူ ဒိတ် နှဲမ်း နဲမ်း ထန် နွေး ဆွန်း အီ မန့် တ တား ဒိတ်\n",
      "Generated Text 7: ရဲ သန္တာ ဆမ် ဒိတ် ထော် သဉ္ဇ ပွ ကာ ဖိန် ဒိတ် ဒိတ် ဂျက်ခ် ဒိတ် ဒိတ် ဖူး သဒ္ဒါ ကာ အီ ဂျား စက္ကန့် ငြိမ့် ဒိတ် သဉ္ဇာ ဒိတ် ထန် ယဉ်း နဲမ်း ကုံး ဒိတ် စိ ကဲ ဆိုက် ဒိတ် ပွ လျှမ် ကောန် ထန် ထန် ဒိတ် ဖူ ရှမ် လူ မယ် ဒိတ် ဟီး မြတ် တောင်း လဲန်း မြဉ္ဇူ ဆမ်း ဒိတ်\n",
      "Generated Text 8: ရဲ ဆွမ့် ကာ လျှန် သဉ္ဇ ထန် ဆွမ့် ထန် ဂျိမ်းစ် ဒိတ် ဒိတ် ကျိန်း ဒိတ် ထန် မေ ဿ ဒိတ် ဒန် လျင့် အစ် ကြား ဒိတ် ဗေး ဒိတ် ဒိတ် ငိုက် ပွ သျှန် ထန် ဒိတ် ကက် မြေ ပွ ဒိတ် ကျော့ ဆီ ဒိတ် ရှမ် ဒိတ် ဗျော ပွ ကြိုင် ဒိတ် ဒိတ် အဲမ် ဂျာလ် ကောင်း ဟတ် မဉ္ဇူ ဂျိမ်းစ် ဒိတ်\n",
      "Generated Text 9: ရဲ သွား ဒိတ် ဂဂ္ဂါ ဒိတ် သျှန်း ထန် ဒိတ် ထည် ဒိတ် ဒိတ် ချာ ဒိတ် ဒိတ် ကန့် ဒိတ် ဒိတ် မိုင်း ဗား ဒေါ မိုင်းလ် ပွ တီ ဒိတ် ဒိတ် မို့စ် ဒိတ် မာန် ဒိတ် ကြူ ဆူး အဲ ဒိတ် ရှမ် ဒါ ငု ဒိတ် နဲမ်း ဒိတ် ဝတ် ရှမ် ပိုက် ပွ ဒိတ် ဂန့် ဆောမ်း ညောင် လိန်း ဆင် အံ့ ဒိတ်\n",
      "Generated Text 10: ရဲ တော ထန် ချန်း ဒိတ် ဝမ် ထန် ထန် ယော် ဒိတ် ဒိတ် ရော ဒိတ် ဒိတ် ဖွင့် အိစ် ဒိတ် ဖေ လွန်း ငုံ ခန်း ရှမ် စက္ကန့် ဒိတ် ကာ ညိမ်း ပွ ဆံ ထန် ဒိတ် မှာ ဆိုက် ဒိတ် ဒိတ် စေး ကျစ် ထန် ဒိတ် ဒိတ် ဗျာ ရှမ် အဲန်း ဒိတ် ထန် ထော် ကိုက် ဖေါ ရေ့ဒ်ဗ် ပဲန်း အဲန်း ဒိတ်\n",
      "\n",
      "real\t0m2.621s\n",
      "user\t0m5.447s\n",
      "sys\t0m2.355s\n",
      "Batch text generation from file:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Random Prompt Generated: ညွန့်\n",
      "Generated texts saved to ./output/name/bert_nofz_gen_texts.txt\n",
      "\n",
      "real\t0m2.188s\n",
      "user\t0m4.896s\n",
      "sys\t0m2.279s\n",
      "Testing:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:429: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Testing: 100%|██████████| 16/16 [00:00<00:00, 50.02it/s]\n",
      "Average Perplexity on Test Data: 1.0089\n",
      "Average Cross-Entropy on Test Data: 0.0089\n",
      "\n",
      "real\t0m1.930s\n",
      "user\t0m4.703s\n",
      "sys\t0m2.418s\n",
      "Training Gpt language model:\n",
      "Epoch 1/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 252.79it/s]\n",
      "Epoch 1, Training Loss: 0.3849\n",
      "Epoch 1/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 743.09it/s]\n",
      "Epoch 1, Validation Loss: 0.0267\n",
      "Best model saved at ./model/name/gpt.nofz.model with validation loss: 0.0267\n",
      "Epoch 2/10 (Training): 100%|█████████████████| 852/852 [00:02<00:00, 285.07it/s]\n",
      "Epoch 2, Training Loss: 0.0119\n",
      "Epoch 2/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 735.37it/s]\n",
      "Epoch 2, Validation Loss: 0.0053\n",
      "Best model saved at ./model/name/gpt.nofz.model with validation loss: 0.0053\n",
      "Epoch 3/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 276.85it/s]\n",
      "Epoch 3, Training Loss: 0.0035\n",
      "Epoch 3/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 754.28it/s]\n",
      "Epoch 3, Validation Loss: 0.0030\n",
      "Best model saved at ./model/name/gpt.nofz.model with validation loss: 0.0030\n",
      "Epoch 4/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 273.66it/s]\n",
      "Epoch 4, Training Loss: 0.0016\n",
      "Epoch 4/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 769.28it/s]\n",
      "Epoch 4, Validation Loss: 0.0025\n",
      "Best model saved at ./model/name/gpt.nofz.model with validation loss: 0.0025\n",
      "Epoch 5/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 275.66it/s]\n",
      "Epoch 5, Training Loss: 0.0009\n",
      "Epoch 5/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 772.21it/s]\n",
      "Epoch 5, Validation Loss: 0.0020\n",
      "Best model saved at ./model/name/gpt.nofz.model with validation loss: 0.0020\n",
      "Epoch 6/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 268.44it/s]\n",
      "Epoch 6, Training Loss: 0.0006\n",
      "Epoch 6/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 735.60it/s]\n",
      "Epoch 6, Validation Loss: 0.0010\n",
      "Best model saved at ./model/name/gpt.nofz.model with validation loss: 0.0010\n",
      "Epoch 7/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 273.19it/s]\n",
      "Epoch 7, Training Loss: 0.0003\n",
      "Epoch 7/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 760.83it/s]\n",
      "Epoch 7, Validation Loss: 0.0018\n",
      "Epoch 8/10 (Training): 100%|█████████████████| 852/852 [00:02<00:00, 285.73it/s]\n",
      "Epoch 8, Training Loss: 0.0002\n",
      "Epoch 8/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 717.16it/s]\n",
      "Epoch 8, Validation Loss: 0.0033\n",
      "Epoch 9/10 (Training): 100%|█████████████████| 852/852 [00:03<00:00, 280.74it/s]\n",
      "Epoch 9, Training Loss: 0.0001\n",
      "Epoch 9/10 (Validation): 100%|█████████████████| 32/32 [00:00<00:00, 745.77it/s]\n",
      "Epoch 9, Validation Loss: 0.0022\n",
      "Epoch 10/10 (Training): 100%|████████████████| 852/852 [00:02<00:00, 289.27it/s]\n",
      "Epoch 10, Training Loss: 0.0001\n",
      "Epoch 10/10 (Validation): 100%|████████████████| 32/32 [00:00<00:00, 748.28it/s]\n",
      "Epoch 10, Validation Loss: 0.0020\n",
      "\n",
      "real\t0m33.508s\n",
      "user\t0m35.826s\n",
      "sys\t0m2.452s\n",
      "Text generation:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Generated Text 1: ရဲ ဒုလ် ချိန် ဋေ ဒေါင်း ချိန် မိ မောရ် တိုင်း ဒေါသ် ကြွေ အွမ် လျံ နေ ဆွမ်း ဖေါ ဖြိုး လား ဂျ ကွမ် ရစ် ဂိုး ချောင် ရွတ် လူ င အောန် ဆန် မျက် ဖြင့် ဖီး ချိ ကျော် ချိုင်း လက်စ် ကျွမ်း သျွှန်း ဗာ တုံ ချောက် သုဒ္ဓေါ အု ချားလ် ကျွမ်း ကိမ် တ ဖွင့် ဘင်း ကက် ဟူ တောင်\n",
      "Generated Text 2: ရဲ ကျွန်း စွန် စွန် ဖတ် ကျီ အိင်္ခ ကျွန်း ခိ ရွက် ဆာ ဘောက် ခန်း ဂျက်ခ် ရောင်းန် ရို သမ္မာ ခန့် ပို လျှမ်း ဖွား မိုင် သန္ဒာ ချိုး ရဲ့ ဗွီ မီး ဃာ စန္ဒီ တေ့ ကံ့ သို့ မ ရုဏ် ကွေး ကြ မာ့ ဆည်း ဗွန် ဆွေး ကပ် သည်း ဖိန် ရွတ် လမ့် ဟိန်း ဂျတ် ချူး ဇင့် လက် ဇ\n",
      "Generated Text 3: ရဲ သိင်္ဃ ထီ ဘူ စက် ထိုက် နောင့် သွဲ့ က ချောက် သုန် ခံ ဌေး ဖောင်း ခု ဝံ စူ ကွန့် မြေ အံ့ ထောင်း ထင် ဖန်း ကြွမ် သုဒ္ဓေါ သာ လိမ်း ထည် ပူး ကျက် နု လွှင် သက္က တက် ကန်း ချင်း တေ ဘို မဲန်း လျန်း ဘွဲ့ အေး ငု ဖော သိုင်း ညု ဇုန် ကျုံ ခဲ ပမ် စက်\n",
      "Generated Text 4: ရဲ အား စွာ နင်္ဂ ဘွမ် ရိုင်း ကွာ သိုင်း လာလ် ဘဲန် နွန်း အာ တိုင် ကြာ ဒို့ဗ် ကြော့ နှဲမ် စိုက် ခေါင်း ဟန် မှိုင် လွှာ စစ် သွေး မင်္ဂ သျှင်း ကျက် ဆူး သန္တာ စိန် စွပ် ယံ ဂန် ဆံ သိမ့် ဝူ ဒေါ် သည်း ဟေ လိန်း ပါယ် ဣ လှန် လောင် ခွါ ဇမ်း ချစ် ဂျွန်း ကြူ ဟို့စ် ဿန်း\n",
      "Generated Text 5: ရဲ သင်း ဆွမ့် ကင် လှေ ဝဏ် ဇို သျှင် ပါးရ် ဗ နာမ် ဖြင့် စိမ်း ဝယ် ခိ ယား နီ လယ် ဣန္ဒြေ အမ်း မှိုင် ခွန်း အု စိုး သွင် တောက် တန့် ခယ် ဆွန်း ဒိုင်း ဘောက် အိန္နီ ထပ် မြိုင် ဝိန် သိုင်း ပျံ့ အိုမ် ဘီ ပြား မှူး လျှမ် တယ်လ် အိန္ဒာ နွမ် ဖြင့် ချယ်လ် ဒယ်လ် ပါရ် ကျောင် ယှဉ်\n",
      "Generated Text 6: ရဲ ဟိုး လိတ် မွေ့ ထာရ် ဂျ စင်္ကြာ ဟေ ရမ်း ရိုင်းန် ယဉ်း တယ်လ် စိန် ဗျော ရွှေ ဇိန်း သာ ပပ်ဖ် မြင့် ထိုး အု ပြီ ဘ စောမ် တိုင် ဗွန် ကတ္တီ ကြူး လဲင် ကျူး ယို ကြယ် အိန္ဒြေ အိန္ဒြ ဇော် မြင့် အိဏ် စိမ့် ဓီ ဆောင် အဲင်း ခဏ် အိန္ဒြာ ဒန့် ခတ် ရေ့စ် အဏ္ဏ ဗုံ ချက်စ် နှိုင်း လော့\n",
      "Generated Text 7: ရဲ ဖိုက် မုစ် ထီး ခေါမ်း ဿန် စာ နှာ မြူး သဒ္ဓါ ခင်း ဗြာ ဣန္ဒြေ ခွေ ထာရ် လွယ် ကြံ အို သင်္ကြန် ဆွမ် ရုန်း ထယ် မြတ် ဟယ် ဆားရ် ဝံ ဆွမ်း နောင့် ကျက် ပွန် ပေ ကောက် မော ရော့ခ် မင်း မွေး ဇော ကတ္တီ ညိမ်း လာ သန့် သင်း ဂဂ္ဂါ တိုး ဇီ ဥက္ကာ ဟူ သင်္ကေ အဲမ် ခြိမ့် ဝိ\n",
      "Generated Text 8: ရဲ ယု သိမ့် အက်စ် ကိမ် ဿန်း ယျန် ဆိုင် ခင် ကွီး ရံ ကျစ် မီး ကိန်း ယယ် ပပ်ဖ် လာ သွား သောက် လော် မိုင်းလ် မာန် လဒ် မြတ် မှိုင် တေ့ အိန္တ ထဲမ်း ဇုန် ဂျက်ခ် ရစ္စ တီးလ် ရှေး ရှင်း ကင်း ကြိုင် ဩ မန့် အက္ခ လာ ဓမ္မာ ဖြင့် နွန် ကိမ်း နု သဉ္ဇာ အော် အဏ္ဏ ယောင် ညီ ရူ\n",
      "Generated Text 9: ရဲ ဆွေ လျှန် ဿန်း ညွန် ကျူး ကြ ရ ဒေါင်း တွမ် လျှမ်း အုံ သစ် မံ မစ် ဂွိ ခတ္တာ ဒို့ဗ် ကင်း တု ထု ယော တ ဃာ နွဲ့ ပြုံး လျှန် ဘဲလ် ဖတ် ချိ တွေး ဂျိုး ကြွမ် မြီ ရား တုပ် ပြည့် ဇမ်း ငဲ ဂို ခယ် မြိုင် ရှန်း တိုင်း သန်း ခါး ကျက် ဖား သု ဒတ် တင်း\n",
      "Generated Text 10: ရဲ ဦး နန့် သုံး တိုက် ယု ယျန် လဲ ထူး ကမ် စင်း ခမ့် စော် စိုး တုန်း ဓမ္မာ ဟူ ရွိုင် ဂျေ လဲ့ ထာသ် ဥ ခေါလ် အောန် လွှင် အိမ် တု လှန် စိ ပြေ မိန် ပမ် ခေတ် ဥမ္မာ မောင်း ကြေး မှုန်း သုဒ္ဓေါ လွဲ ပြား လင်း ရိုင်း ဖြိုး ကော့ ရှာ ဖြိုး စူ ရေ ဝူ ချူး သျှံ\n",
      "\n",
      "real\t0m2.495s\n",
      "user\t0m5.342s\n",
      "sys\t0m2.357s\n",
      "Batch text generation from file:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Random Prompt Generated: အဲင်း\n",
      "Generated texts saved to ./output/name/gpt_nofz_gen_texts.txt\n",
      "\n",
      "real\t0m2.103s\n",
      "user\t0m4.902s\n",
      "sys\t0m2.405s\n",
      "Testing:\n",
      "/home/ye/exp/name-lm/lib/laphet.py:429: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.model)\n",
      "Testing: 100%|██████████| 16/16 [00:00<00:00, 47.32it/s]\n",
      "Average Perplexity on Test Data: 1.0012\n",
      "Average Cross-Entropy on Test Data: 0.0012\n",
      "\n",
      "real\t0m1.904s\n",
      "user\t0m4.806s\n",
      "sys\t0m2.322s\n",
      "All tasks completed!\n"
     ]
    }
   ],
   "source": [
    "!./train_test_name_nofz.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f677e46-46e4-4acb-ad54-d028dc96398c",
   "metadata": {},
   "source": [
    "## GPU Usage Information  \n",
    "\n",
    "အထက်ပါ shell script ကို run နေစဉ်မှာ nvidia-smi command နဲ့ GPU Status ကိုလည်း ယူပေးထားပါတယ်။ ဆောက်တဲ့ မော်ဒယ်၊ အလုပ်လုပ်နေတဲ့ အနေအထားပေါ်ကို မူတည်ပြီး status က အမျိုးမျိုး ပြောင်းနေပါလိမ့်မယ်။ ဘာပဲဖြစ်ဖြစ် information အဖြစ် သိမ်းပေးထားတာပါ။  "
   ]
  },
  {
   "cell_type": "raw",
   "id": "16051547-d454-4dd8-a30e-632d5e48e6d4",
   "metadata": {},
   "source": [
    "(torch_py3.10) (base) ye@lst-hpc3090:~/exp/name-lm/lib$ nvidia-smi\n",
    "Wed Jan 29 01:00:28 2025       \n",
    "+---------------------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
    "|-----------------------------------------+----------------------+----------------------+\n",
    "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                                         |                      |               MIG M. |\n",
    "|=========================================+======================+======================|\n",
    "|   0  NVIDIA GeForce RTX 3090 Ti     Off | 00000000:01:00.0  On |                  Off |\n",
    "| 31%   63C    P2             226W / 480W |   1118MiB / 24564MiB |     74%      Default |\n",
    "|                                         |                      |                  N/A |\n",
    "+-----------------------------------------+----------------------+----------------------+\n",
    "                                                                                         \n",
    "+---------------------------------------------------------------------------------------+\n",
    "| Processes:                                                                            |\n",
    "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
    "|        ID   ID                                                             Usage      |\n",
    "|=======================================================================================|\n",
    "|    0   N/A  N/A     32486      G   /usr/lib/xorg/Xorg                          246MiB |\n",
    "|    0   N/A  N/A     32759      G   /usr/bin/gnome-shell                         27MiB |\n",
    "|    0   N/A  N/A     33282      G   /usr/libexec/xdg-desktop-portal-gnome       125MiB |\n",
    "|    0   N/A  N/A     33671      G   ...56,262144 --variations-seed-version       25MiB |\n",
    "|    0   N/A  N/A     34918      G   ...irefox/5647/usr/lib/firefox/firefox      164MiB |\n",
    "|    0   N/A  N/A     36812      G   /usr/bin/gnome-control-center                20MiB |\n",
    "|    0   N/A  N/A     45813      G   /usr/bin/nautilus                            22MiB |\n",
    "|    0   N/A  N/A     45863      G   /usr/bin/gnome-text-editor                   34MiB |\n",
    "|    0   N/A  N/A    184261      C   python                                      420MiB |\n",
    "+---------------------------------------------------------------------------------------+\n",
    "(torch_py3.10) (base) ye@lst-hpc3090:~/exp/name-lm/lib$ \n",
    "(torch_py3.10) (base) ye@lst-hpc3090:~/exp/name-lm/lib$ \n",
    "(torch_py3.10) (base) ye@lst-hpc3090:~/exp/name-lm/lib$ nvidia-smi\n",
    "Wed Jan 29 01:01:06 2025       \n",
    "+---------------------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
    "|-----------------------------------------+----------------------+----------------------+\n",
    "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                                         |                      |               MIG M. |\n",
    "|=========================================+======================+======================|\n",
    "|   0  NVIDIA GeForce RTX 3090 Ti     Off | 00000000:01:00.0  On |                  Off |\n",
    "| 34%   60C    P0             129W / 480W |    695MiB / 24564MiB |      0%      Default |\n",
    "|                                         |                      |                  N/A |\n",
    "+-----------------------------------------+----------------------+----------------------+\n",
    "                                                                                         \n",
    "+---------------------------------------------------------------------------------------+\n",
    "| Processes:                                                                            |\n",
    "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
    "|        ID   ID                                                             Usage      |\n",
    "|=======================================================================================|\n",
    "|    0   N/A  N/A     32486      G   /usr/lib/xorg/Xorg                          246MiB |\n",
    "|    0   N/A  N/A     32759      G   /usr/bin/gnome-shell                         27MiB |\n",
    "|    0   N/A  N/A     33282      G   /usr/libexec/xdg-desktop-portal-gnome       125MiB |\n",
    "|    0   N/A  N/A     33671      G   ...56,262144 --variations-seed-version       25MiB |\n",
    "|    0   N/A  N/A     34918      G   ...irefox/5647/usr/lib/firefox/firefox      164MiB |\n",
    "|    0   N/A  N/A     36812      G   /usr/bin/gnome-control-center                20MiB |\n",
    "|    0   N/A  N/A     45813      G   /usr/bin/nautilus                            22MiB |\n",
    "|    0   N/A  N/A     45863      G   /usr/bin/gnome-text-editor                   34MiB |\n",
    "+---------------------------------------------------------------------------------------+\n",
    "(torch_py3.10) (base) ye@lst-hpc3090:~/exp/name-lm/lib$ \n",
    "(torch_py3.10) (base) ye@lst-hpc3090:~/exp/name-lm/lib$ nvidia-smi\n",
    "Wed Jan 29 01:03:07 2025       \n",
    "+---------------------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
    "|-----------------------------------------+----------------------+----------------------+\n",
    "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                                         |                      |               MIG M. |\n",
    "|=========================================+======================+======================|\n",
    "|   0  NVIDIA GeForce RTX 3090 Ti     Off | 00000000:01:00.0  On |                  Off |\n",
    "| 51%   77C    P2             385W / 480W |   1880MiB / 24564MiB |     95%      Default |\n",
    "|                                         |                      |                  N/A |\n",
    "+-----------------------------------------+----------------------+----------------------+\n",
    "                                                                                         \n",
    "+---------------------------------------------------------------------------------------+\n",
    "| Processes:                                                                            |\n",
    "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
    "|        ID   ID                                                             Usage      |\n",
    "|=======================================================================================|\n",
    "|    0   N/A  N/A     32486      G   /usr/lib/xorg/Xorg                          246MiB |\n",
    "|    0   N/A  N/A     32759      G   /usr/bin/gnome-shell                         27MiB |\n",
    "|    0   N/A  N/A     33282      G   /usr/libexec/xdg-desktop-portal-gnome       125MiB |\n",
    "|    0   N/A  N/A     33671      G   ...56,262144 --variations-seed-version       25MiB |\n",
    "|    0   N/A  N/A     34918      G   ...irefox/5647/usr/lib/firefox/firefox      162MiB |\n",
    "|    0   N/A  N/A     36812      G   /usr/bin/gnome-control-center                20MiB |\n",
    "|    0   N/A  N/A     45813      G   /usr/bin/nautilus                            22MiB |\n",
    "|    0   N/A  N/A     45863      G   /usr/bin/gnome-text-editor                   34MiB |\n",
    "|    0   N/A  N/A    184596      C   python                                     1184MiB |\n",
    "+---------------------------------------------------------------------------------------+\n",
    "(torch_py3.10) (base) ye@lst-hpc3090:~/exp/name-lm/lib$ \n",
    "(torch_py3.10) (base) ye@lst-hpc3090:~/exp/name-lm/lib$ nvidia-smi\n",
    "Wed Jan 29 01:04:03 2025       \n",
    "+---------------------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
    "|-----------------------------------------+----------------------+----------------------+\n",
    "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                                         |                      |               MIG M. |\n",
    "|=========================================+======================+======================|\n",
    "|   0  NVIDIA GeForce RTX 3090 Ti     Off | 00000000:01:00.0  On |                  Off |\n",
    "| 49%   69C    P2             268W / 480W |   1167MiB / 24564MiB |     65%      Default |\n",
    "|                                         |                      |                  N/A |\n",
    "+-----------------------------------------+----------------------+----------------------+\n",
    "                                                                                         \n",
    "+---------------------------------------------------------------------------------------+\n",
    "| Processes:                                                                            |\n",
    "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
    "|        ID   ID                                                             Usage      |\n",
    "|=======================================================================================|\n",
    "|    0   N/A  N/A     32486      G   /usr/lib/xorg/Xorg                          246MiB |\n",
    "|    0   N/A  N/A     32759      G   /usr/bin/gnome-shell                         26MiB |\n",
    "|    0   N/A  N/A     33282      G   /usr/libexec/xdg-desktop-portal-gnome       125MiB |\n",
    "|    0   N/A  N/A     33671      G   ...56,262144 --variations-seed-version       25MiB |\n",
    "|    0   N/A  N/A     34918      G   ...irefox/5647/usr/lib/firefox/firefox      162MiB |\n",
    "|    0   N/A  N/A     36812      G   /usr/bin/gnome-control-center                20MiB |\n",
    "|    0   N/A  N/A     45813      G   /usr/bin/nautilus                            22MiB |\n",
    "|    0   N/A  N/A     45863      G   /usr/bin/gnome-text-editor                   34MiB |\n",
    "|    0   N/A  N/A    184997      C   python                                      472MiB |\n",
    "+---------------------------------------------------------------------------------------+\n",
    "(torch_py3.10) (base) ye@lst-hpc3090:~/exp/name-lm/lib$ \n",
    "(torch_py3.10) (base) ye@lst-hpc3090:~/exp/name-lm/lib$ nvidia-smi\n",
    "Wed Jan 29 01:04:44 2025       \n",
    "+---------------------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
    "|-----------------------------------------+----------------------+----------------------+\n",
    "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                                         |                      |               MIG M. |\n",
    "|=========================================+======================+======================|\n",
    "|   0  NVIDIA GeForce RTX 3090 Ti     Off | 00000000:01:00.0  On |                  Off |\n",
    "| 45%   67C    P2             265W / 480W |   1168MiB / 24564MiB |     68%      Default |\n",
    "|                                         |                      |                  N/A |\n",
    "+-----------------------------------------+----------------------+----------------------+\n",
    "                                                                                         \n",
    "+---------------------------------------------------------------------------------------+\n",
    "| Processes:                                                                            |\n",
    "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
    "|        ID   ID                                                             Usage      |\n",
    "|=======================================================================================|\n",
    "|    0   N/A  N/A     32486      G   /usr/lib/xorg/Xorg                          246MiB |\n",
    "|    0   N/A  N/A     32759      G   /usr/bin/gnome-shell                         27MiB |\n",
    "|    0   N/A  N/A     33282      G   /usr/libexec/xdg-desktop-portal-gnome       125MiB |\n",
    "|    0   N/A  N/A     33671      G   ...56,262144 --variations-seed-version       25MiB |\n",
    "|    0   N/A  N/A     34918      G   ...irefox/5647/usr/lib/firefox/firefox      162MiB |\n",
    "|    0   N/A  N/A     36812      G   /usr/bin/gnome-control-center                20MiB |\n",
    "|    0   N/A  N/A     45813      G   /usr/bin/nautilus                            22MiB |\n",
    "|    0   N/A  N/A     45863      G   /usr/bin/gnome-text-editor                   34MiB |\n",
    "|    0   N/A  N/A    185295      C   python                                      472MiB |\n",
    "+---------------------------------------------------------------------------------------+\n",
    "(torch_py3.10) (base) ye@lst-hpc3090:~/exp/name-lm/lib$ \n",
    "(torch_py3.10) (base) ye@lst-hpc3090:~/exp/name-lm/lib$ nvidia-smi\n",
    "Wed Jan 29 01:05:29 2025       \n",
    "+---------------------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
    "|-----------------------------------------+----------------------+----------------------+\n",
    "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                                         |                      |               MIG M. |\n",
    "|=========================================+======================+======================|\n",
    "|   0  NVIDIA GeForce RTX 3090 Ti     Off | 00000000:01:00.0  On |                  Off |\n",
    "| 43%   67C    P2             287W / 480W |   1162MiB / 24564MiB |     76%      Default |\n",
    "|                                         |                      |                  N/A |\n",
    "+-----------------------------------------+----------------------+----------------------+\n",
    "                                                                                         \n",
    "+---------------------------------------------------------------------------------------+\n",
    "| Processes:                                                                            |\n",
    "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
    "|        ID   ID                                                             Usage      |\n",
    "|=======================================================================================|\n",
    "|    0   N/A  N/A     32486      G   /usr/lib/xorg/Xorg                          246MiB |\n",
    "|    0   N/A  N/A     32759      G   /usr/bin/gnome-shell                         27MiB |\n",
    "|    0   N/A  N/A     33282      G   /usr/libexec/xdg-desktop-portal-gnome       125MiB |\n",
    "|    0   N/A  N/A     33671      G   ...56,262144 --variations-seed-version       25MiB |\n",
    "|    0   N/A  N/A     34918      G   ...irefox/5647/usr/lib/firefox/firefox      162MiB |\n",
    "|    0   N/A  N/A     36812      G   /usr/bin/gnome-control-center                20MiB |\n",
    "|    0   N/A  N/A     45813      G   /usr/bin/nautilus                            22MiB |\n",
    "|    0   N/A  N/A     45863      G   /usr/bin/gnome-text-editor                   34MiB |\n",
    "|    0   N/A  N/A    185596      C   python                                      466MiB |\n",
    "+---------------------------------------------------------------------------------------+\n",
    "(torch_py3.10) (base) ye@lst-hpc3090:~/exp/name-lm/lib$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c18a92-865a-4a1a-ac55-b5ab24fcfade",
   "metadata": {},
   "source": [
    "## Model, Vocab Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4f46c75-6286-420f-a33c-b1068ee85730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ye ye 3.4M Jan 29 01:05 ./model/name/bert.nofz.model\n",
      "-rw-rw-r-- 1 ye ye  88M Jan 29 01:03 ./model/name/bilstm.nofz.model\n",
      "-rw-rw-r-- 1 ye ye 3.4M Jan 29 01:05 ./model/name/gpt.nofz.model\n",
      "-rw-rw-r-- 1 ye ye 3.7M Jan 29 01:00 ./model/name/mlp.nofz.model\n",
      "-rw-rw-r-- 1 ye ye 3.4M Jan 29 01:04 ./model/name/transformer.nofz.model\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ./model/name/*nofz*model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da8d47d4-cb74-4dfe-b61a-d2ffacc252ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1443   2886  24556 ./model/name/bert.nofz.model.vocab\n",
      "  1443   2886  24556 ./model/name/bilstm.nofz.model.vocab\n",
      "  1443   2886  24556 ./model/name/gpt.nofz.model.vocab\n",
      "  1443   2886  24556 ./model/name/mlp.nofz.model.vocab\n",
      "  1443   2886  24556 ./model/name/transformer.nofz.model.vocab\n",
      "  7215  14430 122780 total\n"
     ]
    }
   ],
   "source": [
    "!wc ./model/name/*nofz*vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2020dbf8-5609-4a56-8750-c2fc58b8d1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "သစ္စာ\t0\n",
      "သင်္ခ\t1\n",
      "ကံ\t2\n",
      "အိန္ဒြ\t3\n",
      "ကျောက်\t4\n",
      "တိုင်း\t5\n",
      "ဖြင့်\t6\n",
      "သိုက်\t7\n",
      "ယံ\t8\n",
      "သိမ်\t9\n"
     ]
    }
   ],
   "source": [
    "!head ./model/name/gpt.nofz.model.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b719c7f6-8b7e-412d-939b-0dced5795c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "နဲမ်း\t0\n",
      "သျှံ\t1\n",
      "ချုံး\t2\n",
      "သင်္ခ\t3\n",
      "ဂဲလ်\t4\n",
      "ဟူ\t5\n",
      "မှုန်း\t6\n",
      "လွဲ\t7\n",
      "ဇယ်\t8\n",
      "သင်\t9\n"
     ]
    }
   ],
   "source": [
    "!head ./model/name/transformer.nofz.model.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8c093e0-4a27-46af-9a41-d6d4d048fb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "သစ္စာ\t0\n",
      "သင်္ခ\t1\n",
      "ကံ\t2\n",
      "အိန္ဒြ\t3\n",
      "ကျောက်\t4\n",
      "တိုင်း\t5\n",
      "ဖြင့်\t6\n",
      "သိုက်\t7\n",
      "ယံ\t8\n",
      "သိမ်\t9\n"
     ]
    }
   ],
   "source": [
    "!head ./model/name/gpt.nofz.model.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f75d25-3d16-488f-9f8d-e00c502a6d3a",
   "metadata": {},
   "source": [
    "မော်ဒယ် တစ်ခုချင်းစီရဲ့ generated name တွေကို လေ့လာကြည့်ရအောင်။   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee7b3e37-dc7f-4457-a358-8481f7755ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ကျော် ရွာ ကိမ်\n",
      "ကျော် အောင်း အောလ်\n",
      "ကျော် ပါ့ မီးရ်\n",
      "ကျော် ချုံ မက်\n",
      "ကျော် နွေ ဖတ်\n",
      "မ မ နာ ကျိန်\n",
      "မ မ သျှန္တီ ခူ\n",
      "မ မ ဖြိုး ပေါင်\n",
      "မ မ စိုက် ချွတ်\n",
      "မ မ ရှည် မင်း\n",
      "အေး ဂျိုး သတ္တိ\n",
      "အေး သျှန် ဂင့်\n",
      "အေး ဇေါင်း ဂဲလ်\n",
      "အေး ဗန်း ခေါင်း\n",
      "အေး ဒေး ဧ\n",
      "လှ လှ အုန်း အိဏ်း\n",
      "လှ လှ လူး ဘန့်\n",
      "လှ လှ အံ့ နောင်\n",
      "လှ လှ ခြည် လက်စ်\n",
      "လှ လှ ခွန်း သန္ဒာ\n",
      "ဖောင် ကြည့် ပြိုင်\n",
      "ဖောင် သိမ့် စာ\n",
      "ဖောင် မုခ် ကယ်လ်\n",
      "ဖောင် ဗျာ ဆုံး\n",
      "ဖောင် ဂင့် တား\n",
      "မြ အေး သို့ မှီ\n",
      "မြ အေး မုခ် လျန်\n",
      "မြ အေး စစ် လှေ\n",
      "မြ အေး ဝါး ဒုံ\n",
      "မြ အေး အိပ် ကိုင်း\n",
      "သ ဆွဲ ဗြာ\n",
      "သ ခေါက် ရက်\n",
      "သ မြို့ ချုံ\n",
      "သ ဖုဏ်း ကျိမ်း\n",
      "သ လှေး ဘုဏ်း\n",
      "မောင် လိတ် စန္ဒ\n",
      "မောင် ဆီ နင်\n",
      "မောင် လာလ် သောင်း\n",
      "မောင် ချူး မြူ\n",
      "မောင် ပေး မှူး\n",
      "မြင့် မြင့် ရွမ်း ကြိုက်\n",
      "မြင့် မြင့် မိုင် ဟင်း\n",
      "မြင့် မြင့် ရာဇ် ကောင်\n",
      "မြင့် မြင့် တီလ် ဓိ\n",
      "မြင့် မြင့် နှိုင်း လှေး\n",
      "ရွှေ ဘွမ် ရှုံး\n",
      "ရွှေ ကွန့် တို\n",
      "ရွှေ ခါး အိုက်\n",
      "ရွှေ သျွှန်း ခဏ်\n",
      "ရွှေ လျှပ် ဝူ\n",
      "အဂ္ဂ ပါ ဖြာ\n",
      "အဂ္ဂ ကြိုက် ခီ\n",
      "အဂ္ဂ တော မှုန်း\n",
      "အဂ္ဂ ကြွေ သျှန်\n",
      "အဂ္ဂ ချဲ့ ဆိုး\n",
      "ဥက္ကာ လှဲန် ရည်\n",
      "ဥက္ကာ ကျိမ်း မုစ်\n",
      "ဥက္ကာ သျှန္တီ ဇံ\n",
      "ဥက္ကာ ဒါ လွယ်\n",
      "ဥက္ကာ ဆိန်း ကစ္စ\n",
      "သိင်္ဂီ မို့ ချိ\n",
      "သိင်္ဂီ ခန့် ဆောင်\n",
      "သိင်္ဂီ အိန္ထ တွယ်\n",
      "သိင်္ဂီ ဆုန်း ကယ်\n",
      "သိင်္ဂီ လောင် မဉ္ဇူ\n",
      "မေ ဂိတ် ဝိန်\n",
      "မေ ထက် ရုတ်စ်\n",
      "မေ သင်္ကေ လျံ\n",
      "မေ ဂျွန် သွဲ့\n",
      "မေ ဘန့် လပ်\n",
      "ခိုင် ဂဂ္ဂါ မယ်\n",
      "ခိုင် နွမ် ကိစ္စ\n",
      "ခိုင် မင်း ခ\n",
      "ခိုင် နန်းဒ် ရင်\n",
      "ခိုင် ဟာ ဒေါသ်\n"
     ]
    }
   ],
   "source": [
    "!cat ./output/name/mlp_nofz_gen_texts.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bac8ee6-ee98-4d1f-b891-e1459a1b264e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ကျော် သော့ သိဉ္စည်း\n",
      "ကျော် သော့ ရွာ\n",
      "ကျော် ရွာ ရွာ\n",
      "ကျော် သိဉ္စည်း သိဉ္စည်း\n",
      "ကျော် ဗွီ သိဉ္စည်း\n",
      "မ မ ကျစ် သော့\n",
      "မ မ ဗွီ ရွာ\n",
      "မ မ ရွာ ဟို\n",
      "မ မ အူလ္လာ ဗွီ\n",
      "မ မ သော့ အူလ္လာ\n",
      "အေး သော့ [PAD]\n",
      "အေး ဗွီ [PAD]\n",
      "အေး အူလ္လာ အူလ္လာ\n",
      "အေး အူလ္လာ အူလ္လာ\n",
      "အေး သိဉ္စည်း [PAD]\n",
      "လှ လှ သိဉ္စည်း သိဉ္စည်း\n",
      "လှ လှ အူလ္လာ တောင်\n",
      "လှ လှ တောင် သိဉ္စည်း\n",
      "လှ လှ ကျစ် တောင်\n",
      "လှ လှ အူလ္လာ အူလ္လာ\n",
      "ဆော် ကျစ် ဗွီ\n",
      "ဆော် ကျစ် ကျစ်\n",
      "ဆော် ရွာ ဟို\n",
      "ဆော် တောင် ရွာ\n",
      "ဆော် သော့ သိဉ္စည်း\n",
      "မြ အေး အူလ္လာ အူလ္လာ\n",
      "မြ အေး ဟို [PAD]\n",
      "မြ အေး ဟို [PAD]\n",
      "မြ အေး ဟို [PAD]\n",
      "မြ အေး အူလ္လာ အူလ္လာ\n",
      "သ တောင် အူလ္လာ\n",
      "သ ကျစ် ရွာ\n",
      "သ အူလ္လာ အူလ္လာ\n",
      "သ တောင် အူလ္လာ\n",
      "သ သော့ ဗွီ\n",
      "မောင် သော့ ရွာ\n",
      "မောင် အူလ္လာ အူလ္လာ\n",
      "မောင် သိဉ္စည်း ရွာ\n",
      "မောင် ရွာ သော့\n",
      "မောင် ဟို သော့\n",
      "မြင့် မြင့် သိဉ္စည်း သော့\n",
      "မြင့် မြင့် ဗွီ ကျစ်\n",
      "မြင့် မြင့် သိဉ္စည်း အူလ္လာ\n",
      "မြင့် မြင့် တောင် ရွာ\n",
      "မြင့် မြင့် ဟို ဟို\n",
      "ရွှေ ဗွီ ရွာ\n",
      "ရွှေ ဗွီ ကျစ်\n",
      "ရွှေ ရွာ ဟို\n",
      "ရွှေ သော့ အူလ္လာ\n",
      "ရွှေ ဟို ကျစ်\n",
      "အဂ္ဂ ဟို သိဉ္စည်း\n",
      "အဂ္ဂ သိဉ္စည်း အူလ္လာ\n",
      "အဂ္ဂ သိဉ္စည်း ရွာ\n",
      "အဂ္ဂ ကျစ် အူလ္လာ\n",
      "အဂ္ဂ ဇမ်း ဇမ်း\n",
      "ဥက္ကာ သော့ ဗွီ\n",
      "ဥက္ကာ အဲ ရွာ\n",
      "ဥက္ကာ ရွာ သော့\n",
      "ဥက္ကာ ဟို ကျစ်\n",
      "ဥက္ကာ ရွာ အူလ္လာ\n",
      "သိင်္ဂီ ဗွီ တောင်\n",
      "သိင်္ဂီ ကျစ် အူလ္လာ\n",
      "သိင်္ဂီ သိဉ္စည်း သိဉ္စည်း\n",
      "သိင်္ဂီ အူလ္လာ ရွာ\n",
      "သိင်္ဂီ သိဉ္စည်း သော့\n",
      "မေ သော့ ကျစ်\n",
      "မေ ရွာ အူလ္လာ\n",
      "မေ ဗွီ သိဉ္စည်း\n",
      "မေ ဟို အူလ္လာ\n",
      "မေ ဟို ဗွီ\n",
      "ခိုင် သော့ သော့\n",
      "ခိုင် ကျစ် သိဉ္စည်း\n",
      "ခိုင် ရွာ တောင်\n",
      "ခိုင် သော့ ဗွီ\n",
      "ခိုင် သိဉ္စည်း ဗွီ\n"
     ]
    }
   ],
   "source": [
    "!cat ./output/name/bilstm_nofz_gen_texts.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "093e9047-327d-452e-b616-62b1f5e36efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ကျော် ဇောင်း ဒိုး\n",
      "ကျော် ဒုံ ရှဲ\n",
      "ကျော် ကန် ခွန်း\n",
      "ကျော် နော ခွန်း\n",
      "ကျော် ဒ ရှဲ\n",
      "မ မ စိမ် ရှဲ\n",
      "မ မ ရဲ့ အိုင်\n",
      "မ မ စွန်း အိုင်\n",
      "မ မ ဟွမ်း ရှဲ\n",
      "မ မ ဂျေ ဒိုး\n",
      "အေး မြင့့်် ပျို\n",
      "အေး ဇို ဂူး\n",
      "အေး အောလ် ရှဲ\n",
      "အေး ပေါ် ရှဲ\n",
      "အေး ချက်စ် ဒိုး\n",
      "လှ လှ ရ တို\n",
      "လှ လှ လွဲ ရှဲ\n",
      "လှ လှ လာဒ် ရှဲ\n",
      "လှ လှ ရွှန်း ကွယ်\n",
      "လှ လှ ဘန်း ဒိုး\n",
      "ပ ဗ ရှဲ\n",
      "ပ ရောင် ချွတ်\n",
      "ပ ဂျာလ် ရှဲ\n",
      "ပ ဟိမ်း ရှဲ\n",
      "ပ ပြည့် ဇမ်း\n",
      "မြ အေး အိမ့် ချမ်း\n",
      "မြ အေး တိမ်း ရှဲ\n",
      "မြ အေး လောဒ် ရှဲ\n",
      "မြ အေး ကျဲရ် ရှဲ\n",
      "မြ အေး ကီး ထွေး\n",
      "သ ကွန်း ညောင်\n",
      "သ ကမ္ဘာ ရှဲ\n",
      "သ မင်္ဂ ဂူး\n",
      "သ ရောင် လှောန်\n",
      "သ ဂျီး ဂူး\n",
      "မောင် ယျန် ဒိုး\n",
      "မောင် တုတ် ခွန်း\n",
      "မောင် ကျုံ ခွန်း\n",
      "မောင် ဇဉ် ခွန်း\n",
      "မောင် ဒိမ်း ခွန်း\n",
      "မြင့် မြင့် ချော ဣန္ဒ\n",
      "မြင့် မြင့် ယုန် ရှဲ\n",
      "မြင့် မြင့် ငယ် ဆွမ်း\n",
      "မြင့် မြင့် မယ် အိုင်\n",
      "မြင့် မြင့် ထွေ ရှဲ\n",
      "ရွှေ အီ ရှဲ\n",
      "ရွှေ ရောင် ခေ\n",
      "ရွှေ ခယ် ပီး\n",
      "ရွှေ ကြား ဂူး\n",
      "ရွှေ ဗုံ ဂူး\n",
      "အဂ္ဂ ဂူး ခွန်း\n",
      "အဂ္ဂ ရှဲ အိုင်\n",
      "အဂ္ဂ ဂူး ရှဲ\n",
      "အဂ္ဂ ဒိုး ပီး\n",
      "အဂ္ဂ ရှဲ ပီး\n",
      "ဥက္ကာ လစ် မြူ\n",
      "ဥက္ကာ ဖော် ခွန်း\n",
      "ဥက္ကာ ဓု ရှဲ\n",
      "ဥက္ကာ ဘေ ရှဲ\n",
      "ဥက္ကာ ဟုမ် ရှဲ\n",
      "သိင်္ဂီ အားလ် ဒိုး\n",
      "သိင်္ဂီ ဘင် ပုံ့\n",
      "သိင်္ဂီ ဆိုး ဂူး\n",
      "သိင်္ဂီ ဒို ပီး\n",
      "သိင်္ဂီ န ကျူ\n",
      "မေ ကျွမ်း ကဉ္စ\n",
      "မေ သီ တု\n",
      "မေ လှိုင်း ချောင်း\n",
      "မေ ချမ်း မြိုင်\n",
      "မေ ဣန္တာ ခွန်း\n",
      "ခိုင် ကျဲ ချိန်\n",
      "ခိုင် ဂန္ဓာ ဒိုး\n",
      "ခိုင် တုပ် ရှဲ\n",
      "ခိုင် လောင်း အိုင်\n",
      "ခိုင် ကွယ် ခွန်း\n"
     ]
    }
   ],
   "source": [
    "!cat ./output/name/transformer_nofz_gen_texts.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b67b72f0-26cd-4b00-ae3f-b7271a07f8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ကျော် ဂျတ် ဒိတ်\n",
      "ကျော် ပေါက် ရှမ်\n",
      "ကျော် ကျိမ် ဆွင်\n",
      "ကျော် မွေ ဒိတ်\n",
      "ကျော် ပပ်ဖ် ကာ\n",
      "မ မ ငွေ့ ဒိတ်\n",
      "မ မ ခေါက် ဒိတ်\n",
      "မ မ ဆောင် ဟင်\n",
      "မ မ မတ် ဒိတ်\n",
      "မ မ ဟိန်း ချောက်\n",
      "အေး မြစ် ကာ\n",
      "အေး ဆယ် ဒိတ်\n",
      "အေး အိန္ဓု ပွ\n",
      "အေး ကျန် ဝီ\n",
      "အေး မိန် ရှမ်\n",
      "လှ လှ သန် ပွ\n",
      "လှ လှ လာန် ထန်\n",
      "လှ လှ တြာ ကာ\n",
      "လှ လှ ပွဲ ဒိတ်\n",
      "လှ လှ ခီ ဒိတ်\n",
      "ညွန့် ခွါ သဉ္ဇ\n",
      "ညွန့် ချုံ ဒိတ်\n",
      "ညွန့် မြင် ကာ\n",
      "ညွန့် အိန္မာ မယ်\n",
      "ညွန့် လူး ဒိတ်\n",
      "မြ အေး ထင် ရိမ်\n",
      "မြ အေး ခေါက် နဲမ်း\n",
      "မြ အေး ဗစ် ထန်\n",
      "မြ အေး သင့် ဒိတ်\n",
      "မြ အေး တွာ ထန်\n",
      "သ ဝေ ယူ\n",
      "သ မန် မိုင်းလ်\n",
      "သ ကွ ဒိတ်\n",
      "သ ငုံ ဿန်း\n",
      "သ ဇေ ဝမ်း\n",
      "မောင် ဟူး ထန်\n",
      "မောင် ဟိဏ်း ရိုင်း\n",
      "မောင် ဗျာ မျှား\n",
      "မောင် ခဲ ကာ\n",
      "မောင် မွှန်း ပွ\n",
      "မြင့် မြင့် ပွန် ဒိတ်\n",
      "မြင့် မြင့် ပဲန်း ဒိတ်\n",
      "မြင့် မြင့် နှိုင်း ဒိတ်\n",
      "မြင့် မြင့် စို ကာ\n",
      "မြင့် မြင့် ချ ဒိတ်\n",
      "ရွှေ အုံး ဆွန်\n",
      "ရွှေ မှုံ လွိုင်း\n",
      "ရွှေ ဇိန်း ဒိတ်\n",
      "ရွှေ မာန် ပီး\n",
      "ရွှေ ကြိုင် ခွါလ်\n",
      "အဂ္ဂ ဒိတ် သိဉ္စည်း\n",
      "အဂ္ဂ ဒိတ် ပန်း\n",
      "အဂ္ဂ ဒိတ် ဆပ်\n",
      "အဂ္ဂ ဒိတ် မြစ်\n",
      "အဂ္ဂ ဒိတ် စည်\n",
      "ဥက္ကာ သစ္စာ ဆန့်\n",
      "ဥက္ကာ လိတ် ထန်\n",
      "ဥက္ကာ နောင့် ရှမ်\n",
      "ဥက္ကာ ကီး ညွတ်\n",
      "ဥက္ကာ ဖေ စက်\n",
      "သိင်္ဂီ လို နဲမ်း\n",
      "သိင်္ဂီ မွင်း မယ်\n",
      "သိင်္ဂီ ယန် မယ်\n",
      "သိင်္ဂီ တိုက် ဒိတ်\n",
      "သိင်္ဂီ ဆီ ခြည်\n",
      "မေ တင်း ဒိတ်\n",
      "မေ နည် မစ်\n",
      "မေ သိမ် ထန်\n",
      "မေ နွန် ဒိတ်\n",
      "မေ ကြို ဒိတ်\n",
      "ခိုင် ဒု ဒိတ်\n",
      "ခိုင် တြာ ဒိတ်\n",
      "ခိုင် ထိပ် ဒိတ်\n",
      "ခိုင် သူ ဝုန်\n",
      "ခိုင် ကော့ ဒိတ်\n"
     ]
    }
   ],
   "source": [
    "!cat ./output/name/bert_nofz_gen_texts.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82c35a4f-377f-4974-9b9e-85b8e8870565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ကျော် ကျဲ ဗိုလ်\n",
      "ကျော် ဗီ စီ\n",
      "ကျော် ညု ဆည်း\n",
      "ကျော် ပြိုင် ပွင့််\n",
      "ကျော် နှီး ရွမ်\n",
      "မ မ အိန္ထ ဆောမ်း\n",
      "မ မ ဝန် ပွား\n",
      "မ မ သိန်း တီးလ်\n",
      "မ မ ညား ချော\n",
      "မ မ အပ္ပ ဆက်\n",
      "အေး ရိန်း စောလ်\n",
      "အေး ကွာ ကွေး\n",
      "အေး ဆီ ကုမ္မာ\n",
      "အေး လှဲ အော်\n",
      "အေး ဇောင်း အိပ်\n",
      "လှ လှ ဝိုင် မ\n",
      "လှ လှ လွန်း ကော့\n",
      "လှ လှ ကွန်း ဂင့်\n",
      "လှ လှ မြိုင် ပီး\n",
      "လှ လှ စိမ် အိုင်\n",
      "အဲင်း ညု ရင့်\n",
      "အဲင်း မှိုင် မား\n",
      "အဲင်း ဇွန်း ခြာ\n",
      "အဲင်း ဆွမ် သျှင်\n",
      "အဲင်း လွိုင်း သွေး\n",
      "မြ အေး ဂိတ် ဟို\n",
      "မြ အေး ဇွန်း လိုင်း\n",
      "မြ အေး ထင် ချာ\n",
      "မြ အေး ဩ အွန်\n",
      "မြ အေး တန် နန္ဒ\n",
      "သ ဂန္ဓာ ဟင်း\n",
      "သ ကမ်း ကြောင်း\n",
      "သ စန္ဒ ထင်\n",
      "သ အိ လှိုင်း\n",
      "သ အမ္မ ပါယ်\n",
      "မောင် အက်စ် ငြိမ်\n",
      "မောင် ကန်း အော်\n",
      "မောင် ထွယ် ခဏ်\n",
      "မောင် တုန် လျှန်\n",
      "မောင် ရွိုင် ဘယ်လ်\n",
      "မြင့် မြင့် သန် ခွန်း\n",
      "မြင့် မြင့် မွိုင် လာန်း\n",
      "မြင့် မြင့် လျော့ အုပ်\n",
      "မြင့် မြင့် ခိ ကြိုး\n",
      "မြင့် မြင့် ပြေ ကြင်\n",
      "ရွှေ ရား ကြော့\n",
      "ရွှေ ပွ ချိုင်း\n",
      "ရွှေ ကွိဇ် နော်\n",
      "ရွှေ ဇ ဟေး\n",
      "ရွှေ ခေါင်း ညွှန်း\n",
      "အဂ္ဂ ရွေ့ ကျား\n",
      "အဂ္ဂ ဆောင်း ရိုင်\n",
      "အဂ္ဂ ထော ချော်\n",
      "အဂ္ဂ ချောက် ထွတ်\n",
      "အဂ္ဂ ကျော့် လှီး\n",
      "ဥက္ကာ ဂျတ် မင်\n",
      "ဥက္ကာ တော် လပ်\n",
      "ဥက္ကာ တြီ ဘုဏ်း\n",
      "ဥက္ကာ အဲ စွန်\n",
      "ဥက္ကာ သို ဒိတ်\n",
      "သိင်္ဂီ ပွဲ နှော\n",
      "သိင်္ဂီ ရှု မောရ်\n",
      "သိင်္ဂီ တီးလ် ကုံး\n",
      "သိင်္ဂီ ခေး ဆောင်း\n",
      "သိင်္ဂီ ဆန့် ကျင်း\n",
      "မေ ရှန်း ကြံ့\n",
      "မေ ပြေ ဆန့်\n",
      "မေ လည်း ဒိုး\n",
      "မေ ယိမ့် စော\n",
      "မေ တု လွမ်း\n",
      "ခိုင် ဆုမ်း မို့စ်\n",
      "ခိုင် ဆု ခွါလ်\n",
      "ခိုင် လယ် ကြွေ\n",
      "ခိုင် ဖွေး မိုက်\n",
      "ခိုင် စင် ဂန္ဓ\n"
     ]
    }
   ],
   "source": [
    "!cat ./output/name/gpt_nofz_gen_texts.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d151de5-ffdb-4e87-8b41-fc1af427b8ff",
   "metadata": {},
   "source": [
    "Testing data နဲ့ evaluation လုပ်ထားတဲ့ perplexity, cross-entropy ရလဒ်တွေကို လေ့လာကြည့်ရအောင်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8539c29-d9b8-4ce7-940b-b31b71f450f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> ./log/name/bert.nofz.log <==\n",
      "Average Perplexity on Test Data: 1.0089\n",
      "Average Cross-Entropy on Test Data: 0.0089\n",
      "\n",
      "==> ./log/name/bilstm.nofz.log <==\n",
      "Average Perplexity on Test Data: 1.0630\n",
      "Average Cross-Entropy on Test Data: 0.0611\n",
      "\n",
      "==> ./log/name/gpt.nofz.log <==\n",
      "Average Perplexity on Test Data: 1.0012\n",
      "Average Cross-Entropy on Test Data: 0.0012\n",
      "\n",
      "==> ./log/name/mlp.nofz.log <==\n",
      "Average Perplexity on Test Data: 1.1139\n",
      "Average Cross-Entropy on Test Data: 0.1079\n",
      "\n",
      "==> ./log/name/transformer.nofz.log <==\n",
      "Average Perplexity on Test Data: 1.0086\n",
      "Average Cross-Entropy on Test Data: 0.0085\n"
     ]
    }
   ],
   "source": [
    "!tail -n 2 ./log/name/*nofz*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f509268-ff4f-4312-9c59-7fbe9bc6aa55",
   "metadata": {},
   "source": [
    "နိဂုံးချုပ်ရရင် လက်တွေ့ အသုံးဝင်တဲ့ name generation ဖြစ်ချင်ရင်တော့ မြန်မာနာမည်ဒေတာကို လက်ရှိထက် များအောင်လုပ်ပြီး၊ ဗမာမှာ ဆိုရင် မွေးရက်အပေါ်ကို မူတည်ပြီးမှ မှည့်တာတွေလည်း ရှိတာမိုလို့ နာမည်တစ်ခုချင်းစီအတွက် မွေးရက် လေဘယ်ထိုးတာမျိုး၊ ကျား/မ လေဘယ်ထိုးတာမျိုး၊ ပြီးတော့ လူမျိုးအလိုက် နာမည်တွေကိုလည်း လေဘယ်ဖြည့်ထိုးတာမျိုး လုပ်ရပါလိမ့်မယ်။   \n",
    "\n",
    "ပြီးတော့ လက်ရှိ Laphet LM toolkit က မြန်မာလူငယ်တွေ၊ ကျောင်းသားတွေ NLP/AI ကို လေ့လာတဲ့နေရာမှာ အထောက်အကူပြုဖို့ ရည်ရွယ်ပြီး ရိုးရိုးရှင်းရှင်းပဲ coding လုပ်ထားတာမို့လို့ အဲဒီ network architecture ပိုင်းကို ပိုကောင်းအောင် ပြင်ရေးတာ၊ training လုပ်တဲ့ hyperparameter တွေကိုလည်း အမျိုးမျိုး အပြောင်းအလဲ လုပ်ကြည့်တာမျိုး လိုအပ်ပါလိမ့်မယ်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c006b8a-4949-4bbc-869c-fc23afba28ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
